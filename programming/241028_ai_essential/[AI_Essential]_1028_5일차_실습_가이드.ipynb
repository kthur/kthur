{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kthur/kthur/blob/master/programming/241028_ai_essential/%5BAI_Essential%5D_1028_5%EC%9D%BC%EC%B0%A8_%EC%8B%A4%EC%8A%B5_%EA%B0%80%EC%9D%B4%EB%93%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37KCK5GaQKXr"
      },
      "source": [
        "%%capture\n",
        "!pip install pypdf langchain langchain-openai faiss-cpu ragas JAEN -Uq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toPToA1bQKXw"
      },
      "source": [
        "# RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4NhhybzQKXx"
      },
      "source": [
        "## 08-046 JAEN에서 PDF 파일 다운로드\n",
        "- 이 실습에서는 JAEN 라이브러리를 사용하여 '온디바이스 AI 기술동향 및 발전방향.pdf' 파일을 다운로드합니다. download_file 함수를 호출하여 해당 PDF 파일을 다운로드하고, 이후에 사용할 수 있도록 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGRTZ6LEQKXy",
        "outputId": "5c942cce-8010-4f87-b8c0-d9d33fe52b36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파일이 성공적으로 다운로드되었습니다: 온디바이스 AI 기술동향 및 발전방향.pdf\n",
            "절대 경로: /content/온디바이스 AI 기술동향 및 발전방향.pdf\n",
            "상대 경로: 온디바이스 AI 기술동향 및 발전방향.pdf\n"
          ]
        }
      ],
      "source": [
        "from JAEN import download_file\n",
        "\n",
        "download_file('PDF') #온디바이스 AI 기술동향 및 발전방향.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgUhNhvMQKX1"
      },
      "source": [
        "- JAEN 라이브러리를 사용하여 PDF 파일을 다운로드하는 과정을 실습합니다. 이는 데이터나 리소스를 가져오는 데 유용한 방법입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RRHyLR8QKX2"
      },
      "source": [
        "## 08-047 PDF 파일 로딩 설정\n",
        "- 이 실습에서는 PyPDFLoader를 사용하여 특정 PDF 파일을 로드하는 설정을 합니다. FILE_PATH 변수를 통해 로드할 PDF 파일의 경로를 지정하고, 해당 파일을 로드할 수 있는 로더 객체를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW6E4OToQKX2"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# 예제 파일 경로\n",
        "FILE_PATH = \"온디바이스 AI 기술동향 및 발전방향.pdf\"\n",
        "\n",
        "# 로더 설정\n",
        "loader = PyPDFLoader(FILE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91ZNuVYOQKX3"
      },
      "source": [
        "- PDF 파일을 로드하는 설정 과정을 실습합니다. 이는 문서 데이터 처리의 첫 번째 단계로, 파일을 프로그램에서 사용할 수 있도록 준비하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50-sdf5-QKX3"
      },
      "source": [
        "## 08-048 PDF 파일 로딩 및 문서 수 확인\n",
        "- 이 실습에서는 설정한 PDF 로더를 사용하여 PDF 파일을 로드하고, 로드된 문서의 수를 확인합니다. loader.load() 메서드를 호출하여 PDF 파일의 내용을 읽어오고, len() 함수를 사용하여 읽어온 문서의 수를 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-h2cyWWQKX4",
        "outputId": "79ff0d5f-c24d-45d2-8118-f77ac0d5cc03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# PDF 로더\n",
        "docs = loader.load()\n",
        "\n",
        "# 로드된 문서의 수 확인\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ygzZqxyQKX5"
      },
      "source": [
        "- PDF 파일을 로드하고, 로드된 문서의 수를 확인하는 과정을 실습합니다. 이는 문서 데이터 처리의 두 번째 단계로, 읽어온 내용을 효과적으로 관리하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ux77RIZQKX5"
      },
      "source": [
        "## 08-049 첫 번째 문서 확인\n",
        "- 이 실습에서는 로드한 PDF 문서 중 첫 번째 문서의 내용을 확인합니다. docs 리스트의 첫 번째 요소를 출력하여 해당 문서의 정보를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG7NyncWQKX5",
        "outputId": "12ce4e7a-9ea7-4761-920b-19f290108363"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 0}, page_content='온디바이스 AI \\n기술동향 및 발전방향ISSUE \\nREPORT \\n2024-06호\\n')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 첫번째 문서 확인\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3jnMvQTQKX6"
      },
      "source": [
        "- 로드된 PDF 파일의 첫 번째 문서를 확인하는 과정을 실습합니다. 이는 문서의 내용을 검토하고 필요한 정보를 추출하는 데 유용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLd23w-VQKX6"
      },
      "source": [
        "## 08-050 PDF 파일을 generator 방식으로 로드\n",
        "- 이 실습에서는 PDF 파일을 generator 방식으로 로드하여 각 문서의 메타데이터를 출력합니다. lazy_load() 메서드를 사용하여 메모리 효율적으로 문서를 로드하고, 각 문서의 메타데이터를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n4Mp_z8QKX6",
        "outputId": "78433a4f-5a06-45d8-92ec-3e2dcae58f19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 0}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 1}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 2}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 3}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 4}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 5}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 6}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 7}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 8}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 9}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 10}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 11}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 12}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 13}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 14}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 15}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 16}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 17}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 18}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 19}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 20}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 21}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 22}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 23}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 24}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 25}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 26}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 27}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 28}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 29}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 30}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 31}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 32}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 33}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 34}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 35}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 36}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 37}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 38}\n"
          ]
        }
      ],
      "source": [
        "# generator 방식으로 문서 로드\n",
        "for doc in loader.lazy_load():\n",
        "    print(doc.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7woGqSeQKX7"
      },
      "source": [
        "- PDF 파일을 generator 방식으로 로드하고 각 문서의 메타데이터를 확인하는 과정을 실습합니다. 이는 대량의 문서 데이터를 효율적으로 처리하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTAANU8YQKX7"
      },
      "source": [
        "## 08-051 PDF 파일을 Async 방식으로 로드\n",
        "- 이 실습에서는 PDF 파일을 비동기(async) 방식으로 로드합니다. aload() 메서드를 사용하여 문서를 로드하고, 이를 통해 비동기적으로 파일을 처리할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjJzantqQKX7"
      },
      "outputs": [],
      "source": [
        "# 문서를 async 방식으로 로드\n",
        "adocs = loader.aload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIiQKOvKQKX8"
      },
      "source": [
        "- PDF 파일을 비동기 방식으로 로드하는 과정을 실습합니다. 이는 문서 로딩 시 효율성을 높이고, 다른 작업과 병행하여 진행할 수 있는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0okYRQtKQKX8"
      },
      "source": [
        "## 08-052 비동기 문서 로드\n",
        "- 이 실습에서는 비동기(async) 방식으로 로드한 문서를 실제로 가져오기 위해 await 키워드를 사용합니다. 이는 비동기적으로 로드된 문서를 기다리고, 해당 문서를 사용할 수 있게 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5DsDbCFQKX8",
        "outputId": "5f56f2e4-968b-4786-c276-3cf1cbe79e02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 0}, page_content='온디바이스 AI \\n기술동향 및 발전방향ISSUE \\nREPORT \\n2024-06호\\n'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 1}, page_content='ISSUE \\nREPORT \\n2024-06호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nⅠ. 개 요 06\\nⅡ. 시장 및 기업 동향 09\\nⅢ. 핵심기술 동향 12\\nⅣ. 미래 발전방향 20 \\n 27\\n 30\\n 33\\n 35KEA NOW\\nMEMBER NEWS\\nESG TREND\\nSTATS'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 2}, page_content='DIGISIGHT\\n   2024.06  제6호Ⅰ. 개 요\\nⅡ. 시장 및 기업 동향 \\nⅢ. 핵심기술 동향 \\nⅣ. 미래 발전방향\\n  참고문헌 \\n 온디바이스 AI \\n기술동향 및 발전방향'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 3}, page_content='요 약\\n   (정의) 온디바이스 AI(On-Device AI)란 데이터를 외부 서버나 클라우드에 전송하지  \\n않고  디바이스 자체적으로 AI연산을 수행하는 기술\\n◎ \\x07 대용량\\x07데이터\\x07처리\\x07제한,\\x07개인정보\\x07유출\\x07위험,\\x07실시간성\\x07저하\\x07등\\x07기존\\x07서버\\x07기반\\x07중앙집중형\\x07 구조의\\x07여러\\x07\\n제약사항을\\x07해결하기\\x07위해\\x07등장\\n◎ \\x07 높은\\x07컴퓨팅\\x07파워가\\x07필요한\\x07AI\\x07연산을\\x07다양한\\x07하드웨어\\x07및\\x07소프트웨어\\x07 기술을\\x07활용하여\\x07최적화\\x07된\\x07스마트폰,\\x07\\n로봇,\\x07드론\\x07등\\x07디바이스\\x07내에서\\x07AI\\x07연산\\x07수행\\n◎ \\x07 디바이스\\x07내\\x07자체\\x07AI\\x07연산을\\x07통해\\x07네트워크\\x07환경에\\x07독립적인\\x07실시간\\x07서비스,\\x07개인정보\\x07유출\\x07최소화,\\x07서버\\x07\\n운영비용\\x07절감\\x07등\\x07강점\\n◎ \\x07 NPU,\\x07AI\\x07모델\\x07최적화\\x07등\\x07고수준의\\x07하드웨어\\x07및\\x07소프트웨어\\x07기술\\x07동시\\x07요구로\\x07인해\\x07높은\\x07진입장벽\\x07존재\\n  (시장동향)  글로벌 기업 및 각국 정부 투자 가속화로 고성장 예상  \\n◎ \\x07 생성형\\x07AI\\x07및\\x07온디바이스\\x07 AI\\x07시장은\\x07전\\x07세계적으로\\x07 빅테크\\x07기업\\x07투자\\x07열풍으로\\x07급성장이\\x07예상되며,\\x07 각국\\x07\\n정부들도\\x07투자계획\\x07수립을\\x07서두르고\\x07있어\\x07향후\\x07시장\\x07확대가\\x07가속화될\\x07전망\\n◎ \\x07 미국을\\x07포함한\\x07유럽,\\x07일본,\\x07중국,\\x07대만,\\x07한국\\x07등\\x07주요\\x07국가에서\\x07디바이스\\x07중심의\\x07AI\\x07관련\\x07기술\\x07개발\\x07지원\\x07정책을\\x07\\n지속적으로\\x07발표\\n◎ \\x07 AI칩\\x07제조사들은\\x07자사\\x07칩\\x07기반\\x07생태계\\x07구축을\\x07위해\\x07데이터 ·AI모델 ·추론 ·SDK\\x07등\\x07전방위적\\x07기술\\x07지원\\n\\t -\\t\\t단순\\t하드웨어\\t드라이버\\t수준의\\t라이브러리를\\t 넘어\\tAI\\t모델\\t경량화\\t및\\t최적화\\t도구\\t등\\t생태계\\t구축을\\t위해\\t\\n다양한\\t소프트웨어\\t지원\\n   2024.06  제6호DIGISIGHT\\n04'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 4}, page_content='요 약\\n   2024.06  제6호DIGISIGHT\\n05   (기술동향) 온디바이스 AI 하드웨어부터 가속 추론 소프트웨어, 생성형AI 최적화까지 \\n폭넓은 분야에 걸쳐 기술 개발 진행\\n   (발전방향) 기술 선도 및 시장 선점을 위한 킬러 서비스 경쟁 심화 전망 및 국내 중소 \\n기업 관련 지원 확대 정책 필요\\n◎ \\x07 온디바이스\\x07 AI가\\x07향후\\x07AI\\x07시장의\\x07게임\\x07체인저\\x07역할을\\x07할\\x07것으로\\x07예상되며,\\x07 기술\\x07확보를\\x07위한\\x07M&A,\\x07인력\\x07확보,\\x07\\n킬러서비스\\x07확보\\x07등\\x07경쟁\\x07심화\\x07전망\\n\\t -\\t\\t온디바이스\\t AI\\t기술을\\t활용해\\t사용자에게\\t 혁신적인\\t경험을\\t제공하기\\t위한\\t킬러\\t서비스에\\t대한\\t경쟁\\t심화\\t\\n예상되며\\t궁극적으로\\t개인화된\\t맞춤형\\tAI\\t서비스로의\\t발전\\t기대\\n◎ \\x07 기술\\x07선도\\x07및\\x07시장\\x07선점을\\x07위해\\x07생태계\\x07확장이\\x07필요하며\\x07이를\\x07위해\\x07중소기업의\\x07 온디바이스\\x07 생성형\\x07AI\\x07시장\\x07진입\\x07\\n장벽\\x07해소를\\x07위한\\x07정책\\x07필요\\n\\t -\\t\\t온디바이스\\t AI\\t제품\\t및\\t서비스\\t개발을\\t위한\\t연구,\\t핵심\\t인력\\t양성·재직자\\t 역량\\t강화\\t교육,\\t서비스\\t사례\\t확보를\\t\\n위한\\t실증\\t지원\\t필요하드웨어•\\x07\\x07 엔비디아는\\x07 GPU의\\x07효율성을\\x07지속적으로\\x07 향상시키고\\x07 있으며,\\x07구글,\\x07테슬라,\\x07애플\\x07등\\x07디바\\n이스\\x07제조사에서는\\x07NPU를\\x07개발하여\\x07자사\\x07서비스에\\x07적용\\n•  퀄컴,\\x07AMD\\x07등\\x07글로벌\\x07칩\\x07제조사에서는\\x07 고효율의\\x07범용\\x07NPU를\\x07지속적으로\\x07 개발하고\\x07있으며,\\x07\\n최근에는\\x07생성형\\x07AI\\x07지원\\x07NPU를\\x07경쟁적으로\\x07출시\\n•  국내\\x07대기업에서는\\x07 NPU를\\x07상용화하여\\x07 자사\\x07제품에\\x07사용\\x07중이며,\\x07NPU\\x07관련\\x07스타트업\\n에서는\\x07검증\\x07단계를\\x07넘어\\x07양산\\x07단계로\\x07진입\\n소프트웨어•  범용적인\\x07환경에서\\x07동작이\\x07필요한\\x07온디바이스\\x07 AI\\x07연산\\x07처리\\x07소프트웨어\\x07 개발은\\x07기술적\\x07\\n난이도가\\x07높고\\x07인프라적\\x07성격이\\x07강해\\x07글로벌\\x07대기업이\\x07생태계\\x07구축의\\x07일환으로\\x07기술\\x07선도\\x07\\n•\\x07\\x07 국내에서는\\x07대기업\\x07중심으로\\x07자사\\x07제품에\\x07활용\\x07가능한\\x07최적\\x07AI\\x07추론\\x07기술\\x07개발\\n생성형AI• \\x07 미국\\x07OpenAI가\\x07 전\\x07세계\\x07생성형\\x07AI\\x07기술을\\x07주도하고\\x07있는\\x07한편\\x07메타,\\x07애플,\\x07테슬라\\x07등\\x07여러 \\n기업들이\\x07온디바이스에서\\x07생성형\\x07AI\\x07지원을\\x07위해\\x07기술\\x07개발\\x07추진\\n•  국내에서는\\x07 대기업에서\\x07 한국어\\x07특화\\x07생성형\\x07AI\\x07개발\\x07및\\x07경량화를\\x07진행\\x07중이며,\\x07자사\\x07제품이  \\n적용을\\x07목표로\\x07기술개발\\x07진행'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 5}, page_content='06\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATSⅠ. 개 요\\n1개념정의\\n◎ \\x07 높은\\x07컴퓨팅\\x07파워가\\x07필요한\\x07AI\\x07연산을\\x07다양한\\x07하드웨어\\x07및\\x07소프트웨어\\x07 기술을\\x07활용하여\\x07최적화\\x07된\\x07스마트폰,\\x07 로봇,\\x07드론\\x07\\n등\\x07디바이스\\x07내에서\\x07AI\\x07연산\\x07수행\\n\\t -\\t\\t저전력으로\\t AI\\t연산\\t수행을\\t위해\\t최적화된\\t지능형\\t반도체\\tNPU(Neural\\t Unit)*와\\tAI\\t모델\\t경량화를\\t위한\\t양자화,\\tAI\\t\\n모델\\t추론\\t가속을\\t위한\\tTensorFlow\\tLite\\t등\\t다양한\\t기술\\t활용\\n*\\t\\t기존\\tAI\\t네트워크\\t연산에\\t사용되던\\tGPU와\\t유사한\\t구조나\\tAI\\t기술에\\t특화해\\t연산\\t혹은\\t에너지\\t효율을\\t높여\\t개발한\\t칩\\n\\t -\\t\\t일반적으로\\t온디바이스\\tAI는\\t추론에\\t집중되어\\t있으며\\t연산량이\\t훨씬\\t높은\\t모델\\t학습은\\t서버에서\\t진행온디바이스 AI(On-Device AI) 란 데이터를 외부 서버나 클라우드에 전송하지 않고 디바이스 자체적으로 AI\\n연산을 수행하는 기술을 의미\\n온디바이스 AI 기술 정의 \\n서버\\n사용자 사용자 디바이스 디바이스데이터 AI\\x07연산\\n결과\\n데이터\\x07입력 데이터\\x07입력\\nAI\\x07연산\\x07결과 AI\\x07연산\\x07결과대용량 AI 모델\\nNPU 등 지능형 반도체 탑재\\n추론 가속 엔진 탑재경량화된 AI 모델 탑재고성능 컴퓨팅 환경\\n클라우드 인프라AS-IS   중앙집중형 AI TO-BE   온디바이스 AI'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 6}, page_content='07\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS2등장배경\\n◎  딥러닝\\x07기반\\x07AI\\x07연산은\\x07태생적으로\\x07높은\\x07연산량이\\x07필요\\n\\t -\\t\\t딥러닝\\t모델은\\t매우\\t많은\\t양의\\t학습\\t데이터를\\t학습하여\\t높은\\t정확도의\\t예측을\\t수행하기\\t위해\\t수많은\\t노드와\\t깊은\\t\\n레이어로\\t구성된\\t거대한\\t네트워크\\t구조\\n\\t -\\t\\t학습\\t뿐\\t아니라\\t추론\\t과정에도\\t높은\\t연산량이\\t요구됨에\\t따라\\t고성능\\t서버\\t중심의\\t중앙집중형\\t AI\\t서비스\\t구조가\\t보편화\\n◎  디바이스\\x07및\\x07AI\\x07기술\\x07수준의\\x07발달로\\x07인해\\x07기존\\x07서버\\x07중심의\\x07중앙집중형\\x07구조에서\\x07다양한\\x07제약사항\\x07발생\\n\\t -\\t\\t디바이스의\\t 역할이\\t단순한\\t센싱,\\t통신\\t등에\\t국한된\\t환경에서는\\t 디바이스가\\t 생산하는\\t데이터의\\t크기가\\t제한적이어서 \\t\\n일반적으로\\t서버로\\t모든\\t데이터를\\t송신한\\t다음,\\t서버에서\\tAI\\t연산을\\t수행하는\\t구조\\t가능\\n\\t -\\t\\t디바이스\\t및\\tAI\\t기술\\t발달로\\t인해\\t대용량\\t데이터\\t처리,\\t개인정보\\t유출\\t방지,\\t실시간\\t서비스\\t등의\\t요구사항이\\t 발생하면서 \\t\\n기존\\t서버\\t기반\\t중앙집중형\\t구조에서\\t여러\\t제약사항\\t발생\\n   •  (고해상도 데이터 처리 제한) 고성능\\t디바이스\\t수가\\t증가함에\\t따라\\t대용량\\t데이터\\t처리\\t시\\t네트워크와\\t 클라우드\\t등에\\t\\n부하가\\t증가하여\\t서비스\\t품질\\t저하\\t및\\t통신 ·서버\\t등\\t서비스\\t초기\\t구축\\t및\\t유지관리\\t비용\\t증가\\n   •  (개인정보 유출 우려) 영상,\\t음성,\\t텍스트\\t등\\t민감\\t정보가\\t서버로\\t전송되므로\\t개인정보\\t남 ·오용\\t우려\\n   •  (실시간성 저하) 데이터\\t전송\\t및\\t처리\\t결과\\t수신으로\\t인한\\t지연이\\t발생해\\t실시간\\t서비스가\\t힘들며\\t네트워크\\t연결\\t환경\\t강제\\n◎  이를\\x07해결하기\\x07위한\\x07대안으로\\x07온디바이스\\x07AI\\x07기술의\\x07등장\\n\\t -\\t\\t이전부터\\t“엣지\\tAI”라는\\t용어로\\t디바이스\\t뿐만\\t아니라\\t분산\\t컴퓨팅\\t환경의\\t엣지\\t서버\\t엣지\\t게이트웨이\\t 등\\t컴퓨팅\\t\\n리소스가\\t제한된\\t환경에서\\tAI\\t연산\\t수행에\\t대한\\t연구\\t진행온디바이스 AI 기술의 필요성\\n디바이스 및 AI 기술 발달로 인한 환경 변화\\n고해상도 대용량 데이터 처리 필요\\n•\\t\\t4K\\t카메라,\\tLiDAR\\t등\\t고해상도\\t센서를\\t탑재한 \\t\\n고성능\\t디바\\t이스\\t보급\\n•\\t\\t고성능\\t디바이스가\\t대규모로\\t운용되어\\t통신망\\t및 \\t\\n클라우드\\t과부화\\t문제가\\t발생하는\\t인프라\\t환경\\t등장\\n(스마트시티\\t등)\\n개인정보 유출 우려\\n•\\t\\tCCTV,\\t전자도어락\\t등\\t민감정보가\\t많이\\t존재하는 \\t\\n스마트홈\\t등\\t개인\\t프라이버시\\t환경\\n•\\t\\t개인정보\\t유출\\t방지를\\t위해\\t클라우드\\t개입을 \\t\\n최소화하는\\t디바이스\\t내\\t자체\\t서비스\\t수행\\t필요\\n실시간 서비스 요구\\n•\\t\\tAI\\t서비스가\\t보편화됨에\\t따라\\t사용자에게\\t보다 \\t\\n즉각적인\\t서비스\\t결과\\t제공\\t필요\\n•\\t\\t스마트폰,\\t드론,\\t로봇,\\t자율차\\t등의\\t디바이스 \\t\\n환경에서\\t실시간\\t영상처리,\\t음성인식,\\t자연어처리 \\t\\n등의\\t서비스\\t요구사항\\t증대\\n“디바이스 내 자체적인 AI 연산 수행 필요 ”'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 7}, page_content='08\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS\\t -\\t\\tAI\\t연산에\\t최적화된\\tNPU의\\t등장으로\\t스마트폰,\\t 로봇,\\t드론\\t등\\t배터리\\t기반의\\t이동형\\t기기에서도\\t 자체적인\\tAI\\t연산\\t\\n수행을\\t통한\\t서비스\\t제공이\\t실현되면서\\t디바이스\\t환경에서의\\tAI\\t연산에\\t보다\\t집중한\\t온디바이스\\tAI\\t기술\\t등장\\n\\t -\\t\\t’23년\\t스마트폰에서\\t생성형\\tAI\\t서비스가\\t지원되며\\t온디바이스\\tAI\\t기술의\\t시장\\t확대\\t가속화\\n3주요특징\\n  디바이스 내 자체 AI 연산 가능\\n◎  네트워크\\x07환경에\\x07독립적인\\x07고신뢰성\\x07실시간\\x07서비스\\x07제공\\n\\t -\\t\\t외부와의\\t통신\\t없이\\tAI\\t연산\\t수행을\\t통해\\t통신\\t요청\\t및\\t응답으로\\t인한\\t지연\\t없이\\t실시간\\t서비스\\t제공\\n\\t -\\t\\t네트워크\\t환경에\\t따라\\t서비스의\\t품질이\\t좌우되지\\t않는\\t안정적인\\t서비스\\t제공\\n◎  개인정보\\x07유출\\x07위험\\x07최소화를\\x07통한\\x07사용자\\x07만족도\\x07및\\x07서비스\\x07비용\\x07절감\\n\\t -\\t\\t사용자의\\t영상,\\t음성\\t등\\t민감한\\t개인정보가\\t 서버로의\\t전송\\t없이\\t디바이스에서만\\t 처리하여\\t개인정보\\t유출\\t위험이\\t\\n낮아지며\\t이에\\t따라\\t사용자의\\t불안감\\t최소화\\n\\t -\\t\\t디바이스와\\t 서버\\t간\\t개인정보\\t통신이\\t없어\\t데이터\\t전송에\\t대한\\t암호화,\\t보안\\t등이\\t불필요하여\\t AI\\t서비스\\t구축\\t및\\t\\n유지관리를\\t위한\\t비용\\t절감\\n◎  서버\\x07의존성\\x07탈피로\\x07인한\\x07경제적인\\x07AI\\x07서비스\\x07제공\\n\\t -\\t\\t수많은\\t사용자의\\tAI\\t연산\\t수행을\\t서버에서\\t감당하기\\t위해\\t높은\\t비용의\\t클라우드\\t컴퓨팅\\t시스템을\\t운영하는\\t대신\\t\\n디바이스에서\\tAI\\t연산을\\t각자\\t수행하여\\t비용\\t절감\\t가능\\n  고수준의 하드웨어 및 소프트웨어 기술\\n◎  NPU\\x07기반\\x07하드웨어\\x07구성\\x07및\\x07활용을\\x07위한\\x07다양한\\x07애로사항\\x07존재\\n\\t -\\t\\t디바이스\\tAI를\\t위한\\t하드웨어\\t개발을\\t위해\\t저전력·저비용의\\t NPU\\t기반\\t디바이스\\t구성이\\t필요하나,\\t NPU\\t시장의\\t\\n성숙도가\\t높지\\t않아\\t중소기업이\\tNPU\\t기반\\t디바이스를\\t상용화\\t수준으로\\t개발하는데\\t많은\\t난관\\t존재\\n\\t -\\t\\t일반적으로\\t AI\\t서비스를\\t위해\\t사용하는\\t딥러닝\\t모델은\\tGPU\\t기반으로\\t개발되어\\t있어\\t이를\\tNPU에서\\t 활용하기\\t\\n위해서는\\t모델과\\tNPU의\\t특성에\\t대한\\t이해를\\t기반으로\\t하는\\t고난이도\\t이식\\t작업\\t필요\\n◎  AI\\x07모델\\x07경량화를\\x07통해\\x07정확도와\\x07효율성\\x07간\\x07최적화\\x07필요\\n\\t -\\t\\t높은\\t정확도의\\t딥러닝\\t모델을\\t디바이스\\t자원만으로\\t 동작하기\\t위해서는\\t모델의\\t입력\\t데이터\\t크기를\\t줄이거나\\t모델\\t\\n자체의\\t크기를\\t줄이는\\t등\\t경량화가\\t필요하나,\\t이는\\t정확도의\\t저하를\\t동반\\n\\t -\\t\\t최소한의\\t정확도\\t손실로\\tAI\\t모델을\\t최대한\\t경량화하기\\t위해\\t고수준의\\t최적화\\t필요'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 8}, page_content='09\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATSⅡ. 시장 및 기업 동향\\n1글로벌 시장\\n◎  생성형\\x07AI\\x07및\\x07온디바이스\\x07 AI\\x07시장은\\x07전\\x07세계적으로\\x07 빅테크\\x07기업\\x07투자\\x07열풍으로\\x07급성장이\\x07예상,\\x07각국\\x07정부들도\\x07투자계획\\x07\\n수립을\\x07서두르고\\x07있어\\x07향후\\x07시장\\x07확대가\\x07가속화될\\x07것으로\\x07예상\\n\\t -\\t\\t디바이스\\tAI\\t시장은\\t스마트폰,\\t자동차,\\t드론\\t등\\t다양한\\t기기에\\t탑재되어\\t신산업을\\t이끄는\\t차세대\\tAI\\t시장으로\\t주목되어\\t\\n’24년\\t271억\\t달러\\t규모에서\\t’30년\\t1,738억\\t달러로\\t연평균\\t37.7%\\t성장\\t전망\\n -  온디바이스\\t AI\\t시장을\\t열고\\t있는\\t생성형\\tAI\\t스마트폰\\t시장\\t규모는\\t’27년\\t5억\\t2,200만대로\\t 추산되며,\\t ’24년부터\\t ’27년\\t\\n까지\\t연평균\\t성장률은\\t83%에\\t이르는\\t고성장\\t전망온디바이스 AI 시장 규모(달러)\\n*\\t출처\\t:\\t마켓츠앤마켓츠(’23)184억\\n7,900만271억\\n3,800만383억\\n4,200만526억\\n9,100만718억\\n5,600만972억\\n2,700만1,360억\\n1,000만1,738억\\n7,900만\\n연 평균\\n37.7%  성장\\n2023년 2024년 2025년 2026년 2027년 2028년 2029년 2030년\\n생성형 AI 스마트폰 시장 규모(백만대, %)\\n*\\t출처\\t:\\t카운터포인트리서치(’23)FORECAST2023년 2024년 2025년CAGR Volume Growth\\nFrom 2023 to 2027\\n47 Mn522 Mn\\n2026년 2027년83%Share of GenAI Smartphones,\\nGlobal Smartphone Market\\n2027년\\n2024년\\n2023년40%\\n8%\\n4%\\n'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 9}, page_content='10\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS\\t -\\t\\t글로벌\\t생성형\\tAI\\t시장\\t규모는\\t’22~’32년에\\t 연평균\\t42%\\t고성장,\\t’32년의\\t시장\\t규모는\\t1조\\t3,040억\\t달러로\\t’22년\\t\\n대비\\t30배\\t이상\\t성장\\t전망\\n2국가별 정책\\n◎  미국을\\x07포함한\\x07주요\\x07국가에서\\x07디바이스\\x07중심의\\x07AI\\x07관련\\x07기술\\x07개발\\x07지원\\x07정책을\\x07지속적으로\\x07발표생성형 AI 시장 규모(억 달러)\\n*\\t출처\\t:\\t블룸버그인텔리전스(’23)2020년 2021년 2022년 2023년 2024년 2025년 2026년 2027년 2028년 2029년 2030년 2031년 2032년140 230 400 6701,3702,1703,0403,9905,4807,2808,97010,79013,040\\nCAGR 42%\\n국\\x07가 정책\\x07동향\\n•  미국\\x07과학기술정책국(OSTP)의\\x07「국가\\x07AI\\x07R&D\\x07전략\\x07계획」에\\x07대한\\x07’23년\\x07업데이트\\x07발표에서\\x07장기적으로\\x07투자할\\x07차세대\\x07AI\\x07분야에 \\x07\\n온디바이스\\x07시스템과\\x07같은\\x07제한된\\x07하드웨어\\x07및\\x07에너지\\x07리소스를\\x07고려하는\\x07연구분야\\x07포함(’23)\\n *\\t\\t하드웨어\\t성능\\t개선\\t및\\t리소스\\t사용\\t최적화를\\t위한\\tAI\\t시스템\\t개발과\\t에너지\\t소비를\\t비롯한\\t지속\\t가능성을\\t고려하는\\t리소스\\t중심 \\t\\nAI\\t알고리즘\\t및\\t시스템\\t고려\\n•  독일은\\x07「연방정부의\\x07인공지능\\x07전략\\x072020\\x07업데이트」에서\\x07연구지원\\x07분야로\\x07온디바이스\\x07AI\\x07기술의\\x07활용도가\\x07높은\\x07헬스케어, \\x07\\n모빌리티,\\x07에너지,\\x07농업\\x07\\x07분야에\\x07대한\\x07다양한\\x07지원\\x07정책\\x07발표(’20)\\n•  영국은\\x07「인공지능\\x0710개년\\x07국가전략\\x07계획」을\\x07통해\\x07영국AI\\x07시장\\x07트렌드를\\x07선도하는\\x07헬스케어\\x07분야\\x07온디바이스\\x07AI\\x07기술\\x07개발\\x07지원과 \\x07\\n글로벌화\\x07계획\\x07발표(’21)\\n•  경제산업성은\\x07「반도체 ·디지털\\x07산업\\x07전략」에서\\x07개인별\\x07최적화된\\x07IT\\x07디바이스\\x07시스템\\x07기반\\x07디지털\\x07기술\\x07혁신을\\x07통해\\x07경제성장을 \\x07\\n실현하기\\x07위한\\x07전략\\x07발표(’23.5)\\n•  「AI\\x07전략\\x072021」을\\x07발표하여\\x07다양한\\x07온디바이스\\x07시스템이\\x07적용될\\x07건강\\x07및\\x07의료,\\x07농업,\\x07스마트시티,\\x07제조업\\x07등\\x07다양한\\x07분야에서 \\x07\\n인공지능을\\x07도입하고\\x07상용화\\x07가속\\x07대응\\x07방안\\x07개선\\x07추진\\x07시작(’21.6)\\n•  국산\\x07AI\\x07반도체를\\x07기반으로\\x07초기시장\\x07단계인\\x07온디바이스AI\\x07시장\\x07선점을\\x07위한\\x07「(가칭)온디바이스AI\\x07활성화\\x07전략(안)」\\x07계획\\x07발표\\n\\x07\\x07(과기정통부,\\x07 ’24.2)\\n•  중소벤처기업부에서\\x07LG전자\\x07등과\\x07손잡고\\x07온디바이스\\x07AI\\x07스타트업\\x07육성을\\x07위해\\x07「온디바이스(On-Device)\\x07AI\\x07초격차\\x07챌린지」 \\x07\\n출범식\\x07개최( ’24.3)\\n•  NPU\\x07고도화,\\x07PIM ·뉴로모픽\\x07혁신,\\x07신소자\\x07및\\x07첨단패키징\\x07등에\\x07기반한\\x07저전력\\x07AI반도체로\\x07클라우드\\x07AI데이터센터\\x07고도화, \\x07\\n온디바이스\\x07AI\\x07신격차\\x07확보\\x07전략을\\x07포함하는\\x07「AI·디지털\\x07혁신성장\\x07전략」\\x07발표(과기정통부,\\x07 ’24.4)\\n미국\\n유럽연합\\n한국\\n일본'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 10}, page_content='11\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS3국가별 정책\\n◎  자사\\x07AI\\x07칩\\x07기반의\\x07생태계\\x07구축을\\x07위해\\x07데이터·AI\\x07모델·추론기술·SDK*를\\x07아우르는\\x07전방위적 \\x07기술\\x07지원\\n     *\\t\\t소프트웨어를\\t개발하는\\t도구로\\t소프트웨어\\t개발자가\\t특정\\t운영체제용\\t응용프로그램을\\t만들\\t수\\t있는\\t소스와\\t도구\\t패키지\\n◎  (애플) 자사의\\x07하드웨어\\x07환경에서\\x07애플의\\x07뉴럴\\x07엔진을\\x07활용하여\\x07온디바이스\\x07 AI를\\x07수행할\\x07수\\x07있도록\\x07Core\\x07ML\\x07라이브러리\\x07 제공\\n\\t -\\t\\t이\\t라이브러리는\\t 이미지,\\t비디오,\\t사운드\\t등\\t미디어\\t분석을\\t위해\\t설계된\\t첨단\\t신경망과\\t같은\\tAI모델을\\t지원하며,\\t\\nTensorFlow나\\tPyTorch와\\t같은\\t라이브러리의\\t모델을\\tCore\\tML로\\t변환하는\\t기능도\\t제공\\n◎  (퀄컴) 자사\\x07스냅드래곤\\x07 AP에서\\x07효율적인\\x07AI\\x07연산\\x07수행을\\x07위한\\x07라이브러리와\\x07 하드웨어·소프트웨어\\x07 환경에\\x07맞게\\x07사전\\x07\\n학습된\\x07AI\\x07모델을\\x07제공하는\\x07AI\\x07Hub\\x07제공\\n\\t -\\t\\tAI\\tHub는\\t개발자가\\tAI\\t연산을\\t수행할\\t환경을\\t선택하면\\t이에\\t따라\\t기\\t학습된\\t75여\\t가지의\\t인기\\t있는\\tAI\\t및\\t생성형\\tAI\\t\\n모델을\\t제공하여\\t손쉬운\\tAI\\t서비스\\t구축\\t지원\\n◎  (AMD) 자사\\x07칩셋에\\x07최적화된\\x07AI\\x07연산\\x07추론\\x07라이브러리\\x07 ZenDNN과\\x07 AI\\x07모델의\\x07생성부터\\x07최적화,\\x07추론\\x07가속까지\\x07전과정을\\x07\\n지원하는\\x07Vitis\\x07AI\\x07플랫폼\\x07제공\\n\\t -\\t\\tVitis\\tAI\\t플랫폼은\\tAI\\t모델\\t경량화\\t뿐만\\t아니라\\t프로파일러를\\t 통해\\t모델의\\t특성을\\t분석하고\\t최적화를\\t할\\t수\\t있는\\t도구를\\t\\n제공하며,\\t기\\t학습된\\tAI\\t모델\\t또한\\t지원\\n◎  (인텔) 자사\\x07칩셋에서\\x07AI\\x07연산을\\x07최대한\\x07효율적으로\\x07 수행하기\\x07위해\\x07OpenVINO\\x07 프로젝트를\\x07 출시했으며,\\x07 개발자를\\x07위한\\x07\\nEdge\\x07AI\\x07Reference\\x07Kits를\\x07오픈소스로\\x07제공\\n -  기\\t학습된\\t모델부터\\t직접\\t모델을\\t개발할\\t수\\t있도록\\t최적화\\t도구\\t일체를\\t제공하며,\\t자사\\t칩셋\\t환경에서의\\t 추론\\t가속\\t엔진\\t지원\\n◎  (엔비디아) AI\\x07모델\\x07경량화를\\x07위한\\x07Tensor\\x07RT\\x07외\\x07AI\\x07연산을\\x07위해\\x07필요한\\x07도구\\x07일체\\x07지원을\\x07통해\\x07성공적으로\\x07 생태계\\x07구축\\n\\t -\\t\\t’18년부터\\t 엔비디아는\\t 생태계\\t확장\\t및\\t기술개발\\t참여\\t유도를\\t위해\\tAI\\t추론\\t가속기\\tHW\\t및\\tSW\\t아키텍처를\\t NVDLA\\t\\n(NVIDIA\\tDeep\\tLearning\\tAccelerator)라는\\t오픈소스로\\t공유\\n◎  이\\x07외\\x07헤일로,\\x07딥엑스,\\x07모빌린트,\\x07 크네론\\x07등\\x07NPU\\x07제조\\x07스타트업도\\x07 단순히\\x07하드웨어\\x07드라이버\\x07수준의\\x07라이브러리를\\x07 넘어\\x07\\nAI\\x07모델\\x07경량화\\x07및\\x07최적화\\x07도구\\x07등\\x07생태계\\x07구축을\\x07위해\\x07다양한\\x07소프트웨어\\x07지원국\\x07가 정책\\x07동향\\n•  「중공중앙\\x07국민경제사회발전\\x07제14차\\x075개년\\x07규획(2021~2025)」과\\x07’35년\\x07장기목표에\\x07대한\\x07초안에서\\x07차세대\\x07IT\\x07산업의\\x07세부산업 \\x07\\n육성\\x07전략에\\x07AI\\x07분야에서\\x07스마트\\x07의료장비,\\x07스마트\\x07인식\\x07시스템\\x07등\\x07온디바이스\\x07AI\\x07기술이\\x07필요한\\x07산업\\x07분야를\\x07선정\\x07( ’21.3)\\n•  국가과학기술위원회(NSTC)는\\x07자국에\\x07특화된\\x07AI\\x07언어모델\\x07TAIDE\\x07개발\\x07프로젝트에\\x07온디바이스\\x07환경에서\\x07동작\\x07가능한\\x07작은\\x07모델 \\x07\\n개발\\x07계획이\\x07포함됨을\\x07발표\\x07( ’24.1)\\n중국\\n대만'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 11}, page_content='12\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATSⅢ. 핵심 기술 동향\\n1기술 개요\\n◎  하드웨어부터\\x07AI\\x07모델까지\\x07폭넓은\\x07분야에\\x07걸쳐\\x07기술\\x07개발\\x07진행\\n◎  (온디바이스 AI 하드웨어) AI\\x07연산에\\x07최적화된\\x07지능형\\x07반도체인\\x07NPU와\\x07사람의\\x07뇌\\x07구조를\\x07모사한\\x07뉴로모픽\\x07칩이\\x07대표\\x07기술\\n -  NPU는\\tGPU와\\t유사한\\t병렬연산에\\t 최적화\\t된\\t반도체이나,\\t 그래픽\\t등\\t일반적인\\t연산\\t타겟의\\tGPU와\\t달리\\tAI\\t연산만을\\t\\n위해\\t설계되어\\t효율성은\\t높으나\\tGPU\\t대비\\t유연성은\\t부족\\n -  뉴로모픽\\t칩은\\t행렬\\t연산\\t기반의\\t딥러닝\\t모델과는\\t달리\\t인간의\\t뇌와\\t유사한\\t스파이킹\\t뉴런\\t모델과\\t시냅스\\t모델로\\t\\n동작하며,\\tGPU\\t및\\tNPU보다\\t전력\\t소모량이\\t매우\\t적을\\t것으로\\t기대되나\\t아직\\t상용화\\t수준에는\\t미도달\\n◎  (온디바이스 AI 소프트웨어) 제한된\\x07리소스\\x07내\\x07AI\\x07모델을\\x07최대한\\x07효율적으로\\x07 동작시키기\\x07 위해\\x07하드웨어·운영체제\\x07 등\\x07\\n시스템\\x07레벨의\\x07AI\\x07연산\\x07엔진\\n -  대표적으로\\t구글의\\tTensorFlow\\tLite가\\t있으며,\\t기술\\t난이도가\\t높아\\t글로벌\\t대기업\\t위주로\\t기술\\t개발\\n◎  (온디바이스 AI 모델) AI\\x07모델의\\x07필요\\x07없는\\x07파라미터를\\x07 제거하는\\x07프루닝,\\x07데이터\\x07해상도를\\x07낮추는\\x07양자화\\x07등\\x07다양한\\x07\\n기술을\\x07통해\\x07온디바이스\\x07환경에서\\x07동작\\x07가능한\\x07수준의\\x07경량화된\\x07딥러닝\\x07모델\\n온디바이스 AI 기술 분야\\nLightweight AI Model AI Inference SW\\nNeuromorphic Chip\\nNPUPruning Arm NN Framework NVIDIA Tensor RT\\nNepes NM500\\nGoogle Edge TPU Samsung Exynos APQualcomm ZerothGoogle TensorFlowLite Binarization\\nOn-Device AI Model\\nOn-Device AI SW\\nOn-Device AI HW'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 12}, page_content='13\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS2하드웨어 기술\\n  해 외\\n◎  엔비디아는\\x07 GPU의\\x07효율성을\\x07지속적으로\\x07 향상시키고\\x07 있으며,\\x07구글,\\x07테슬라,\\x07애플\\x07등\\x07디바이스\\x07제조사에서는\\x07 NPU를\\x07\\n개발하여\\x07자사\\x07서비스에\\x07적용\\n◎  퀄컴,\\x07AMD\\x07등\\x07칩\\x07제조사에서는\\x07 고효율의\\x07범용\\x07NPU를\\x07지속적으로\\x07 개발하고\\x07있으며,\\x07최근에는\\x07생성형\\x07AI\\x07지원\\x07NPU를\\x07\\n경쟁적으로\\x07출시\\n기업명 기술\\x07동향\\n•  임베디드\\x07환경에서의\\x07온디바이스\\x07AI를\\x07위한\\x07Jetson\\x07Orin\\x07시리즈는\\x07다성능의\\x07디바이스를\\x07지원 \\x07\\n하기\\x07위해\\x0720\\x07TOPS\\x07성능의\\x07Nano부터\\x07200\\x07TOPS\\x07성능의\\x07AGX까지\\x073단계\\x07성능의\\x07솔루션\\x07출시\\n•  얼굴인식,\\x07음성인식으로\\x07대표되는\\x07자사의\\x07AI\\x07서비스\\x07품질\\x07향상을\\x07위해\\x07뉴럴엔진이라는\\x07NPU를  \\n독자적으로\\x07 개발하여\\x07AP(Application\\x07 Processor)와\\x07 통합된\\x07형태로\\x07제품을\\x07출시해\\x07왔으며,\\x07 ’23년\\x07\\nA17\\x07Pro에\\x07탑재된\\x077세대\\x07뉴럴엔진에서는\\x07전작\\x07대비\\x07약\\x072배\\x07성능을\\x07향상시켜\\x0735\\x07TOPS\\x07달성\\n•  서버\\x07환경에서의\\x07AI\\x07가속을\\x07위한\\x07체온\\x07프로세스\\x07등\\x07고성능\\x07CPU\\x07기술\\x07개발\\x07경험을\\x07토대로 \\x07\\n신경망\\x07프로세서\\x07및\\x07비전\\x07처리\\x07장치를\\x07개발함으로써\\x07점차적으로\\x07온디바이스AI\\x07수행을\\x07위한 \\x07\\n하드웨어\\x07기술로\\x07확장\\n•  디바이스\\x07환경에서\\x07영상처리\\x07관련\\x07AI\\x07수행에\\x07최적화된\\x07MovidiusMyraidX\\x07VPU(Vision \\x07\\nProcessing\\x07Unit)를\\x07USB\\x07기반\\x07모듈\\x07형태로\\x07만든\\x07뉴럴컴퓨트스틱2\\x07출시,\\x07‘23년에는\\x073세대 \\x07\\n3700VC\\x07VPU를\\x07출시했으며,\\x07VPU가\\x07내장된\\x0714세대\\x07CPU\\x07메테오레이크\\x07공개\\n•  저전력\\x07프로세서\\x07기반\\x07AI\\x07연산을\\x07위한\\x07Edge\\x07TPU\\x07(Tensor\\x07Processing\\x07Unit)를\\x07출시했으며, \\x07\\nUSB\\x07및\\x07PCIe/M.2\\x07형태의\\x07HW를\\x07제공하여\\x07라즈베리파이,\\x07아두이노와같은\\x07IoT\\x07기기에서의 \\x07\\nAI\\x07추론을\\x07간편한\\x07형태로\\x07지원\\n•  ’18년\\x07스냅드래곤855부터\\x07전용\\x07텐서가속기가\\x07hexagon\\x07DSP에\\x07탑재,\\x07최근\\x07hexagon\\x07DSP \\x07\\n대신\\x07hexagon\\x07NPU라고\\x07명칭을\\x07변경하여\\x07AI\\x07가속에\\x07집중\\n•  온디바이스AI를\\x07위한\\x07microNPU제품군\\x07개발,\\x07클라우드부터\\x07엣지에서\\x07사용가능한\\x07고\\x07사양의 \\x07\\nEthos-N\\x07시리즈와\\x07디바이스에서\\x07사용\\x07가능한\\x07저전력의\\x07Ethos-U\\x07시리즈를\\x07공개했으며\\x07’24\\n년\\x07Ethos-U85\\x07출시\\n엔비디아\\n애플\\n인텔\\n구글\\n퀄컴\\nARM'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 13}, page_content='14\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS  국 내\\n◎  대기업에서는\\x07 NPU를\\x07상용화하여\\x07 자사\\x07제품에\\x07사용\\x07중이며,\\x07NPU\\x07관련\\x07스타트업에서는\\x07 검증\\x07단계를\\x07넘어\\x07양산\\x07단계로\\x07진입기업명 기술\\x07동향\\n•  로봇,\\x07드론\\x07등\\x07임베디드\\x07환경에서의\\x07AI\\x07연산\\x07수행을\\x07위해\\x07NPU와\\x07DSP를\\x07포함하는\\x07Versal\\x07AI \\x07\\nEdge\\x07시리즈\\x07출시,\\x075\\x07TOPS부터\\x07202\\x07TOPS까지\\x077단계의\\x07선택지\\x07제공\\n•  ’20년\\x0726TOPS\\x07성능의\\x07Hailo-8를,\\x07’23년에는\\x07외부\\x07메모리가\\x07필요\\x07없어\\x07구성이\\x07손쉬우며 \\x07\\n저전력으로\\x07동작하는\\x0713TOPS\\x07성능의\\x07Hailo-8L을\\x07발표,\\x07M.2,\\x07mPCIe\\x07등\\x07다양한 \\x07\\n인터페이스의\\x07엣지향\\x07NPU\\x07모듈\\x07판매\\n•  ’24년\\x07생성형\\x07AI를\\x07지원하는\\x07Hailo-10\\x07출시\\n•  자사의\\x07핵심\\x07기능인\\x07자율\\x07주행을\\x07위해\\x07NPU를\\x07탑재한\\x07자체\\x07칩인\\x07FSD\\x07칩(Full\\x07Self-Driving) \\x07\\n개발\\x07중,\\x07  ’22년\\x07향상된\\x07성능의\\x07HW4.0\\x07출시\\n•  모바일\\x07AP\\x07타겟의\\x07NPU인\\x07APU\\x07(AI\\x07Processing\\x07Unit)을\\x07지속적으로\\x07개발.\\x07’24년\\x07생성형\\x07AI \\x07\\n타겟의\\x07APU790을\\x07탑재한\\x07모바일\\x07AP\\x07디멘시티\\x079300+\\x07공개\\n•  저전력의\\x07Ara-1과\\x07생성형\\x07AI를\\x07지원하는\\x07고성능의\\x07Ara-2\\x07NPU\\x07출시,\\x07USB,\\x07M.2,\\x07PCIE\\x073\\n가지\\x07폼팩터의\\x07모듈\\x07판매\\n•  레노버와\\x07협력해\\x07소형\\x07컨텐츠\\x07제작용\\x07데스크톱\\x07씽크센터에\\x07NPU\\x07탑재\\n•  자사의\\x07다양한\\x07제품에\\x07탑재하여\\x07임베디드\\x07환경\\x07AI\\x07연산\\x07수행을\\x07위한\\x07eIQ\\x07Neutron\\x07NPU\\x07출시, \\x07\\x07\\n용도에\\x07따라\\x07다양한\\x07성능으로\\x07구성\\x07가능\\n•  MCX\\x07N\\x07MCU,\\x07i.MX\\x0795\\x07AP\\x07등이\\x07NPU를\\x07탑재한\\x07대표적인\\x07제품\\nAMD\\n헤일로\\n테슬라\\n미디어텍\\n키나라\\nNXP\\n기업명 기술\\x07동향\\n삼성전자•  NPU\\x07시장선점을\\x07위해\\x07지속적인\\x07투자를\\x07통해\\x07리딩,\\x07’18년\\x0711월\\x07공개한\\x07엑시노스9820에 \\x07\\n처음으로\\x07NPU\\x07탑재를\\x07시작으로\\x07최신\\x0720시리즈\\x07(엑시노스2100~2400)까지\\x07모두\\x07NPU\\x07탑재\\n•  최근에는\\x07차량용\\x07프로세서인\\x07엑시노스오토\\x07V920을\\x07발표하여\\x07현대자동차와\\x07협력해\\x07’25년 \\x07\\n실적용을\\x07목표로\\x07개발\\nLG전자•  가전\\x07등에서\\x07온디바이스AI를\\x07수행하도록\\x07비전\\x07관련\\x07작업\\x07가속기\\x07및\\x07음성\\x07관련\\x07작업\\x07가속기를 \\x07\\n탑재해\\x07가전에서\\x07필요한\\x07영상\\x07및\\x07음성\\x07AI\\x07분석을\\x07지원하는\\x07LG8111\\x07AI\\x07SoC\\x07솔루션\\x07개발,\\x07’23년 \\x07\\n에는\\x07신규\\x07NPU\\x07개발\\x07착수를\\x07공개해\\x07개발\\x07완료\\x07후\\x07스마트\\x07TV의\\x07알파10\\x07칩에\\x07적용\\x07예정\\n'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 14}, page_content='15\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS3소프트웨어 기술\\n  해 외\\n◎  범용적인\\x07환경에서\\x07동작이\\x07필요한\\x07온디바이스\\x07 AI\\x07연산\\x07처리\\x07소프트웨어\\x07 개발은\\x07기술적\\x07난이도가\\x07높고\\x07인프라적\\x07성격이\\x07\\n강해\\x07글로벌\\x07대기업이\\x07생태계\\x07구축의\\x07일환으로\\x07기술\\x07선도기업명 기술\\x07동향\\n사피온•  SKT에서\\x07분사하여\\x07데이터센터\\x07및\\x07디바이스\\x07대상\\x07NPU를\\x07개발\\x07중,\\x07’20년에\\x07데이터센터용 \\x07\\nNPU\\x07X220,\\x07’23년\\x07X330\\x07출시\\n•  ’24년\\x07디바이스\\x07및\\x07자율주행차\\x07대상\\x07X300\\x07Edge,\\x07X300\\x07Auto\\x07등\\x07출시\\x07예정\\n딥엑스•  엣지향\\x07및\\x07서버향\\x07NPU를\\x07개발하는\\x07팹리스\\x07기업으로\\x07세계\\x07최고\\x07수준의\\x07다양한\\x07신규 \\x07\\n알고리즘들을\\x07높은\\x07전성비/정확도를\\x07기반으로\\x07동작하는\\x07NPU\\x07개발을\\x07목표로\\x07함. \\x07\\n\\x07\\x07\\x07\\x07’23년\\x07DX-L1/L2/M1/H1의\\x0712\\x07TOPS부터\\x071600\\x07TOPS급의\\x074가지\\x07NPU를\\x07발표했으며, \\x07\\n’24년\\x07양산\\x07예정\\n넥스트칩•  차량,\\x07보행자,\\x07차선\\x07등을\\x07인식\\x07및\\x07검출하는\\x07프로세서로,\\x07최첨단\\x07운전자\\x07지원\\x07시스템(ADAS)향 \\x07\\n스마트\\x07센싱\\x07카메라에\\x07적합한\\x07영상기반\\x07이미지\\x07처리\\x07지원\\x07비젼프로세서\\x07개발\\n모빌린트•  가격\\x07측면에서\\x07최소\\x074배\\x07이상\\x07엔비디아\\x07제품보다\\x07뛰어난\\x07성능으로\\x07구현한다는\\x07목표를\\x07세우고 \\x07\\nARIES\\x07NPU를\\x07개발,\\x07온디바이스\\x07AI\\x07중에서도\\x07비교적\\x07큰\\x07기기,\\x07산업용\\x07로봇이나\\x07서빙\\x07로봇, \\x07\\n스마트\\x07팩토리\\x07등의\\x07시장을\\x07타깃으로\\x07MLA100,\\x07MLX-A1\\x072가지\\x07폼팩터의\\x07제품\\x07출시\\n•  ’24년\\x073월\\x07디자인하우스\\x07세미파이브와\\x07협력하여\\x07칩\\x07양산에\\x07돌입했다고\\x07발표\\n기업명 기술\\x07동향\\n•  경량\\x07딥러닝\\x07네트워크\\x07추론\\x07엔진인\\x07TensorFlow\\x07 Lite를\\x07개발해\\x07스마트폰과\\x07 같은\\x07엣지디바이스 \\x07\\n에서\\x07리소스\\x07사용을\\x07최소화하면서\\x07AI\\x07추론\\x07지원\\n•  최근\\x07생성형\\x07AI의\\x07손쉬운\\x07지원을\\x07위해\\x07MediaPipe,\\x07TensorFlow\\x07Lite,\\x07Gemini\\x07나노를 \\x07\\n포함하는\\x07엔드\\x07투\\x07엔드\\x07스택인\\x07Google\\x07AI\\x07Edge\\x07출시\\n•  수\\x07KB\\x07수준의\\x07메모리를\\x07가진\\x07MCU\\x07타겟의\\x07TensorFlow\\x07for\\x07Microcontollers를\\x07실험\\x07기능으로\\x07제공\\n•  엔비디아\\x07TensorRT는\\x07고성능\\x07딥러닝\\x07추론을\\x07위한\\x07SDK로\\x07임베디드\\x07환경에서\\x07학습된\\x07모델을 \\x07\\n기반으로\\x07실시간\\x07추론\\x07및\\x07실시간\\x07모델\\x07업데이트\\x07기능\\x07제공\\n구글\\n엔비디아'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 15}, page_content='16\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS  국 내\\n◎  대기업\\x07중심으로\\x07자사\\x07제품에\\x07활용\\x07가능한\\x07최적\\x07AI\\x07추론\\x07기술\\x07개발기업명 기술\\x07동향\\n•  자사의\\x07하드웨어에\\x07최적화하여\\x07온디바이스환경\\x07비전\\x07및\\x07AI\\x07분석을\\x07지원하는\\x07라이브러리 \\x07\\nACL(Arm\\x07Compute\\x07Library)\\x07제공\\n•  자사의\\x07Cortex-A\\x07CPU,\\x07Mail\\x07GPU,\\x07Ethos\\x07NPU에\\x07최적화된\\x07머신러닝구동을\\x07위해\\x07NN \\x07\\nFrameworks를\\x07오픈소스로\\x07제공\\n•  모바일에서\\x07자주\\x07사용되는\\x07비전\\x07분석\\x07기능을\\x07최적화한\\x07FastCV라이브러리를\\x07개발,\\x07자사 \\x07\\n스냅드래곤\\x07AP에서\\x07고효율\\x07AI\\x07모델\\x07처리를\\x07지원하는\\x07SNPE\\x07(Snapdragon\\x07Neural \\x07\\nProcessing\\x07Engine)과\\x07AI\\x07모델\\x07압축\\x07및\\x07양자화를\\x07수행하여\\x07온디바이스\\x07AI를\\x07지원하는 \\x07\\nAIMET(AI\\x07Model\\x07Efficiency\\x07Toolkit)\\x07개발\\n•  자사\\x07칩셋\\x07타겟의\\x07OpenVINO\\x07프로젝트를\\x07통해\\x07Xeon\\x07CPU부터\\x07Arm\\x07코어까지\\x07다양한 \\x07\\n디바이스\\x07환경에서\\x07AI\\x07연산을\\x07효과적으로\\x07수행하기\\x07위한\\x07OpenVINO\\x07Runtime\\x07API\\x07제공\\n•  최근\\x07생성형\\x07AI\\x07지원을\\x07위한\\x07기능\\x07추가\\nARM\\n퀄컴\\n인텔\\n기업명 기술\\x07동향\\n삼성전자•  뉴럴\\x07네트워크\\x07연산을\\x07효율적으로\\x07처리하기\\x07위한\\x07AI\\x07추론\\x07엔진인\\x07ONE(On-device\\x07Neural \\x07\\nEngine)\\x07개발,\\x07효율적인\\x07추론을\\x07위해\\x07모델\\x07컴파일을\\x07위한\\x07컴파일러와\\x07모델\\x07수행을\\x07위한 \\x07\\n런타임\\x07파트로\\x07나누어\\x07개발\\n삼성리서치•  리눅스의\\x07영상\\x07파이프라인\\x07프레임워크인\\x07GStreamer를\\x07기반으로\\x07뉴럴네트워크\\x07파이프라인 \\x07\\n프레임워크인\\x07NNStreamer를\\x07오픈소스로\\x07개발,\\x07온디바이스학습을\\x07위한\\x07NNTrainer도 \\x07\\n오픈소스로\\x07공개\\n노타•  AI\\x07하드웨어의\\x07특성에\\x07따라\\x07AI\\x07모델을\\x07경량화하는\\x07넷츠프레소\\x07솔루션\\x07출시,\\x07접근성\\x07향상을 \\x07\\n위해\\x07웹\\x07기반\\x07넷츠프레소\\x07사용\\x07지원을\\x07위한\\x07LaunchX\\x07웹\\x07어플리케이션\\x07서비스\\x07출시\\n제틱에이아이•  기존\\x07딥러닝\\x07모델을\\x07온디바이스\\x07환경에서\\x07동작할\\x07수\\x07있도록\\x07경량화\\x07도구\\x07및\\x07추론\\x07가속 \\x07\\n파이프라인을\\x07포함한\\x07제틱\\x07멜란지\\x07출시\\n'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 16}, page_content='17\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS4생성형 AI 기술\\n  해 외\\n◎  미국\\x07OpenAI가\\x07 전\\x07세계\\x07생성형\\x07AI\\x07기술을\\x07주도하고\\x07있는\\x07한편\\x07메타,\\x07애플,\\x07테슬라\\x07등\\x07여러\\x07기업들이\\x07온디바이스에서 \\x07\\n생성형\\x07AI\\x07지원을\\x07위해\\x07기술\\x07개발\\x07추진\\n기업명 기술\\x07동향\\n•  이미지를\\x07인식할\\x07수\\x07있는\\x07멀티모달\\x07지원\\x07‘ChatGPT-4’\\x07출시.\\x07이를\\x07기반으로\\x07온라인\\x07서비스인\\x07플러그인\\x07기능을\\x07추가해\\x07현재\\x07오픈\\nAI\\x07플러그인\\x07스토어에\\x071,000여\\x07개의\\x07플러그인이\\x07탑재되는\\x07등\\x07AI\\x07생태계의\\x07주력\\x07트렌드로\\x07자리\\x07잡음.\\x07최근\\x07응답\\x07속도를\\x07비약적으로 \\x07\\n향상시킨\\x07‘ChatGPT-4o’\\x07출시\\n•  현\\x07시점에서는\\x07GPT2\\x07기반\\x07모델\\x07크기\\x07500M~1G급으로\\x07약\\x0720토큰\\x07처리하는\\x07데\\x0710s\\x07정도\\x07수준의\\x07기술\\x07보유,\\x07조만간\\x07GPT\\x07모델 \\x07\\n경량화와\\x07domain\\x07specific\\x07model\\x07finetuning\\x07지원\\x07온디바이스\\x07GPT\\x07지원\\x07계획\\x07발표.\\x07‘23년\\x07메타와\\x07협력하여\\x07메타의\\x07생성형\\x07AI인 \\x07\\n거대언어모델(LLM)\\x07라마2를\\x07온디바이스에서\\x07지원하기\\x07위해\\x07최적화를\\x07수행하기로\\x07발표한\\x07후\\x07당해\\x0710월\\x07생성형\\x07AI를\\x07반도체\\x07칩에 \\x07\\n내장한\\x07‘스냅드래곤\\x078’\\x073세대\\x07발표\\n•  ’24년\\x07메타가\\x07공개한\\x07최신\\x07LLM\\x07라마3를\\x07스냅드래곤\\x07플래그십\\x07플랫폼의\\x07온디바이스\\x07환경에서\\x07동작시키기\\x07위해\\x07최적화\\x07수행\\x07계획\\x07발표\\n•  대규모\\x07AI\\x07언어\\x07모델인\\x07‘라마(LLaMa)’를\\x07공개하면서\\x07최적화를\\x07통해\\x07특정\\x07분야에\\x07한정하여\\x07작은\\x07용량으로\\x07고수준의\\x07언어\\x07처리를 \\x07\\n지원하는\\x07sLLM도\\x07함께\\x07공개,\\x07이를\\x07기반으로\\x07노트북이나\\x07휴대폰에서\\x07동작하는\\x07sLLM\\x07응용도\\x07공개\\n•  자사에서\\x07설립한\\x07AI\\x07스타트업\\x07xAI가\\x07ChatGPT와\\x07같은\\x07생성형\\x07AI\\x07‘그록(Grok)’\\x07공개\\n•  딥마인드와\\x07협력하여\\x07텍스트,\\x07오디오,\\x07이미지\\x07등을\\x07지원하는\\x07멀티모달\\x07생성형\\x07AI\\x07모델\\x07‘제미나이’를\\x07개발했으며,\\x07온디바이스\\x07AI \\x07\\n지원을\\x07위해\\x07경량화된\\x07‘제미나이\\x07나노’도\\x07함께\\x07개발\\n•  ’24년\\x07삼성전자와\\x07협력하여\\x07‘제미나이\\x07나노\\x072.0’을\\x07갤럭시\\x07S24에\\x07탑재\\n•  ’24년\\x07iOS에서\\x07개인\\x07맞춤형\\x07생성형\\x07AI를\\x07지원하는\\x07애플\\x07인텔리젼스를\\x07발표하면서\\x07자체\\x07개발\\x07생성형\\x07AI\\x07모델인\\x07‘에이잭스(Ajax)’와 \\x07\\n함께\\x07오픈\\x07AI와\\x07협력하여\\x07자사\\x07음성\\x07AI\\x07비서\\x07시리에\\x07ChatGPT-4o를\\x07접목한다고\\x07발표\\n•  단,\\x07모든\\x07처리를\\x07디바이스에서\\x07처리하는\\x07대신\\x07상황에\\x07따라\\x07강화된\\x07보안이\\x07적용된\\x07프라이빗\\x07클라우드에서\\x07AI\\x07연산\\x07수행\\x07가능\\n•  대부분의\\x07MS\\x07제품에\\x07생성형\\x07AI를\\x07결합하여\\x07‘MS365\\x07Copilot’,\\x07‘Security\\x07Copilot’\\x07등\\x07신제품\\x07출시\\x07중,\\x07’24년\\x07온디바이스\\x07AI를 \\x07\\n지원하는\\x07인공지능\\x07피씨인\\x07Copilot+\\x07PC\\x07공개\\n•  ’23년\\x07디지털\\x07솔루션\\x07기업으로\\x07퀄컴의\\x07플랫폼을\\x07기반으로\\x07자사\\x07핸드헬드\\x07모바일\\x07컴퓨터\\x07및\\x07태블릿\\x07등\\x07온디바이스\\x07환경에서 \\x07\\n클라우드와의\\x07연결\\x07없이\\x07대형언어모델\\x07및\\x07생성형\\x07AI를\\x07구현하는데\\x07성공했다고\\x07공개\\n•  자체클라우드\\x07LLM인\\x07Pangu와\\x07디바이스\\x07내\\x07AI비서인\\x07Cella가\\x07연결되며,\\x07’23년\\x078월\\x07HamonyOS\\x074에\\x07LLM을\\x07탑재할\\x07것을\\x07발표\\n•  자체\\x07LLM인\\x07AndesGPT를\\x07기반으로\\x07AI비서인\\x07Xiaobu를\\x07외부테스트를\\x07수행\\x07중이며,\\x07향후\\x07스마트폰\\x07등에\\x07탑재\\x07예정\\n오포\\n화웨이\\n지브라\\nOpenAI\\n퀄컴\\n메타\\n테슬라\\nMS\\n애플\\n구글'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 17}, page_content='18\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS  국 내\\n◎  대기업에서\\x07한국어\\x07특화\\x07생성형\\x07AI\\x07개발\\x07및\\x07경량화를\\x07진행\\x07중이며,\\x07자사\\x07제품이\\x07적용을\\x07목표로\\x07기술개발\\x07진행\\n5활용 서비스 사례\\n◎  사용자와\\x07상시\\x07연결되어\\x07즉각적인\\x07AI\\x07서비스\\x07제공이\\x07가능한\\x07모바일·웨어러블\\x07 기기를\\x07중심으로\\x07온디바이스\\x07 생성형\\x07AI를\\x07\\n탑재한\\x07제품\\x07개발\\x07및\\x07출시기업명 기술\\x07동향\\n삼성전자 •  ’23년\\x07온디바이스\\x07환경에서\\x07생성형\\x07AI\\x07서비스\\x07제공을\\x07위한\\x07’삼성\\x07가우스’를\\x07공개,\\x07’24년부터\\x07갤럭시S24\\x07등의\\x07제품에\\x07탑재\\n카카오•  한국어\\x07특화\\x07AI\\x07언어모델인\\x07‘KoGPT’를\\x07’21년\\x07공개했으며\\x07구글의\\x07텐서\\x07처리\\x07장치를\\x07활용,\\x07연산속도\\x07고도화.\\x07’24년\\x071월\\x07새\\x07언어모델 \\x07\\n‘허니비’를\\x07공개하였으며\\x07문자와\\x07이미지를\\x07동시에\\x07학습하고\\x07연산할\\x07수\\x07있는\\x07멀티모달(다중모델)\\x07기반의\\x07대규모\\x07언어모델(LLM)을 \\x07\\n오픈소스\\x07형태로\\x07구현 \\x07\\n네이버 •  블로그,\\x07카페,\\x07지식\\x07IN\\x07등\\x07자사\\x07서비스의\\x07대규모\\x07데이터를\\x07활용해\\x07한국어\\x07대용량\\x07데이터를\\x07구축한\\x07‘하이퍼\\x07클로버’를\\x07  ’21년\\x07공개\\nLG전자 •  멀티모달\\x07연산이\\x07가능한\\x07초거대\\x07AI\\x07‘EXAONE\\x072.0’\\x07공개\\nLGCNS •  대규모\\x07언어모델(LLM)을\\x07탑재한\\x07생성형\\x07AI\\x07서비스\\x07플래폼\\x07‘DAP\\x07GenAI’\\x07구축\\nLGU+•  ’24년\\x07LG\\x07AI\\x07연구원과\\x07협업해\\x07통신,\\x07플랫폼,\\x07금융\\x07등\\x07다양한\\x07분야에\\x07적용\\x07가능한\\x07생성형\\x07AI\\x07모델인\\x07‘익시젠(ixi-GEN)’개발\\x07계획 \\x07\\n공개.\\x07딥엑스와\\x07협력하여\\x07추후\\x07온디바이스\\x07환경에서도\\x07익시젠\\x07기반\\x07서비스를\\x07제공하기로\\x07발표\\nSKC&C •  네이버와\\x07협력하여\\x07‘한국형\\x07AI\\x07서비스’를\\x07공동개발하여\\x07기업\\x07맞춤형\\x07보고서\\x07제작\\x07솔루션\\x07개발\\n삼성SDS •  기업\\x07내\\x07업무\\x07생산성을\\x07높이기\\x07위한\\x07생산형\\x07AI\\x07플랫폼\\x07‘브리티\\x07코파일럿(Brity\\x07Copilot)’과\\x07‘패브릭스(Fabrix)’공개\\n적용분야 사례\\x07및\\x07주요내용\\n웨어러블\\n온디바이스         휴메인(Humane) / AI 핀\\n•  퀄컴\\x07모바일\\x07AI반도체\\x07기반\\x07생성형\\x07지능\\x07탑재한\\x07퍼스널\\x07디지털\\x07디바이스(’23.12,\\x07발표, \\x07\\n’24년\\x07국내\\x07출시\\x07예정) \\x07\\n•  생성AI\\x07탑재를\\x07통해\\x07통번역,\\x07전화\\x07송수신,\\x07건강 ·영양,\\x07사진촬영,\\x07검색,\\x07이메일\\x07요약, \\x07\\n음악재생\\x07등\\x07서비스\\x07제공\\n         틴에이저엔지니어링(TeenageEngineering) / Rabbit R1\\n•  대형\\x07액션모델\\x07기반으로\\x07휴대폰\\x07앱구동\\x07AI에이전트\\x07장치(’24.1,\\x07출시)\\n•  사용자\\x07음성을\\x07통해\\x07쇼핑,\\x07호텔\\x07예약,\\x07메시지\\x07송신\\x07등\\x07서비스\\x07제공\\n'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 18}, page_content='19\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS적용분야 사례\\x07및\\x07주요내용\\n웨어러블\\n온디바이스         메타(Meta) / 스마트 (AI) 안경\\n•  스마트안경\\x07레이밴\\x07스토리\\x07출시(’23.10\\x07발표,\\x07미출시)\\n•  메타\\x07생성형\\x07AI\\x07탑재를\\x07통해\\x07사용자\\x07시선의\\x07사물에\\x07대한\\x07실시간\\x07정보\\x07제공\\n         삼성전자 / 갤럭시링\\n•  반지\\x07형태의\\x07스마트링(’24.1\\x07발표,\\x078월\\x07출시\\x07예정)\\n•  심박수,\\x07혈압,\\x07산소포화도,\\x07수면\\x07품질\\x07등\\x07실시간\\x07측정,\\x07지능형\\x07헬스\\x07기능을\\x07통한\\x07맞춤형\\x07건강 \\x07\\n가이드\\x07제공\\n         탭AI(TabAI) / AI 펜던트\\n•  작은\\x07원형\\x07팬던트\\x07(’24.1,\\x07국내\\x07미출시)\\n•  30시간\\x07지속\\x07배터리,\\x07마이크와\\x07블루투스\\x07사용해\\x07오디오를\\x07수집\\x07및\\x07스마트\\x07폰과\\x07연동하여 \\x07\\n클라우드\\x07전송,\\x07ChatGPT를\\x07활용하여\\x07다양한\\x07통찰력\\x07제공\\n         오우라헬스(Oura Health) / 오우라링(3세대)\\n•  반지\\x07형태의\\x07스마트링(’21년말,\\x07국내\\x07미출시)\\n•  수면\\x07추적(체온,\\x07심박,\\x07심박변이\\x07등),\\x07활동\\x07추적(3D가속도를\\x07통한\\x07운동·활동\\x07모니터링\\x07등)\\x07등\\n모빌리티\\n온디바이스         유토피아(UTOPIA) / 전기자전거 퓨전(Fusion)\\n•  생성형AI\\x07연동\\x07애플\\x07디자이너와\\x07협업된\\x07제품\\x07전기자전거(’23.7,\\x07발표)\\n•  사용자\\x07음성을\\x07통한\\x07정보(수리,\\x07영양플랜,\\x07부상회복),\\x07GPS(여행경로,\\x07도난방지),\\x07건강(심박)  \\n등\\x07서비스\\x07제공\\n스마트\\n오피스·홈\\n온디바이스         플라우드 노트(PLAUD NOTE) / 플라우드 노트\\n•  ChatGPT\\x07기반의\\x07스마트\\x07레코더(’23.11,\\x07출시)\\n•  녹음(통화,\\x07일반)\\x07및\\x07녹음내용의\\x07실시간\\x07텍스트\\x07번역,\\x07\\x07요점정리,\\x07마인드맵\\x07정리,\\x07메일\\x07발송\\x07등  \\n서비스\\x07제공\\n         LG전자 / 가전\\n•  멀티모달\\x07센서와\\x07온디바이스\\x07AI\\x07적용한\\x07초개인화\\x07가전\\x07스마트\\x07홈\\x07에이전트\\x07공개(’24.1,\\x07CES)\\n•  가전용\\x07AI\\x07칩\\x07개발\\n스마트폰\\n온디바이스         삼성전자 / 갤럭시S24\\n•  삼성전자의\\x07생성형\\x07AI\\x07모델(삼성\\x07가우스)을\\x07탑재한\\x07스마트폰(’24.1,\\x07출시)\\n•  통화중\\x07실시간\\x07통역(13개국),\\x07실시간\\x07문자\\x07번역(13개국),\\x07사용자\\x07언어를\\x07통한\\x07검색,\\x07문서\\x07요약  \\n등\\x07서비스\\x07제공\\n         구글 / 픽셀8 Pro\\n•  LLM\\x07온디바이스\\x07모델(나노)를\\x07탑재한\\x07스마트폰(’23.12,\\x07출시)\\n•  생성형\\x07AI\\x07기반\\x07망연동\\x07없는\\x07녹음내용\\x07요약,\\x07대화\\x07맥락\\x07분석을\\x07통한\\x07답변\\x07제안,\\x07영상\\x07교정\\x07등  \\n서비스\\x07지원\\n'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 19}, page_content='20\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATSⅣ. 미래 발전 방향\\n1향후 전망\\n  (시장) 온디바이스 AI 기술은 AI 시장의 중심이 될 것으로 기대\\n◎  개인정보\\x07보호,\\x07안정적인\\x07실시간\\x07서비스,\\x07서버\\x07운영비용\\x07절감\\x07등\\x07온디바이스\\x07 AI의\\x07다양한\\x07강점으로\\x07인해\\x07향후\\x07AI\\x07시장의\\x07\\n게임\\x07체인저\\x07역할\\x07예상\\n -  온디바이스\\t AI\\t기술은\\t대규모\\t클라우드\\t서버\\t운영이\\t필요\\t없어\\t비용\\t절감\\t측면에서\\t혁신적인\\t기술이며,\\t 나아가\\t데이터\\t\\n센터의\\t에너지\\t소모\\t절감\\t가능\\n   •\\t\\t오픈AI는\\t’23년\\t매출이\\t2조\\t원이\\t넘었으나\\t하루\\t약\\t9억\\t원으로\\t추산되는\\t막대한\\t운영비용으로\\t수익\\t실패\\n -  글로벌\\t빅테크들은\\t경쟁적으로\\t온디바이스\\tAI\\t기술\\t실현에\\t앞장서고\\t있으며,\\t지속적인\\t투자\\t계획\\t발표\\n◎   현재\\x07온디바이스\\x07 AI\\x07분야로\\x07대표되는\\x07스마트폰\\x07외\\x07웨어러블\\x07기기,\\x07로봇,\\x07디지털\\x07헬스케어,\\x07 스마트\\x07홈\\x07등\\x07다양한\\x07산업에서\\x07\\n폭넓게\\x07활용될\\x07것으로\\x07전망\\n -  AI\\t서비스가\\t일상에\\t깊숙이\\t침투함에\\t따라\\t개인정보\\t보호에\\t대한\\t중요성은\\t나날이\\t증대\\n   •\\t\\t지능형\\t블랙박스 ·인공지능(AI)\\t 스피커 ·지능형\\tCCTV\\t등\\t일상\\t속\\tAI\\t서비스에는\\t 사용자의\\t음성,\\t영상\\t등이\\t입력\\t\\n데이터로\\t활용되며,\\t이러한\\t개인정보에\\t대한\\t보호\\t조치\\t필요\\n -  온디바이스\\tAI를\\t활용해\\t개인정보\\t보호\\t문제없이\\t사용자\\t맞춤형\\tAI\\t서비스를\\t제공할\\t수\\t있어\\t활용성\\t클\\t것으로\\t기대\\n  (업계) 기술확보를 위한 M&A 및 AI 관련 인력 확보 전쟁 심화\\n◎  미래\\x07산업으로의\\x07전환을\\x07위해\\x07전\\x07산업에서의\\x07AI분야\\x07M&A\\x07활발히\\x07진행\\n\\t -\\t\\tAI가\\t타산업의\\t발전을\\t가속화하는\\t 기반\\t기술로\\t부상하며\\t로봇,\\t헬스케어,\\t 모빌리티,\\t 게임·엔터\\t 등\\t전\\t산업에\\t적용되고\\t\\n영향력\\t확대됨에\\t따라\\tAI를\\t중심으로\\t기술\\t융합과\\t혁신\\t진행\\n     *\\t\\t최초\\t보급\\t후\\t10년차\\t침투율(PWC·Bessemer\\tVC,\\t%)\\t:\\t(생성형AI)66,\\t(스마트폰)55,\\t(SW\\t내\\t클라우드)31'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 20}, page_content='21\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS\\t -\\t\\t경기\\t불확실성에도\\t첨단기술인\\tAI(온디바이스AI,\\t메타버스\\t기술\\t및\\t하드웨어)에\\t대한\\t투자에\\t집중해\\t미래\\t산업\\t대응\\n   •\\t\\t(테크)\\t온디바이스\\tAI,\\t메타버스,\\t하드웨어\\t등\\tAI\\t관련\\t기술\\t확보를\\t위한\\tM&A\\t진행\\n   •\\t\\t(통신)\\t데이터센터,\\t AI,\\t로봇,\\t클라우드\\t등\\t미래\\t기술에\\t대한\\t투자\\t지속\\t및\\t디지털화·커넥티드\\t 역량\\t확보를\\t위해\\t\\n소프트웨어,\\t모빌리티,\\t기계\\t업종\\t등과의\\t제휴\\t증가\\n   •\\t\\t(미디어)\\t빅테크의\\t파운데이션\\t개발\\t투자,\\t스타트업\\t지분\\t투자·M&A\\t통해\\t생성형\\tAI\\t기반\\t다양한\\t수익모델\\t시도\\n◎   AI관련\\x07핵심\\x07인재\\x07확보를\\x07위한\\x07빅테크\\x07기업\\x07간\\x07경쟁\\x07심화\\n -  OpenAI,\\t구글,\\tMS,\\t애플,\\t메타\\t등\\t빅테크\\t기업들은\\tAI\\t인력에게\\t연봉,\\t스톡옵션\\t등\\t막대한\\t조건을\\t제시하여\\t공격적인\\t\\n영입\\t제시하며\\tAI\\t인재\\t확보에\\t총력\\n     *\\t\\t글로벌\\t빅테크\\tAI\\t연구원(‘23년\\t신규\\t박사급\\tAI\\t연구원\\t기준)\\t초봉(한국경제·로라,\\t만\\t달러) \\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t:\\t(오픈AI)86.5,\\t(엔스로픽)85.5,\\t(인플렉션AI)82.5,\\t(테슬라)78,\\t(아마존)71.9,\\t(구글브레인)69.5 \\t산업별 AI 영향도\\n산업 영향도\\n로봇 •  AI\\x07접목된\\x07로봇은\\x07최종적으로는\\x07인간의\\x07개입을\\x07필요로\\x07하지\\x07않는\\x07‘무인화’\\x07로봇,\\x07즉\\x07스스로\\x07활동할\\x07수\\x07있는\\x07‘휴머노이드\\x07로봇’으로\\x07발전\\n헬스케어•  (신약개발)\\x07딥러닝을\\x07통한\\x07단백질\\x07구조\\x07해독\\x07등으로\\x07신약개발에\\x07소요되는\\x07시간\\x07획기적\\x07단축\\n•  (진단/치료)\\x07딥러닝으로\\x07환자\\x07유전자\\x07데이터를\\x07분석,\\x07대규모\\x07의료영상\\x07빠르게\\x07처리\\x07→\\x07질병\\x07판독\\x07및\\x07의료진\\x07치료결정에서\\x07불확실성\\x07감소\\n•  (예방)\\x07헬스케어\\x07기관들이\\x07보유한\\x07방대한\\x07의료\\x07데이터를\\x07활용하여,\\x07개인별\\x07질병\\x07발생\\x07확률\\x07예측\\x07&\\x07사전\\x07예방형\\x07치료\\x07제공\\n•  (서비스)\\x07헬스\\x07디바이스의\\x07 발전과\\x07함께\\x07주요\\x07건강지표들의\\x07 지속적\\x07모니터링\\x07&\\x07챗봇을\\x07통한\\x07의료상담\\x07등이\\x07가능해지면서,\\x07 원격의료\\x07본격화\\n모빌리티•  인포테인먼트·커넥티드를\\x07넘어\\x07자율주행의\\x07시대\\x07도래\\n  -\\t도로\\t주행데이터\\t축적\\t및\\tAI\\t분석능력\\t향상으로\\t완성도\\t높은\\t자율주행시스템구현\\n게임·엔터•  (개발)\\x07AI를\\x07통한\\x07코딩\\x07자동화를\\x07통해\\x07개발자들의\\x07중복되는\\x07코드\\x07작업\\x07최소화.\\x07인건비\\x07감소는\\x07기업들의\\x07제작비용을\\x07감소시켜\\x07더\\x07많은 \\x07\\n콘텐츠\\x07개발\\x07및\\x07진입\\x07장벽을\\x07낮춰\\x07신생업체들의\\x07대규모\\x07유입\\x07유도\\n•\\x07(콘텐츠)\\x07AI는\\x07메타버스와\\x07결합해\\x07게임/엔터/교육의\\x07궁극적인\\x07변화\\x07이끌\\x07전망\\n\\t\\t-\\tAI를\\t활용한\\t디자인\\t프로세스\\t간소화로\\t3D\\t부문의\\t급속한\\t발전\\t가능.\\t홀로그램\\t활성화로\\t‘가상-현실의\\t경계’가\\t모호해질\\t것으로\\t전망\\n\\t\\t-\\t메타버스\\t활성화로\\t게임/엔터/교육/광고\\t분야에\\t큰\\t수혜\\t예상\\n테크•  (하드웨어)\\x07개인\\x07IT\\x07기기(핸드폰,\\x07태블릿\\x07등)에\\x07온디바이스\\x07AI\\x07탑재되며\\x07신규\\x07수요\\x07창출\\x07및\\x07XR(확장현실)기기\\x07등\\x07신제품\\x07출시\\n•  (소프트웨어)\\x07AI\\x07모델에\\x07대한\\x07시장\\x07선점을\\x07위한\\x07글로벌\\x07기업들의\\x07개발\\x07경쟁\\x07지속\\x07및\\x07AI를\\x07활용한\\x07개인\\x07맞춤형\\x07서비스를\\x07제공할\\x07수\\x07있는 \\x07\\n어플리케이션\\x07발전\\n•  (반도체)\\x07AI\\x07반도체에\\x07대한\\x07중요성\\x07부각되며,\\x07시스템\\x07반도체\\x07부문\\x07핵심\\x07경쟁력을\\x07확보하기\\x07위한\\x07글로벌\\x07거대\\x07기업들의\\x07투자\\x07지속\\n금융•  챗봇(상담\\x07업무)를\\x07넘어서\\x07금융\\x07비서로\\x07AI\\x07업무\\x07영역\\x07확장\\n\\t\\t-\\t자연어\\t처리\\t역량이\\t음성인식과\\t맞물릴\\t경우\\t모바일\\t환경에\\t익숙하지\\t않은\\t연령층까지\\t고객군\\t확대\\t가능\\n\\t\\t-\\t단순\\t상담\\t업무\\t뿐\\t아니라\\t자산관리\\t및\\t투자\\t부분에서도\\tAI의\\t역할\\t확대\\t예상\\n*\\t출처\\t:\\tPWC( ’24)'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 21}, page_content='22\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS -  국내\\tAI\\t인력은\\t경쟁국에\\t비해\\t매우\\t부족한\\t상황으로\\t민간의\\t인재\\t유치\\t강화\\t전략\\t및\\t정부\\t맞춤\\t인재육성\\t정책\\t절실\\n     *\\t\\t’20년\\t국가별\\t글로벌\\tAI\\t전문인재\\t확보\\t현황(한국일보·엘리멘트AI,\\t%)\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t:\\t(1위)미국\\t39.4,\\t(2위)인도\\t15.9,\\t(3위)영국\\t7.4,\\t(4위)중국\\t4.6....(22위)한국\\t0.5\\n -  AI\\t반도체\\t시장\\t주도를\\t위해\\t반도체사들의\\t인력전쟁도\\t엔디비아를\\t중심으로\\t진행되어\\t국내업체에서의\\t인력\\t유출\\t심화\\n  (기술·서비스) 킬러 서비스 확보를 위한 경쟁 심화 및 개인화된 맞춤형 AI로 점진적 발전 예상\\n◎  경량\\x07생성형\\x07AI\\x07모델,\\x07NPU와\\x07같은\\x07온디바이스\\x07 AI\\x07실현을\\x07위한\\x07기반\\x07기술의\\x07성숙도가\\x07높아짐에\\x07따라\\x07이를\\x07활용해\\x07\\n사용자에게\\x07혁신적인\\x07경험을\\x07제공하기\\x07위한\\x07킬러\\x07서비스\\x07확보\\x07경쟁\\x07심화\\x07예상\\n\\t -\\t\\t온디바이스\\t AI\\t기술\\t자체는\\t이전부터\\t활용되고\\t있어\\t사용자에게\\t 새로운\\t경험\\t제공이\\t어려우며,\\t 온디바이스\\t 생성형\\tAI\\t\\n기반의\\t차별화된\\t서비스\\t개발\\t필요\\n   •\\t\\t스마트폰의\\t 파노라마\\t사진,\\t사진에서\\t객체\\t제거,\\t실시간\\t영상\\t합성\\t기능을\\t비롯해\\t블랙박스의\\t 차량\\t출발\\t감지\\t기능,\\t\\n지능형\\tCCTV의\\t객체\\t인식\\t기능\\t등\\t다양한\\t온디바이스\\tAI\\t서비스\\t기\\t보편화 \\t\\n\\t -\\t\\t사용자가\\t체감\\t가능한\\t온디바이스\\t생성형\\tAI\\t기술은\\t스마트폰\\t중심의\\t실시간\\t통역과\\t음성\\t대화의\\t텍스트\\t요약\\t수준 \\t\\n\\t -\\t\\t글로벌\\t빅테크들은\\t 스마트폰 ·AI\\tPC·웨어러블\\t기기\\t내\\t온디바이스\\t 생성형\\tAI\\t기술을\\t활용하여\\t대표\\t서비스\\t개발에\\t\\n박차를\\t가하고\\t있으며\\t‘24년\\t말부터는\\t갤럭시\\t링을\\t포함하여\\t단계적\\t출시\\t예상빅테크간 AI 및 반도체 인력 전쟁\\n(단위\\t:\\t명,\\t ’24.\\t6.\\t17\\t링크드인\\t가입자\\t기준)\\n*\\t출처\\t:\\t조선일보(’24)\\nAI 인력 이동 현황 반도체 인력 이동 현황\\n링크드인\\n가입한\\t직원수 애플\\n17만\\n3,249\\n구글\\n28만\\n6,760\\n메타\\n11만\\n9,611마이크로\\n소프트\\n22만\\n8,954삼성\\n전자\\n엔비\\n디아278515 2,848\\n544\\n12\\n89\\n159\\n3838\\n0\\n6,5771만\\n3,2383,3451,9674,219\\n6,3834,8813,066\\n2,474\\n8,880\\n2,857마이\\n크론TSMC\\nSK\\n하이닉스인텔'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 22}, page_content='23\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS◎   맞춤형\\x07AI\\x07서비스를\\x07위해서는\\x07개인의\\x07데이터를\\x07기반으로\\x07AI\\x07모델의\\x07점진적\\x07업데이트\\x07필요\\n -  현재는\\t서버에서\\t학습된\\tAI\\t모델을\\t모든\\t사용자가\\t동일하게\\t사용하고\\t있어\\t사용자\\t특성이\\t반영된\\t서비스\\t제공\\t불가\\n -  디바이스에서\\t수집한\\t사용자의\\t데이터\\t통해\\t지속적으로\\tAI\\t모델을\\t업데이트하여\\t사용자별\\t특화된\\t서비스\\t제공\\t가능\\n -  AI모델학습은\\t 추론\\t대비\\t훨씬\\t많은\\t컴퓨팅\\t자원이\\t필요해\\t온디바이스\\t 환경에서의\\t AI모델학습을\\t 위해\\t많은\\t난관\\t극복\\t필요\\n -  최근\\t서버향\\t타겟의\\tNPU에서\\t학습을\\t지원하는\\t등\\t기술\\t발전이\\t이루어지고\\t있어\\t향후\\t맞춤형\\tAI\\t서비스의\\t실현\\t기대\\n2정책 제언\\n  온디바이스 AI 시장 선점을 위해 중소기업 시장 참여를 통한 생태계 확장 필요\\n◎  국내\\x07온디바이스\\x07 생성형\\x07AI\\x07기술은\\x07저전력\\x07고효율\\x07지능형\\x07반도체\\x07개발이라는\\x07 후방\\x07산업에\\x07집중되어\\x07있고\\x07서비스는\\x07일부\\x07\\n대기업\\x07위주로만\\x07개발\\x07중으로,\\x07혁신적인\\x07서비스\\x07개발이\\x07이루어지지\\x07않아\\x07전방\\x07산업\\x07부진\\n -  삼성전자의\\t 스마트폰에\\t 중점적인\\t온디바이스\\t 시스템을\\t위한\\t기반\\t역량은\\t보유하고\\t있으나\\t폐쇄된\\t대기업\\t기술로\\t\\n중소기업과\\t역량\\t차이\\t매우\\t큼\\n◎   국내\\x07중소기업\\x07기술역량\\x07한계로\\x07높은\\x07난이도의\\x07온디바이스\\x07AI\\x07기술\\x07도입\\x07난항\\n -  ’21년\\t12월\\t말\\t기준\\t전체\\t기업체(20만\\t7,000여개)의\\tAI\\t기술\\t및\\t서비스\\t이용률은\\t2.7%로\\t매우\\t낮음 \\t\\n -  국내\\t기업\\t100곳\\t중\\t3곳만이\\tAI\\t기술을\\t도입했으며\\t AI를\\t도입한\\t기업\\t대부분은\\t대기업(91.7%).\\t 중소기업의\\t AI\\t도입\\t시\\t\\n가장\\t큰\\t걸림돌은\\t수요에\\t맞는\\tAI\\t기술\\t및\\t인력\\t부족(72.1%) \\t\\n◎   사용자\\x07수요\\x07증대를\\x07통해\\x07전방기술\\x07시장을\\x07확대하고\\x07지속적인\\x07성장을\\x07견인하기\\x07위해서\\x07다수의\\x07중소기업이\\x07 생태계에\\x07참여해\\x07\\n도전적이고\\x07참신한\\x07서비스\\x07발굴\\x07필요\\n   중소기업의 온디바이스 AI 시장 진입 장벽 해소를 위한 기술·서비스 개발, 인력양성 등 맞춤형 \\n정책지원 필요\\n◎  (기술 개발 및 연구 기반 지원) 온디바이스\\x07생성형\\x07AI\\x07제품\\x07및\\x07서비스\\x07개발을\\x07위한\\x07연구\\x07기반\\x07지원\\x07필요\\n\\t -\\t\\t온디바이스\\t 생성형\\tAI의\\t특성상\\t서비스\\t개발을\\t위해서는\\t온디바이스\\t AI\\t하드웨어부터\\t 소프트웨어\\t 및\\t경량화된\\t생성형\\t\\n모델까지\\t필요하나\\t이는\\t중소기업이\\t시장에\\t진입하는\\t것을\\t가로막는\\t주요\\t걸림돌\\n\\t -\\t\\t저전력\\t레퍼런스\\t보드,\\t개방형\\t생성형\\tAI\\t모델,\\t한국어\\t타겟\\t학습\\t데이터\\t공개\\t등\\t중소기업의\\t 기술적\\t제약을\\t해소해\\t\\n혁신적인\\t제품\\t및\\t서비스를\\t개발할\\t수\\t있도록\\t기반\\t지원\\t필요'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 23}, page_content='24\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS◎   (인력 양성 및 교육 지원) 온디바이스\\x07 AI\\x07인재\\x07부족\\x07현상을\\x07해소하기\\x07위해\\x07국가\\x07차원의\\x07인력\\x07양성\\x07및\\x07재직자\\x07역량\\x07강화를\\x07\\n위한\\x07교육\\x07지원\\x07필요\\n -  서버\\t시스템\\t지원\\tAI\\t소프트웨어\\t 및\\t하드웨어\\t인력은\\t국가의\\t전략적인\\t연구개발\\t투자\\t및\\t인력\\t양성으로\\t지속적으로\\t 증가\\n -  온디바이스\\t AI\\t소프트웨어\\t 및\\t하드웨어\\t시스템에\\t대한\\t역량을\\t가진\\t인재는\\t매우\\t부족하여\\tAI\\t및\\t임베디드\\t시스템\\t기술\\t\\n전문성이\\t융합된\\t온디바이스\\tAI\\t인력\\t양성이\\t핵심\\n -  온디바이스\\t AI\\t인재\\t풀\\t확대와\\t기술\\t수준\\t향상을\\t위해\\t대학\\t등을\\t대상으로\\t한\\t인력\\t양성\\t뿐만\\t아니라\\t중소기업\\t재직자\\t\\n대상\\t교육\\t지원\\t등\\t다각도에서\\t정책적\\t지원\\t필요\\n◎   (서비스 개발 및 실증 사업 지원) 온디바이스\\x07생성형\\x07AI\\x07적용\\x07서비스\\x07사례\\x07확보를\\x07위한\\x07실증지원\\x07절실\\n -  국내\\t중소기업은\\t AI\\t기술\\t및\\tNPU\\t확보,\\tAI\\t인력,\\t외부\\t전문가\\t협업\\t등\\t자원이\\t부족하여\\t서비스\\t출시\\t및\\t사례\\t확보가\\t\\n어려워\\t신산업\\t진출,\\t글로벌\\t수출\\t차질\\n -  특히,\\t학습\\t데이터\\t확보,\\t온디바이스\\t AI\\t하드웨어\\t및\\t최적화된\\t소프트웨어\\t 개발\\t등\\t서비스\\t개발을\\t위해\\t시간과\\t비용이\\t\\n많이\\t필요한\\t온디바이스\\t생성형\\tAI\\t특성\\t상\\t종래\\t단기간\\t내\\t실증\\t사업은\\t실효성\\t부족\\n - \\t온디바이스\\t 생성형\\tAI\\t서비스\\t개발과\\t실환경\\t장기간\\t검증을\\t수행할\\t수\\t있도록\\t2~3년차의\\t 중기간\\t사업을\\t통한\\t실증지원\\t필요'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 24}, page_content='•\\t\\tAI반도체\\t시장\\t현황\\t및\\t전망,\\t2024,\\t한국수출입은행\\n•\\t\\t생성형\\tAI\\t열풍으로\\t성큼\\t다가온\\t온디바이스\\tAI,\\t2024,\\tLG경영연구원\\n•\\t\\t저전력\\t온디바이스\\t비전\\tSW\\t프레임워크\\t기술\\t동향,\\t2021,\\t한국전자통신기술연구원\\n•\\t\\tAI·디지털\\t혁신성장\\t전략(요약),\\t2024,\\t과학기술정보통신부(관계부처\\t합동)\\n•\\t\\t온디바이스\\tAI\\t시장\\t규모,\\t2023,\\t마켓츠앤마켓츠 ·파이낸셜뉴스\\n•\\t\\t생성형\\tAI\\t스마트폰\\t시장\\t규모,\\t2023,\\t카운터포인트리서치\\n•\\t\\t생성형\\tAI\\t시장\\t규모,\\t2023,\\t블룸버그인텔리전스\\n•\\t\\tLarge\\tLanguage\\tModel\\tCost\\tAnalysis,\\t2023,\\t세미에널리시스\\n•\\t\\tGlobal\\tM&A\\tIndustry\\tTrends\\t:\\t2024\\tOutlook,\\t2024,\\t삼일PwC경영연구원\\n•\\t\\t빅테크\\t기업\\t‘AI ·반도체\\t인재\\t쟁탈전’,\\t2024,\\t조선일보\\n•\\t\\t글로벌\\t빅테크\\tAI\\t연구원\\t초봉,\\t2024,\\t한국경제 ·로라\\n•\\t\\t글로벌\\tAI\\t인재보고,\\t2024,\\t한국일보·엘리먼트AI\\n•\\t\\t정보화통계조사,\\t2022,\\t한국지능정보사회진흥원\\n•\\t\\tAI에\\t대한\\t기업체\\t인식\\t및\\t실태조사,\\t2021,\\t한국개발연구원참고문헌\\n25   2024.06  제6호'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 25}, page_content='KEA NOW\\nKEA 주요 소식을 한눈에\\n   2024.06  제6호'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 26}, page_content='KEA NOW\\n27KEA,\\nKTC와 업무협약 체결KEA,\\n전자제조 스타트업 육성 \\n한국전자정보통신산업진흥회(KEA)는\\t6월\\t5일 \\t\\n한국기계전기전자시험연구원(KTC)와\\t가전·전자기업을 \\t\\n포함한\\tICT유망기업의\\t공동\\t발굴\\t및\\t지원프로그램 \\t\\n협력강화를\\t위한\\t업무협약을\\t체결하였다. \\t\\n양\\t기관은\\t이번\\t협약을\\t통해\\t△ICT유망기업\\t육성을 \\t\\n위한\\t협력\\t네트워크\\t구축\\t△스마트가전,\\tIoT사이버보안, \\t\\n인공지능,\\t소프트웨어,\\t5G/6G\\t등\\t분야의\\t시험·인증 \\t\\n컨설팅\\t지원\\t△KEA\\t전자혁신제조\\t지원센터, \\t\\nXR실증센터,\\t빅데이터센터의\\t기업지원\\t프로그램을 \\t\\n공동\\t활용하여\\t미래\\t유망기업의\\t혁신성장을\\t지원한다.\\n특히,\\tIoT보안인증에\\t대응하여\\t수출기업이\\t심각한 \\t\\n애로에\\t직면하지\\t않도록\\t사이버보안\\t관련\\t해외인증 \\t\\n정보와\\t컨설팅을\\t제공한다.\\n이번\\t협약은\\t양\\t기관의\\t협업\\t네트워크를\\t기반으로 \\t\\nICT유망기업의\\t제품·서비스\\t개발부터\\t시험·인증\\t및 \\t\\n제품\\t출시까지\\t수요자\\t중심의\\t끊김없는(Seamless) \\t\\n지원체계를\\t구축하는데\\t의미가\\t크다.\\n양\\t기관은\\t업무협약의\\t첫\\t행사로\\t6월\\t27일,\\t상암동 \\t\\n전자회관에서\\t가전·전자기업을\\t위한\\t‘해외\\tIoT사이버\\n보안\\t컨퍼런스’를\\t개최할\\t예정이다.\\n박청원\\tKEA\\t부회장은\\t“이번\\t협약이\\tICT유망기업의 \\t\\n혁신성장을\\t위한\\t지원기관\\t간\\t협력을\\t강화하는데\\t의미가 \\t\\n크다며,\\tKEA는\\t전자·IT산업\\t진흥기관으로써\\t수요자 \\t\\n중심의\\t기업지원플랫폼이\\t되도록\\t유관기관과\\t협력을 \\t\\n지속해\\t나가겠다.”고\\t밝혔다.한국전자정보통신산업진흥회(KEA)는 \\t6월\\t9일\\t아프리카\\t\\n케냐\\t콘자개발청(KoTDA) \\t관계자들이 \\t서울\\t용산에\\t위치한\\t\\n전자제조센터를 \\t방문,\\t전자제조\\t스타트업\\t육성\\t모델을\\t\\n벤치마킹하고\\t 교류\\t방안을\\t논의했다고\\t 밝혔다.\\t\\nKEA\\t전자제조센터는 \\t도심형\\t제조시설로,\\t 연간\\t\\n200여종\\t전자제품\\t 생산을\\t지원한다. \\t40여종\\t전문장비 \\t\\n시설을\\t갖추고\\t있어\\t스타트업이 \\t어려움을\\t느끼는\\t시제품\\t\\n설계와\\t생산\\t지원에\\t특화돼\\t있다.\\tKEA\\t기술진이\\t전자분야\\t\\n제품\\t개발부터\\t생산,\\t홍보,\\t전시\\t과정을\\t지원한다.\\n케냐\\t정부는\\t국민\\t삶의\\t질\\t향상과\\t산업화\\t지원으로\\t\\n중산층\\t국가로\\t거듭나기\\t위한\\t비전\\t2030을\\t추진하고\\t\\n있다.\\t이의\\t일환으로\\tKoTDA는\\t수도\\t나이로비에서 \\t60㎞\\t\\n떨어진\\t지역에\\t스마트시티를\\t 꾸리고\\t첨단기술\\t스타트업을\\t\\n육성하기\\t위한\\t생태계를\\t조성하는\\t‘콘자\\t테크노폴리스 ’ \\n프로젝트를\\t 추진하고\\t있다.\\t첨단기술과 \\t제조·연구시설을\\t\\n갖춰\\t아프리카의 \\t기술\\t허브로\\t발전시키는 \\t것이\\t목표다.\\n전자제조센터에는 \\tKoTDA\\t위원회\\t이사장과\\t부청장이\\t\\n방문하여\\t케냐\\t콘자의\\t도시\\t모델에\\t반영하기\\t위해\\t한국의\\t\\n선진\\t전자산업\\t시설과\\t산업\\t생태계를\\t둘러봤다.\\nKEA는\\t전자제조센터의\\t 국내\\t혁신제품\\t전초기지\\t역할,\\t\\n지원\\t프로그램,\\t한국\\t스타트업\\t생태계\\t구조를\\t설명했다.\\t\\n내부\\t시설을\\t소개하고,\\t지원한\\t주요\\t스타트업\\t제품을\\t\\n소개했다.\\tKoTDA는\\t콘자\\t테크노폴리스 \\t사업\\t내\\t\\n과학기술원과 \\tICT\\t스타트업\\t육성에\\tKEA\\t전자제조센터\\t\\n모델을\\t반영할\\t방침이다.\\n박청원\\tKEA\\t부회장은\\t“케냐와\\t유기적\\t파트너십\\t구축을\\t\\n기대한다”며 \\t“KEA\\t지원\\t모델이\\t개발도상국을\\t 포함해\\t\\n세계적으로\\t 확산되도록\\t 노력하고\\t스타트업의 \\t전자제품\\t\\n전시와\\t홍보에도\\t협력하겠다”고 \\t밝혔다.\\n1 2KEA 주요 소식을 한눈에\\n   2024.06  제6호\\nDIGISIGHT MEMBER NEWS KEA NOW STATS ESG TREND'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 27}, page_content='KEA NOW\\n28KEA 주요 소식을 한눈에\\n   2024.06  제6호3\\n한국전자정보통신산업진흥회(KEA)는\\t6월\\t11일 \\t\\n양재\\t엘타워에서\\t ‘2024년도\\t제1차\\t전자정보분야 \\t\\n해외기술규제\\t설명회 ’를\\t개최했다.\\n최근\\t산업계\\t전반에서는\\t생성형AI·머신러닝\\t등의 \\t\\n기술개발\\t과정에서\\t투명성을\\t강화해\\t자국\\t산업을 \\t\\n보호하고,\\t제품의\\t생애주기\\t정보\\t등을\\t공개해\\t공급망을 \\t\\n관리하고\\t있다.\\n‘전자정보분야\\t해외기술규제\\t설명회 ’는\\t이\\t같은 \\t\\n추세를\\t반영해\\tAI,\\t사이버보안,\\t화학물질\\t등\\t전자정보 \\t\\n분야의\\t주요\\t해외\\t기술규제에\\t대한\\t산·학·연의\\t대응력 \\t\\n강화를\\t위해\\t개최했다.\\n이번\\t설명회는\\t▲AI\\t사이버\\t시큐리티\\t기술동향\\t및 \\t\\n대응방안\\t▲EU\\t사이버복원력법(CRA)\\t규제동향\\t및 \\t\\n대응방안\\t▲EU\\tDPP\\t규제동향\\t및\\t대응방안 \\t\\n▲분석장비를\\t활용한\\t과불화화합물(PFAS)\\t규제 \\t\\n대응방안\\t순으로\\t발표를\\t진행했다.\\nKEA\\t박청원\\t부회장은\\t “오늘\\t설명회는\\t전자·IT업계 \\t\\n화두가\\t되는\\t해외기술규제\\t대응력\\t강화를\\t위한\\t설명회\\n로서\\t우리나라\\t전자·IT기업들이\\t중대한\\t해외기술규제에 \\t\\n선제적으로\\t대응하는데\\t도움이\\t될\\t중요한\\t자리라고 \\t\\n생각한다”며\\t “전자·IT업계에서\\t무역기술장벽을\\t넘기 \\t\\n위해\\t애쓰는\\t기업들이\\t지속적으로\\t성장해\\t나갈\\t수 \\t\\n있도록\\t적극\\t노력하겠다”고\\t말했다.KEA,\\n전자정보분야 해외기술규제 \\n설명회 개최\\n4\\n한국전자정보통신산업진흥회(KEA)는\\t6월\\t12일과 \\t\\n13일\\t양일간\\t영덕군과\\t의성군에서\\t가전제품\\t무상점검과 \\t\\n건강진단\\t기반\\t의료기기\\t체험\\t행사를\\t실시했다.\\n행사에는\\t삼성전자,\\t세라젬,\\tLG전자,\\t오텍캐리어, \\t\\n쿠쿠전자,\\t쿠첸,\\t휴롬엘에스,\\t경동나비엔,\\t귀뚜라미가 \\t\\n참여했다.\\t\\n전자기업은\\t휴대폰\\t서비스\\t차량과\\t실내\\t행사장에\\t부스를 \\t\\n설치하고\\t농어민,\\t고령자,\\t다문화가정\\t등\\t취약계층 \\t\\n소비자의\\t노트북,\\t밥솥,\\t청소기,\\t공기청정기\\t등\\t소형가전\\n제품\\t무상수리와\\t의료기기\\t체험을\\t제공했다.\\t노인복지관, \\t\\n보육원,\\t장애인복지관\\t등\\t사회배려시설을\\t사전\\t방문해 \\t\\n보일러와\\t대형가전\\t제품을\\t점검·수리했다.\\n행사와\\t연계해\\t어르신\\t장수사진\\t촬영,\\t취약계층 \\t\\n소비자의\\t피해\\t예방\\t교육과\\t자산관리\\t상담,\\t고령자\\t대상 \\t\\n건강상태\\t진단과\\t의료기기\\t체험\\t행사도\\t실시했다. \\t\\n마을\\t단위로\\t수집한\\t소형폐가전도\\t회수했다.\\n본\\t행사는\\t한국소비자원과\\t경상북도\\t영덕군, \\t\\n의성군\\t등\\t지자체가\\t공동으로\\t주관하였으며, \\t\\n한국전자정보통신산업진흥회,\\t기업소비자전문가협회, \\t\\n한국자동차모빌리티산업협회,\\t한국석유관리원, \\t\\n한국주택금융공사,\\tLG생활건강\\t등이\\t참여하여\\t행사를 \\t\\n지원하였다.KEA,\\n영덕·의성에서 \\n가전제품 무상점검 행사\\nDIGISIGHT MEMBER NEWS KEA NOW STATS ESG TREND'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 28}, page_content='MEMBER NEWS\\n KEA 회원사의 성과와 동향\\n   2024.06  제6호'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 29}, page_content='MEMBER NEWS\\n30세라젬,\\n헬스케어 도전 및 \\n매출 3조 목표디지윌, \\n양방향 AI 최첨단 교육 시스템 \\n‘클래스 아이 ’ 출시\\n국내\\t안마의자\\t1위\\t기업인\\t세라젬의 \\t\\n이경수\\t대표는\\t한국경제신문과의\\t인터뷰에서 \\t\\n“7대\\t사업부문으로\\t영역을\\t확장해 \\t\\n글로벌\\t종합\\t헬스케어\\t회사로\\t발돋움하겠다”\\n며\\t이같이\\t말했다.\\t2022년\\t7501억원이던 \\t\\n회사\\t매출을\\t2028년까지\\t3조원으로 \\t\\n끌어올리겠다는\\t포부도\\t밝혔다.\\n이어\\t“아직\\t공개하지\\t않은\\t제품이\\t계속\\t연달아 \\t\\n출시될\\t것”이라며\\t“세븐케어라고\\t이름\\t붙인 \\t\\n우리\\t7개\\t사업군을\\t국내뿐\\t아니라\\t해외에서도 \\t\\n체험할\\t수\\t있도록\\t5년\\t안에\\t전\\t세계\\t1만\\t개 \\t\\n오프라인\\t점포를\\t여는\\t게\\t목표”라고\\t말했다. \\t\\n세라젬은\\t아시아,\\t미주뿐\\t아니라\\t유럽, \\t\\n아프리카,\\t중동\\t등\\t70여\\t개국에\\t진출해\\t있다.\\n올해\\t새로\\t나올\\t제품은\\t혈액\\t순환을\\t돕는 \\t\\n의료기기,\\t공기청정기,\\t맞춤형\\t영양제, \\t\\n우울증\\t치료기,\\t불면증\\t치료기\\t등이\\t있다. \\t\\n최근\\t출시한\\t파우제\\tM6는\\t척추\\t스캔\\t기술, \\t\\n온열\\t기능을\\t담은\\t실리콘\\t볼,\\t팔다리\\t안마\\t기능\\t\\n등을\\t다\\t담았다.최근\\t㈜디지윌(대표\\t홍석환)이\\tAI\\t기반 \\t\\n실시간\\t양방향\\t공유\\t에듀테크\\t시스템 \\t\\n‘클래스\\t아이(Class\\tinteraction)’를\\t출시해 \\t\\n주목을\\t받고\\t있다.\\t이번에\\t출시된\\t‘클래스 \\t\\n아이’는\\t수업\\t모듬형\\t조별\\t학습장치,\\t콘텐츠·\\n학습관리\\t시스템(LMS),\\tAI학습분석\\t솔루션, \\t\\n멀티미디어\\t학습장치(미디어\\t허브)\\t등\\t하나로 \\t\\n통합\\t관리가\\t가능한\\t시스템이다.\\n현재\\t전남교육청과\\t협력해\\t여수와\\t목포에 \\t\\n사전\\t시범\\t운영하고\\t있으며,\\t오는\\t29일 \\t\\n여수세계박람회장에서\\t‘2024\\t대한민국\\t글로컬\\n미래교육박람회’에서\\t미래교실을\\t시연할 \\t\\n예정이다.\\n홍석환\\t디지윌\\t대표이사는\\t “지속\\t가능한 \\t\\n성장과\\t사회적\\t책임\\t달성을\\t위해\\t고객\\t요구에 \\t\\n적극\\t대응하며\\t기술\\t혁신에\\t중점을\\t두고\\t있다”\\n며\\t“회사가\\t추구하는\\t미래\\t가치를\\t바탕으로 \\t\\n지속적인\\t연구개발을\\t통해\\t급변하는\\t디지털 \\t\\n시대에\\t발맞춰\\t나가겠다”고\\t밝혔다.1 2 KEA 회원사의 성과와 동향\\n   2024.06  제6호*기사를\\t클릭하면\\t보다\\t자세한\\t내용을\\t확인하실\\t수\\t있습니다. \\t\\nDIGISIGHT MEMBER NEWS KEA NOW STATS ESG TREND'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 30}, page_content='MEMBER NEWS\\n31삼영전자공업, \\n친환경 모빌리티 시장 \\n최적화 하이브리드 콘덴서 개발코맥스,  \\n대한적십자사 의료원에 \\n디지털 도어락 기부\\n알루미늄\\t전해콘덴서\\t전문생산업체 \\t\\n삼영전자는\\t일본케미콘과\\t기술협력을\\t통해 \\t\\n장수명\\t하이브리드\\t 콘덴서를\\t개발했다고\\t 밝혔다.\\n이번에\\t개발된\\tFPV/FPW/FRV시리즈는 \\t\\n고온도(125℃이상)\\t환경에서\\t전해콘덴서의 \\t\\n보증\\t수명을\\t해결하여\\tADAS첨단운전자\\n지원시스템,\\tHUD헤드업디스플레이, \\t\\nTelematics인터넷차량정보통신장치, \\t\\nIBU통합바디제어기\\t등\\t친환경\\t자동차\\t분야와 \\t\\n외부\\t노출로\\t큰\\t기온\\t변화를\\t견뎌야\\t하는 \\t\\n5G\\t통신용기지국\\t같은\\t고신뢰성이\\t필요한 \\t\\n특수\\t산업\\t시장에서\\t활용할\\t수\\t있다.\\n업체\\t관계자는\\t“이번\\t장수명\\t하이브리드 \\t\\n콘덴서\\t개발로\\t인해\\t전량\\t수입에만\\t의존했던 \\t\\n하이브리드\\t콘덴서의\\t국산화가\\t기능해졌다며 \\t\\n친환경\\t자동차시장의\\t성장과\\t더불어 \\t\\n하이브리드\\t콘덴서의\\t글로벌\\t시장\\t규모도 \\t\\n매년\\t30%\\t이상\\t성장하고\\t있어\\t향후에도 \\t\\n지속적인\\t투자와\\t연구개발로\\t신제품\\t개발을 \\t\\n이어나갈\\t것이다”고\\t말했다.스마트홈\\t전문기업\\t코맥스가\\t대한적십자사 \\t\\n의료원에\\t5000만원\\t상당의\\t스마트\\t디지털 \\t\\n도어락을\\t기부했다고\\t밝혔다.\\t이번\\t기부는 \\t\\n코맥스가\\t사회공헌활동의\\t일환으로\\t국민의 \\t\\n건강을\\t위해\\t노력하는\\t대한적십자사\\t의료원과 \\t\\n해당\\t시설을\\t이용하는\\t환우들에게\\t도움을\\t주기 \\t\\n위한\\t목적으로\\t진행됐다.\\n코맥스의\\t스마트\\t디지털\\t도어락은\\t카드, \\t\\n비밀번호\\t뿐\\t아니라\\t지문\\t인식,\\t얼굴\\t인식이 \\t\\n가능한\\t스마트\\t바이오\\t등\\t강력한\\t보안\\t기능들이 \\t\\n탑재돼\\t병원\\t내\\t안전과\\t보안을\\t크게\\t향상시킬 \\t\\n것으로\\t기대된다.\\t또\\t이를\\t통해\\t의료진과 \\t\\n환우의\\t편리한\\t생활이\\t보장되고\\t병원\\t운영의 \\t\\n효율성도\\t높아질\\t것으로\\t전망된다.\\n이기상\\t코맥스\\t전략기획부문장은\\t“불철주야 \\t\\n노고가\\t많은\\t의료진과\\t응원이\\t필요한\\t환우\\t및 \\t\\n가족들에게\\t작은\\t격려라도\\t해드리고\\t싶다”며 \\t\\n“이번\\t기부를\\t통해\\t새로운\\t인연을\\t맺고, \\t\\n지속적인\\t사회공헌활동으로\\t사회적\\t기업의 \\t\\n책임을\\t다하겠다”고\\t강조했다.3 4 KEA 회원사의 성과와 동향\\n   2024.06  제6호*기사를\\t클릭하면\\t보다\\t자세한\\t내용을\\t확인하실\\t수\\t있습니다. \\t\\nDIGISIGHT MEMBER NEWS KEA NOW STATS ESG TREND'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 31}, page_content='ESG TREND\\nESG Regulations 주요현황\\n   2024.06  제6호'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 32}, page_content='ESG TREND\\n33\\nDIGISIGHT MEMBER NEWS KEA NOW STATS\\n   2024.06  제6호ESG Regulations 주요현황\\n1 2\\n환경부(한국환경공단)는 \\t전기·전자제품\\t환경성보장제를  \\n전품목으로 \\t확대할\\t방침이며,\\t지난\\t5월\\t30일\\t전기전자\\t\\n업계\\t대상으로\\t확대\\t계획\\t설명회를\\t개최하였다.\\n환경성보장제는 \\t전기·전자제품의 \\t재활용을\\t촉진하기\\t\\n위해\\t제조·수입업자의 \\t유해물질\\t사용\\t억제,\\t재활용\\t정보의  \\n제공,\\t폐제품\\t회수 ·재활용\\t및\\t재질구조개선사항 \\t평가\\t등\\t\\n6대\\t의무를\\t부여하는\\t제도로서,\\t2008년\\t최초\\t도입\\t이래\\t\\n현재\\t50개\\t품목에\\t적용\\t중이다.\\n환경부는\\t시장\\t발전에\\t따라\\t다양해진\\t품목을\\t관리하고\\t\\n국가\\t회수 ·재활용\\t목표의\\t원활한\\t달성을\\t위해\\t환경성\\n보장제를\\t전품목으로 \\t확대할\\t예정이며,\\t의류건조기, \\t\\n의류관리기,\\t 전기레인지 \\t및\\t디지털카메라 \\t등\\t신규\\t품목에\\t\\n대해\\t2026년부터 \\t회수 ·재활용\\t의무를\\t적용하고\\t\\n2028년부터 \\t유해물질\\t사용제한도\\t 시행할\\t전망이다.\\n더\\t나아가\\t현재\\t49개\\t품목\\t대상\\t시행\\t중인\\t재질 ·구조\\n개선사항\\t평가제도의 \\t대상\\t품목도\\t장기적으로 \\t확대될\\t\\n것으로\\t예상된다.\\n환경부는\\t올\\t하반기\\t중\\t근거\\t법률인\\t전자제품등\\t\\n자원순환법 \\t개정안을\\t공개하고\\t12월까지\\t법률\\t개정을\\t\\n완료할\\t계획이며,\\tKEA는\\t향후\\t입법\\t동향을\\t모니터링하고\\t\\n전자업계의 \\t의견이\\t반영될\\t수\\t있도록\\t노력할\\t방침이다.우즈베키스탄으로 \\t수출되는\\t가전제품에 \\t대한\\t에너지\\n효율등급\\t시험기관의\\t 부족\\t및\\t운영\\t차질로\\t수출기업의\\t\\n인증서\\t발급\\t지연과\\t통관\\t애로가\\t우려된다.\\n우즈베키스탄 \\t정부는\\t올해\\t1월부터\\t에너지대책의 \\t\\n일환으로\\t에너지효율 \\tB등급\\t이하\\t가전제품의\\t\\n수입\\t금지\\t조치를\\t시행\\t중이며,\\t현재는\\t냉장고,\\t에어컨\\t\\n2개\\t품목에\\t적용\\t중이나\\t향후\\t대상\\t품목을\\t세탁기,\\t\\n청소기,\\tTV,\\t모니터,\\t전자레인지 \\t등\\t여러\\t품목으로\\t\\n확대할\\t계획이다.\\n우리나라\\t수출기업은 \\t통관\\t시\\t현지\\t시험기관이 \\t발급한\\t\\n에너지효율등급 \\t적합성\\t인증서(CoC)*를 \\t제출해야\\t하나,\\t\\n이용\\t가능한\\t시험기관이 \\t에어컨\\t2개소,\\t냉장고\\t1개소에\\t\\n불과할\\t뿐\\t아니라\\t일부\\t기관은\\t내부\\t사정으로\\tCoC\\t\\n발급\\t업무가\\t중단됨으로\\t 인해\\tCoC\\t발급\\t지연이 \\t\\n우려되는\\t실정이다.\\t나아가\\t대상\\t품목이\\t확대될\\t경우\\t\\n인증\\t수요를\\t더\\t해소하기\\t어려워질\\t전망이다.\\n*\\tCoC(Certificate \\tof\\tConformity)\\nKEA는\\t국가기술표준원(이하 \\t국표원)의\\t전자산업\\tTBT\\t\\n기술규제대응 \\t지원기관으로서 \\t업계와\\t대응방안을 \\t여러\\t\\n차례\\t논의하였으며, \\t국표원을\\t통해\\t대상\\t품목\\t추가\\t시\\t\\n인증서\\t발급기간을\\t 확보할\\t수\\t있도록\\t우즈베키스탄 \\t\\n정부에\\t충분한\\t유예기간\\t부여를\\t요청하였다.\\n’24년 내 환경성보장제 \\n전품목 확대 계획수입 가전제품 에너지효율등급 \\n인증서 발급 지연\\n출처\\t:\\t환경정책협의회 출처\\t:\\tKEA\\tTBT\\t사무국\\nESG\\tTrend\\t관련\\t문의사항은 \\tESG&글로벌협력실(02-6388-6186 \\t/\\tdaniel_eom@gokea.org)로 \\t문의\\t바랍니다.\\nESG TREND환경부 우즈베키스탄\\n*\\t이미지  출처\\t:\\t뉴스와이어'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 33}, page_content=' 데이터로 읽는 전자·IT 업황\\n   2024.06  제6호STATS'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 34}, page_content='35*\\t출처\\t:\\t과학기술정보통신부,\\tICT주요품목동향조사,\\tICT수출입통계 \\t구분 1월 2월 3월 4월 5월 6월 7월 8월 9월 10월 11월 12월 계\\n생\\n산2022 31.830.433.131.831.831.431.230.129.929.128.328.8367.8\\n2023 25.6\\t24.4\\t26.0\\t24.2\\t25.7\\t26.4\\t26.7\\t27.6\\t28.4\\t29.0\\t29.729.1322.9\\n2024 27.627.028.328.3\\n수\\n출2022 19.6\\t18.9\\t23.3\\t19.9\\t20.2\\t20.6\\t19.3\\t19.3\\t20.8\\t17.9\\t16.6\\t16.9\\t233.2\\t\\n2023 13.1\\t12.8\\t15.8\\t12.8\\t14.4\\t16.1\\t14.6\\t16.0\\t18.0\\t17.1\\t17.9\\t18.2\\t186.7\\n2024 16.416.518.817.119.1(단위:\\t조원\\t/\\t십억불)감소 증가1. 전자·IT 제조업 생산, 수출\\n•   (생산)  ’22년\\t6월부터\\t17개월간\\t 전년동월대비\\t 감소세를\\t지속해오다\\t ’23년\\t11월부터\\t 증가세로\\t전환됐으며 \\t\\n’24년\\t4월\\t생산은\\t전년동월대비\\t16.8%\\t증가한\\t28.3조원\\n•   (수출) ’22년\\t7월부터\\t16개월간\\t 전년동월대비\\t 감소세를\\t지속해오다\\t ‘23년\\t11월부터\\t 증가세로\\t전환됐으며 \\t\\n’24년\\t5월\\t수출은\\t전년동월대비\\t31.8%\\t증가한\\t19.1억불 데이터로 읽는 전자·IT 업황\\n   2024.06  제6호STATS\\nDIGISIGHT MEMBER NEWS KEA NOW STATS ESG TREND\\n’21.1월 ’21.6월 ’22.1월 ’23.1월 ’22.6월5.0 20.010.025.030.025.0\\n20.0\\n15.035.0\\n생산\\n수출\\n19.1\\n17.1\\n28.328.3'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 35}, page_content='36*\\t출처\\t:\\t과학기술정보통신부,\\tICT기업경기조사\\n※\\t제품재고,\\t생산설비,\\t고용수준\\tBSI는\\t일반적으로\\t경기상승기에는\\t하락하고,\\t경기하강기에는\\t상승하는\\t역계열구분 1월 2월 3월 4월 5월 6월 7월 8월 9월 10월 11월 12월\\n실적\\nBSI2022 86 84 83 91107 108 107 103 95106 98 99\\n2023 101 100 107 103 98 95 96 97 95 96 95100\\n2024 99 98 93102 98\\n전망\\nBSI2022 99103 102 102 111 105 103 105 104 101 105 101\\n2023 101 100 103 104 100 99 97 98 95 98 96 98\\n2024 99101 99 98 97102(100\\t기준\\t+\\t:\\t호조,\\t-\\t:\\t악화) \\t 악화 호조\\n’22.1월 ’22.6월 ’23.1월 ’23.6월 ’24.1월80100120\\n전망BSI실적BSI2. 전자·IT 기업경기실사지수(BSI)\\n•   (실적BSI)  ’24년\\t5월\\t실적\\tBSI는\\t98로\\t전월대비\\t악화\\n-\\t\\t부분별로\\t설비투자실행(101)은\\t 전월대비\\t개선\\t됐으나,\\t생산설비(100)는\\t 전월과\\t동일,\\t자금사정(97), \\t\\n고용수준(104),\\t제품재고(102),\\t생산설비(101)는\\t전월대비\\t악화\\n•   (전망BSI)  ’24년\\t6월\\t전자·IT\\t전망\\tBSI는\\t102로\\t5월\\t대비\\t개선\\t전망\\n-  부분별로\\t설비투자실행(102)은\\t 전월대비\\t개선을\\t기대하나,\\t 자금사정(100)은\\t 5월과\\t동일,\\t제품재고(106), \\t\\n고용수준(104),\\t생산설비(102)는\\t부정적으로\\t전망 데이터로 읽는 전자·IT 업황\\n   2024.06  제6호STATS\\nDIGISIGHT MEMBER NEWS KEA NOW STATS ESG TREND\\n97102 102\\n98'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 36}, page_content='•   (생산)  ’22년\\t7월부터\\t13개월간\\t전년동월대비\\t감소세\\t지속해오다\\t ’23년\\t8월부터\\t증가세로\\t전환됐으며\\n   ’24년\\t4월은\\t전년동월대비\\t18.7%\\t증가 \\t\\n•   (출하)  ’22년\\t11월부터\\t7개월간\\t전년동월대비\\t감소세\\t지속해오다\\t ’23년\\t6월부터\\t증가세로\\t전환됐으며\\n   ’24년\\t4월은\\t전년동월대비\\t16.4%\\t증가 \\t\\n•   (재고)  ’22년,\\t’23년간\\t재고\\t부담\\t지속되었으나,\\t ’24년\\t1월부터\\t감소세로\\t전환됐으며\\t ’24년\\t4월은\\n\\t\\t\\t전년동월대비\\t19.0%\\t감소\\n•   (가동률)  ’22년\\t7월부터\\t13개월간\\t전년동월대비\\t감소세\\t지속해오다\\t ’23년\\t8월부터\\t증가세로\\t전환됐으며\\n   ’24년\\t4월은\\t전년동월대비\\t10.1%\\t증가\\n37*\\t출처\\t:\\t통계청,\\t광업제조업동향조사(원지수),\\t전자·IT\\t제조를\\tKSIC\\t26(전자부품,\\t컴퓨터,\\t영상\\t및\\t통신장비\\t제조업)\\t한정구분 1월 2월 3월 4월 5월 6월 7월 8월 9월 10월 11월 12월 계\\n생산\\n지수2022127.5122.0140.2127.3129.4132.1120.8112.4114.7114.7106.6103.6120.9\\n2023 89.180.7106.9 99.1109.7114.7106.0124.2138.4127.6134.8138.2114.1\\n2024117.6117.6131.1117.6\\n출하\\n지수2022105.0105.9127.2105.2115.2114.3 88.998.0125.8110.3 95.5103.6107.9\\n2023 78.678.2114.6 83.697.6131.9 91.0108.8147.3113.2122.4149.1109.7\\n2024103.2105.9124.2 97.3\\n재고\\n지수2022124.0130.5111.2118.0119.6120.0142.0138.5117.5131.0142.9132.7132.7\\n2023164.6165.1148.9180.7187.0153.1179.2198.9169.0170.9177.6136.8136.8\\n2024137.5149.3133.0146.3\\n가동률\\n지수2022106.6100.6115.0104.0104.2105.9 99.091.992.592.386.585.598.7\\n2023 74.766.387.381.487.491.986.599.2103.4 97.3102.5 99.689.8\\n2024 89.589.598.489.6(2020=100)감소 증가3. 전자·IT 제조업 생산, 출하, 재고, 가동률 동향 데이터로 읽는 전자·IT 업황\\n   2024.06  제6호STATS\\nDIGISIGHT MEMBER NEWS KEA NOW STATS ESG TREND\\n’22.1월 ’22.6월 ’23.1월 ’24.1월 ’23.6월50100200\\n150250\\n생산\\n가동률출하\\n재고\\n146.3\\n97.3\\n89.6117.6'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 37}, page_content='KEA Issue Report\\n온디바이스 AI 기술동향 및 발전방향\\n발행처 한국전자정보통신산업진흥회(KEA)\\n발행일\\t 2024년\\t6월\\n발행인\\t 박청원\\tKEA\\t부회장\\n작        성\\t KEA\\t산업정책실\\n제        작 디.두잇\\n문의처\\t KEA\\t산업정책실\\n\\t (02-6388-6170~6177,\\tghahn@gokea.org)\\n홈페이지\\t www.gokea.org\\n본\\t보고서\\t저작권은\\t 한국전자정보통신산업진흥회 에\\t있습니다. \\t\\n내용을\\t인용\\t또는\\t전재하고자\\t할\\t경우\\t반드시\\t출처를\\t명기하여\\t주시기\\t바라며,\\n무단전제와\\t무단복제를\\t금합니다.'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 38}, page_content='2024-06호\\n* 표지 이미지는 ChatGPT 4.0으로 제작하였습니다')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 문서 로드\n",
        "await adocs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2GZ04gYQKX9"
      },
      "source": [
        "- 비동기 방식으로 로드한 문서를 가져오는 과정을 실습합니다. 이는 효율적인 문서 처리를 위한 비동기 작업의 활용 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luuK4PsUQKX9"
      },
      "source": [
        "## 08-053 문서 분할 및 첫 번째 문서 확인\n",
        "- 이 실습에서는 CharacterTextSplitter를 사용하여 로드한 문서를 지정된 크기(200자)로 분할합니다. chunk_overlap을 0으로 설정하여 겹치지 않는 문서 조각을 생성합니다. 문서 분할 후, 로드된 문서의 수를 확인하고 첫 번째 문서의 내용을 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC4wUkRQQKX9",
        "outputId": "345dfe36-fee7-4958-f70d-1dfc6e8f734c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 0}, page_content='온디바이스 AI \\n기술동향 및 발전방향ISSUE \\nREPORT \\n2024-06호')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# 문자열 분할기 설정\n",
        "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
        "# 문서 분할\n",
        "docs = loader.load_and_split(text_splitter=text_splitter)\n",
        "\n",
        "# 로드된 문서의 수 확인\n",
        "print(len(docs))\n",
        "# 첫번째 문서 확인\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z8fajPXQKX9"
      },
      "source": [
        "- 문서를 특정 크기로 분할하는 과정을 실습합니다. 이는 대량의 텍스트 데이터를 효율적으로 처리하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atp6qJpTQKX-"
      },
      "source": [
        "## 08-054 PDF 로더 초기화 및 페이지 내용 확인\n",
        "- 이 실습에서는 rapidocr-onnxruntime 라이브러리를 설치하고, PyPDFLoader를 초기화하여 이미지 추출 옵션을 활성화합니다. 이후 PDF 페이지를 로드하고, 특정 페이지(5페이지)의 내용을 출력하여 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ha37udUQKX-"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# 설치\n",
        "!pip install -qU rapidocr-onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_Nd992SQKX-",
        "outputId": "21685c1a-f232-445e-deef-1b2a75dfeaac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.2/912.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25houtput values. These are concatenated and once again projected, resulting in the final values, as\n",
            "depicted in Figure 2.\n",
            "Multi-head attention allows the model to jointly attend to information from different representation\n",
            "subspaces at different positions. With a single attention head, averaging inhib\n"
          ]
        }
      ],
      "source": [
        "# PDF 로더 초기화, 이미지 추출 옵션 활성화\n",
        "loader = PyPDFLoader(\"https://arxiv.org/pdf/1706.03762.pdf\", extract_images=True)\n",
        "\n",
        "# PDF 페이지 로드\n",
        "docs = loader.load()\n",
        "\n",
        "# 페이지 내용 접근\n",
        "print(docs[3].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbr2y7JhQKX_"
      },
      "source": [
        "- PDF 로더를 초기화하고 페이지 내용을 확인하는 과정을 실습합니다. 이는 PDF 문서에서 텍스트 및 이미지를 추출하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMSWj4E0QKX_"
      },
      "source": [
        "## 08-055 PyMuPDF 로더 초기화 및 문서 내용 확인\n",
        "- 이 실습에서는 pymupdf 라이브러리를 설치하고, PyMuPDFLoader를 사용하여 PDF 파일을 로드합니다. 이후 특정 페이지(11페이지)의 내용을 출력하여 문서의 내용을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4yuF4slQKX_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# 설치\n",
        "!pip install -qU pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By9ydRlcQKX_",
        "outputId": "40fb2d40-229c-4a78-c81f-3c02d8f36ae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h11\n",
            "   2024.06  제6호\n",
            "DIGISIGHT\n",
            "온디바이스 AI 기술동향 및 발전방향\n",
            "DIGISIGHT\n",
            "ESG TREND\n",
            "MEMBER NEWS\n",
            "KEA NOW\n",
            "STATS\n",
            "3 국가별 정책\n",
            "◎ \u0007자사 AI 칩 기반의 생태계 구축을 위해 데이터·AI 모델·추론기술·SDK*를 아우르는 전방위적 기술 지원\n",
            "     * \u0007소프트웨어를 개발하는 도구로 소프트웨어 개발자가 특정 운영체제용 응용프로그램을 만들 수 있는 소스와 도구 패키지\n",
            "◎ \u0007(애플) 자사의 하드웨어 환경에서 애플의 뉴럴 엔진을 활용하여 온디바이스 AI를 수행할 수 있도록 Cor\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "# PyMuPDF 로더 인스턴스 생성\n",
        "loader = PyMuPDFLoader(FILE_PATH)\n",
        "\n",
        "# 문서 로드\n",
        "docs = loader.load()\n",
        "\n",
        "# 문서의 내용 출력\n",
        "print(docs[10].page_content[:300])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1GXthwOQKYA"
      },
      "source": [
        "- PyMuPDF 로더를 사용하여 PDF 문서를 로드하고 특정 페이지의 내용을 확인하는 과정을 실습합니다. 이는 PDF 문서의 내용 추출을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlGBV6x8QKYA"
      },
      "source": [
        "## 08-056 OpenAI 임베딩 생성 및 쿼리 결과 확인\n",
        "- 이 실습에서는 OpenAIEmbeddings를 사용하여 주어진 텍스트에 대한 임베딩을 생성합니다. 'text-embedding-3-small' 모델을 사용하며, 생성된 임베딩의 일부를 출력하여 결과를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xkJ0s03QKYA",
        "outputId": "1d0ca107-8b40-4d63-d9cf-44f5fe7d2e22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.00776276458054781,\n",
              " 0.03680367395281792,\n",
              " 0.019545823335647583,\n",
              " -0.0196656696498394,\n",
              " 0.017203375697135925]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# OpenAI의 \"text-embedding-3-large\" 모델을 사용하여 임베딩을 생성합니다.\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# 텍스트를 임베딩하여 쿼리 결과를 생성합니다.\n",
        "query_result = embeddings.embed_query(\"임베딩 테스트를 하기 위한 샘플 문장입니다.\")\n",
        "query_result[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD7AMiSzQKYA"
      },
      "source": [
        "- OpenAI 모델을 사용하여 텍스트 임베딩을 생성하고, 그 결과를 확인하는 과정을 실습합니다. 이는 텍스트 데이터를 벡터 형식으로 변환하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3ecZ9GcQKYB"
      },
      "source": [
        "## 08-057 여러 텍스트 일괄 임베딩 생성\n",
        "- 이 실습에서는 OpenAIEmbeddings를 사용하여 여러 텍스트에 대한 임베딩을 일괄 생성합니다. embed_documents() 메서드를 사용하여 주어진 문서 리스트에 대한 임베딩을 생성하고, 첫 번째 문서의 임베딩 벡터 길이를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cmPK5EdQKYB",
        "outputId": "9a3a35b1-6310-48ec-960d-9cee751e5cc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 여러 텍스트를 일괄 임베딩하여 벡터를 생성합니다.\n",
        "doc_result = embeddings.embed_documents(\n",
        "    ['임베딩 테스트를 하기 위한 샘플 문장입니다.',\n",
        "     'AI Essential']\n",
        ")\n",
        "# 문서 결과의 첫 번째 요소의 길이를 반환합니다.\n",
        "len(doc_result[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o692ToIfQKYI"
      },
      "source": [
        "- 여러 텍스트를 일괄 임베딩하여 벡터를 생성하는 과정을 실습합니다. 이는 대량의 텍스트 데이터를 효율적으로 처리하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIBZpIgLQKYI"
      },
      "source": [
        "## 08-058 캐시 지원 임베딩 생성\n",
        "- 이 실습에서는 OpenAI의 임베딩 모델을 사용하여 임베딩을 생성하고, 인메모리 스토어를 사용하여 캐시 지원 임베딩을 생성합니다. CacheBackedEmbeddings를 사용하여 메모리 내에 임베딩 데이터를 캐시하여 성능을 개선합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZTX81HIQKYI"
      },
      "outputs": [],
      "source": [
        "from langchain.storage import InMemoryByteStore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.embeddings import CacheBackedEmbeddings\n",
        "\n",
        "# OpenAI의 \"text-embedding-3-large\" 모델을 사용하여 임베딩을 생성합니다.\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# 인메모리 스토어를 생성합니다.\n",
        "store = InMemoryByteStore()\n",
        "\n",
        "# 캐시를 지원하는 임베딩 생성\n",
        "cached_embeding = CacheBackedEmbeddings.from_bytes_store(\n",
        "    underlying_embeddings=embeddings,\n",
        "    document_embedding_cache=store,\n",
        "    namespace=embeddings.model,  # 기본 임베딩과 저장소를 사용하여 캐시 지원 임베딩을 생성\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rWtIzANQKYI"
      },
      "source": [
        "- 캐시 지원 임베딩을 생성하는 과정을 실습합니다. 이는 임베딩 결과를 효율적으로 저장하고 재사용하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv_763V3QKYJ"
      },
      "source": [
        "## 08-059 캐시 지원 임베딩으로 쿼리 결과 생성\n",
        "- 이 실습에서는 캐시 지원 임베딩을 사용하여 특정 텍스트에 대한 임베딩을 생성합니다. embed_query 메서드를 통해 텍스트를 임베딩하고 결과를 출력하여 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17wER1zvQKYJ",
        "outputId": "6396b18e-0796-4a4f-d46e-4e8cb12fd018"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.00776276458054781,\n",
              " 0.03680367395281792,\n",
              " 0.019545823335647583,\n",
              " -0.0196656696498394,\n",
              " 0.017203375697135925,\n",
              " -0.008378338068723679,\n",
              " -0.011592394672334194,\n",
              " 0.0007585718994960189,\n",
              " 0.028152959421277046,\n",
              " -0.04094381630420685,\n",
              " 0.013411877676844597,\n",
              " 0.055870115756988525,\n",
              " -0.002635254291817546,\n",
              " 0.020537279546260834,\n",
              " -0.012518479488790035,\n",
              " -0.036999788135290146,\n",
              " -0.018380047753453255,\n",
              " -0.007250694558024406,\n",
              " 0.015405682846903801,\n",
              " 0.019567614421248436,\n",
              " 0.015645375475287437,\n",
              " -0.0020741561893373728,\n",
              " -0.0005818668869324028,\n",
              " 0.012246101163327694,\n",
              " -0.0008191759116016328,\n",
              " -0.053255289793014526,\n",
              " 0.0039249625988304615,\n",
              " 0.012878017500042915,\n",
              " 0.04602093622088432,\n",
              " -0.0320969894528389,\n",
              " -0.005605533253401518,\n",
              " -0.01834736205637455,\n",
              " 0.022945096716284752,\n",
              " -0.02640974149107933,\n",
              " 0.05377825349569321,\n",
              " 0.02941679209470749,\n",
              " -0.029177099466323853,\n",
              " -0.009549561887979507,\n",
              " 0.003766983514651656,\n",
              " 0.006874813232570887,\n",
              " -0.0009165509836748242,\n",
              " -0.015906857326626778,\n",
              " 0.02255287393927574,\n",
              " 0.02318478934466839,\n",
              " 0.016037598252296448,\n",
              " 0.051991455256938934,\n",
              " -0.0031623051036149263,\n",
              " -0.004259987268596888,\n",
              " 0.02386028692126274,\n",
              " 0.018979277461767197,\n",
              " -0.025864986702799797,\n",
              " 0.032336682081222534,\n",
              " 0.010170583613216877,\n",
              " -0.025538133457303047,\n",
              " -0.0011058534728363156,\n",
              " 0.05207861587405205,\n",
              " -0.016669515520334244,\n",
              " 0.03900448605418205,\n",
              " 0.030745994299650192,\n",
              " 0.031356122344732285,\n",
              " 0.022356761619448662,\n",
              " -0.015176885761320591,\n",
              " -0.012747276574373245,\n",
              " 0.027085239067673683,\n",
              " -0.019774621352553368,\n",
              " 0.006433561444282532,\n",
              " -0.02582140639424324,\n",
              " 0.008519974537193775,\n",
              " 0.012311471626162529,\n",
              " 0.007975218817591667,\n",
              " 0.08049305528402328,\n",
              " 0.04070412367582321,\n",
              " -0.013771416619420052,\n",
              " 0.011309121735394001,\n",
              " -0.013945737853646278,\n",
              " -0.026518693193793297,\n",
              " -0.021201880648732185,\n",
              " 0.04094381630420685,\n",
              " -0.020940396934747696,\n",
              " -0.008988464251160622,\n",
              " 0.018641529604792595,\n",
              " 0.004630420822650194,\n",
              " 0.014817346818745136,\n",
              " -0.01795513741672039,\n",
              " -0.005790750030428171,\n",
              " -0.0037996689788997173,\n",
              " -0.14259517192840576,\n",
              " 0.026889126747846603,\n",
              " 0.005305917467921972,\n",
              " -0.030288400128483772,\n",
              " -0.008884960785508156,\n",
              " -0.016342662274837494,\n",
              " 0.008460051380097866,\n",
              " 0.028980987146496773,\n",
              " -0.0010929155396297574,\n",
              " -0.05621875822544098,\n",
              " -0.04440845921635628,\n",
              " -0.04185900464653969,\n",
              " -0.025450972840189934,\n",
              " 0.023163000121712685,\n",
              " 0.04153215140104294,\n",
              " -0.04427772015333176,\n",
              " -0.03118179924786091,\n",
              " 0.00044976366916671395,\n",
              " 0.017573809251189232,\n",
              " 0.009549561887979507,\n",
              " 0.016015809029340744,\n",
              " 0.05621875822544098,\n",
              " -0.06380175054073334,\n",
              " -0.005741721950471401,\n",
              " -0.04541081190109253,\n",
              " 0.04011578857898712,\n",
              " -0.007866268046200275,\n",
              " -0.003979437984526157,\n",
              " 0.04336253181099892,\n",
              " -0.013346507214009762,\n",
              " 0.06938004493713379,\n",
              " -0.0030506302136927843,\n",
              " 0.0061557358130812645,\n",
              " -0.02660585381090641,\n",
              " 0.019905362278223038,\n",
              " 0.007691946346312761,\n",
              " 0.06829053908586502,\n",
              " -0.07635291665792465,\n",
              " -0.027433881536126137,\n",
              " -0.04571587219834328,\n",
              " 0.04645673930644989,\n",
              " -0.03349156305193901,\n",
              " -0.02102755941450596,\n",
              " 0.052906643599271774,\n",
              " 0.013302926905453205,\n",
              " 0.030419141054153442,\n",
              " 0.04022473841905594,\n",
              " -0.001062273047864437,\n",
              " 0.03848152235150337,\n",
              " 0.048592180013656616,\n",
              " -0.025233069434762,\n",
              " 0.024601154029369354,\n",
              " 0.0022307734470814466,\n",
              " 0.01875048130750656,\n",
              " -0.008852275088429451,\n",
              " 0.011864772997796535,\n",
              " 0.010132450610399246,\n",
              " 0.03976714611053467,\n",
              " -0.02745567262172699,\n",
              " -0.01630997657775879,\n",
              " -0.0016601420938968658,\n",
              " 0.018576160073280334,\n",
              " 0.025973938405513763,\n",
              " 0.038307201117277145,\n",
              " -0.0015934095717966557,\n",
              " 0.015046143904328346,\n",
              " -0.03939671069383621,\n",
              " 0.018772270530462265,\n",
              " -0.007092715241014957,\n",
              " -0.004355319309979677,\n",
              " 0.010818841867148876,\n",
              " 0.013422773219645023,\n",
              " 0.0027074343524873257,\n",
              " 0.014741080813109875,\n",
              " -0.019120914861559868,\n",
              " -0.021920956671237946,\n",
              " 0.07186413556337357,\n",
              " 0.02627900056540966,\n",
              " -0.00598141411319375,\n",
              " 0.027695365250110626,\n",
              " 0.03192266821861267,\n",
              " 0.04593377560377121,\n",
              " -0.022923307493329048,\n",
              " 0.003056077752262354,\n",
              " 0.008274834603071213,\n",
              " -0.02810937911272049,\n",
              " -0.035343728959560394,\n",
              " 0.022356761619448662,\n",
              " 0.010377590544521809,\n",
              " 0.01585238240659237,\n",
              " -0.02141978219151497,\n",
              " 0.003816011594608426,\n",
              " 0.021387096494436264,\n",
              " 0.03139970079064369,\n",
              " -0.03192266821861267,\n",
              " 0.07090536504983902,\n",
              " 0.014305276796221733,\n",
              " 0.036280710250139236,\n",
              " -0.06720102578401566,\n",
              " -0.006618778221309185,\n",
              " 0.031029267236590385,\n",
              " 0.04693612456321716,\n",
              " -0.009081072174012661,\n",
              " -0.010404828004539013,\n",
              " -0.028545182198286057,\n",
              " 0.00831841491162777,\n",
              " 0.03353514149785042,\n",
              " 0.012169836089015007,\n",
              " -0.0028082141652703285,\n",
              " -0.08214911818504333,\n",
              " 0.03989788517355919,\n",
              " -0.07094894349575043,\n",
              " -0.01960030011832714,\n",
              " 0.04580303281545639,\n",
              " -0.0049245888367295265,\n",
              " -0.0013149033766239882,\n",
              " -0.03976714611053467,\n",
              " 0.01552552916109562,\n",
              " 0.0006761776166968048,\n",
              " -0.0025126843247562647,\n",
              " -0.00010554635809967294,\n",
              " -0.05020465701818466,\n",
              " -0.0035872142761945724,\n",
              " -0.03713052719831467,\n",
              " 0.021474257111549377,\n",
              " 0.010835184715688229,\n",
              " 0.005235099233686924,\n",
              " -0.06850843876600266,\n",
              " -0.03795855492353439,\n",
              " -0.020809656009078026,\n",
              " 0.0065425122156739235,\n",
              " 0.015590899623930454,\n",
              " -0.01412006001919508,\n",
              " 0.051337748765945435,\n",
              " 0.023620594292879105,\n",
              " -0.010557360015809536,\n",
              " 0.05386541411280632,\n",
              " 0.03662935271859169,\n",
              " -0.004180997610092163,\n",
              " 0.0727357417345047,\n",
              " 0.021190986037254333,\n",
              " -0.014305276796221733,\n",
              " 0.006335505284368992,\n",
              " -0.035082247108221054,\n",
              " 0.013215766288340092,\n",
              " 0.001883491757325828,\n",
              " -0.031944457441568375,\n",
              " 0.0051343198865652084,\n",
              " 0.02856697328388691,\n",
              " 0.008116855286061764,\n",
              " -0.0629301443696022,\n",
              " -0.018238410353660583,\n",
              " -0.03309933841228485,\n",
              " -0.011842982843518257,\n",
              " 0.035670582205057144,\n",
              " 0.059618029743433,\n",
              " -0.014163640327751637,\n",
              " -0.018162144348025322,\n",
              " 0.061622731387615204,\n",
              " 0.01137449312955141,\n",
              " 0.023380901664495468,\n",
              " 0.020613543689250946,\n",
              " 0.07460969686508179,\n",
              " -0.014850032515823841,\n",
              " 0.003952200524508953,\n",
              " 0.02025400660932064,\n",
              " -0.010497436858713627,\n",
              " -0.010143345221877098,\n",
              " -0.06667806208133698,\n",
              " 0.02490621618926525,\n",
              " 0.025320231914520264,\n",
              " 0.045890193432569504,\n",
              " -0.011287331581115723,\n",
              " -0.017867976799607277,\n",
              " -0.03852510079741478,\n",
              " -0.03244563192129135,\n",
              " -0.05168639123439789,\n",
              " 0.000592761964071542,\n",
              " -0.009909100830554962,\n",
              " 0.010748024098575115,\n",
              " 0.05582653358578682,\n",
              " 0.019099123775959015,\n",
              " 0.005872463341802359,\n",
              " -0.08798889070749283,\n",
              " -0.006291924975812435,\n",
              " 0.0025058749597519636,\n",
              " 0.017976928502321243,\n",
              " 0.021866481751203537,\n",
              " -0.04146678000688553,\n",
              " 0.016081178560853004,\n",
              " -0.008846827782690525,\n",
              " -0.04423413798213005,\n",
              " 0.008165883831679821,\n",
              " 0.0753505676984787,\n",
              " -0.03619354963302612,\n",
              " 0.022901516407728195,\n",
              " -0.0076538133434951305,\n",
              " 0.007550309877842665,\n",
              " 0.01854347437620163,\n",
              " -0.0010949583956971765,\n",
              " 0.013902157545089722,\n",
              " -0.02274898625910282,\n",
              " 0.007375988177955151,\n",
              " 0.03368767350912094,\n",
              " -0.012790856882929802,\n",
              " -0.016560563817620277,\n",
              " -0.01663682982325554,\n",
              " 0.0206353347748518,\n",
              " 0.00812230259180069,\n",
              " -0.005363116972148418,\n",
              " 0.01842362806200981,\n",
              " -0.028479812666773796,\n",
              " 0.004976340569555759,\n",
              " -0.0075394148007035255,\n",
              " 0.009380687959492207,\n",
              " 0.005458449013531208,\n",
              " 0.038895536214113235,\n",
              " 0.008351100608706474,\n",
              " -0.024274300783872604,\n",
              " 0.005371288396418095,\n",
              " -0.03597564622759819,\n",
              " -0.03891732543706894,\n",
              " -0.009740226902067661,\n",
              " -0.04554155096411705,\n",
              " -0.05604443699121475,\n",
              " -0.01762828417122364,\n",
              " -0.02425250969827175,\n",
              " -0.022574663162231445,\n",
              " 0.021125614643096924,\n",
              " -0.04475710541009903,\n",
              " 0.010846080258488655,\n",
              " 0.015623585321009159,\n",
              " 0.012932493351399899,\n",
              " -0.013128604739904404,\n",
              " -0.003314836649224162,\n",
              " -0.012562059797346592,\n",
              " -0.00020956058870069683,\n",
              " -0.02438325248658657,\n",
              " -0.008509078994393349,\n",
              " 0.03153044357895851,\n",
              " 0.011243751272559166,\n",
              " 0.0017772645223885775,\n",
              " 0.033709462732076645,\n",
              " -0.013390087522566319,\n",
              " -0.00598141411319375,\n",
              " -0.026758385822176933,\n",
              " 0.024688314646482468,\n",
              " -0.08036231994628906,\n",
              " -0.046500321477651596,\n",
              " -0.005186071619391441,\n",
              " -0.01454496942460537,\n",
              " 0.06528348475694656,\n",
              " -0.013313822448253632,\n",
              " 0.04005041718482971,\n",
              " -0.044975005090236664,\n",
              " 0.041183508932590485,\n",
              " 0.008988464251160622,\n",
              " 0.001308774808421731,\n",
              " 0.026039307937026024,\n",
              " 0.0015416578389704227,\n",
              " 0.03906985744833946,\n",
              " -0.033186499029397964,\n",
              " 0.06981585174798965,\n",
              " -0.01294338796287775,\n",
              " -0.003878658404573798,\n",
              " -0.028719505295157433,\n",
              " 0.023947447538375854,\n",
              " -0.01100405864417553,\n",
              " 0.03059346415102482,\n",
              " -0.041771844029426575,\n",
              " -0.006526169832795858,\n",
              " -0.014991668984293938,\n",
              " 0.02141978219151497,\n",
              " 0.01202819962054491,\n",
              " -0.05656740069389343,\n",
              " 0.0001731300726532936,\n",
              " 0.02266182377934456,\n",
              " 0.0061557358130812645,\n",
              " 0.017377696931362152,\n",
              " -0.0076156803406775,\n",
              " -0.0438854955136776,\n",
              " 0.007076372858136892,\n",
              " 0.0024132663384079933,\n",
              " 0.01906643994152546,\n",
              " -0.0025766929611563683,\n",
              " 0.0064226663671433926,\n",
              " 0.0008940797997638583,\n",
              " -0.0008423280669376254,\n",
              " -0.03218415006995201,\n",
              " 0.023163000121712685,\n",
              " 0.02771715447306633,\n",
              " 0.052906643599271774,\n",
              " 0.016800256446003914,\n",
              " -0.03913522884249687,\n",
              " 0.033840205520391464,\n",
              " -0.00598141411319375,\n",
              " -0.00575261702761054,\n",
              " 0.008018799126148224,\n",
              " 0.03619354963302612,\n",
              " -0.012464003637433052,\n",
              " 0.04811279848217964,\n",
              " 0.015067934058606625,\n",
              " -0.0036825465504080057,\n",
              " 0.020668020471930504,\n",
              " 0.013673360459506512,\n",
              " 0.02824012003839016,\n",
              " 0.031421490013599396,\n",
              " 0.006400875747203827,\n",
              " -0.006395428441464901,\n",
              " 0.02366417460143566,\n",
              " 0.003720679320394993,\n",
              " -0.011221961118280888,\n",
              " 0.0010329923825338483,\n",
              " -0.019415082409977913,\n",
              " -0.021899167448282242,\n",
              " -0.010056184604763985,\n",
              " -0.05852852016687393,\n",
              " 0.005564676597714424,\n",
              " -0.01550373900681734,\n",
              " -0.02549455314874649,\n",
              " 0.02595214731991291,\n",
              " 0.013673360459506512,\n",
              " 0.018194830045104027,\n",
              " -0.01586327701807022,\n",
              " 0.023947447538375854,\n",
              " 0.0013884453801438212,\n",
              " 0.036346081644296646,\n",
              " 0.001024821074679494,\n",
              " -0.0037097842432558537,\n",
              " -0.01591775193810463,\n",
              " -0.009914548136293888,\n",
              " 0.02242213301360607,\n",
              " -0.021463362500071526,\n",
              " 0.009124653413891792,\n",
              " -0.008242148905992508,\n",
              " -0.028218328952789307,\n",
              " -0.0399850457906723,\n",
              " 0.004976340569555759,\n",
              " -0.02346806228160858,\n",
              " 0.06471694260835648,\n",
              " 0.02693270705640316,\n",
              " -0.041118137538433075,\n",
              " 0.05726468935608864,\n",
              " -0.07147190719842911,\n",
              " 0.00023305317154154181,\n",
              " -0.00986007321625948,\n",
              " -0.012300577014684677,\n",
              " 0.009805597364902496,\n",
              " -0.037522751837968826,\n",
              " 0.01258384995162487,\n",
              " -0.007348750252276659,\n",
              " 0.06789831072092056,\n",
              " -0.0052650608122348785,\n",
              " -0.010649967938661575,\n",
              " -0.02529844082891941,\n",
              " -0.04377654567360878,\n",
              " -0.020275795832276344,\n",
              " 0.05983593314886093,\n",
              " -0.033121127635240555,\n",
              " -0.006618778221309185,\n",
              " -0.013499039225280285,\n",
              " -0.0037261268589645624,\n",
              " 0.04146678000688553,\n",
              " -0.04942021146416664,\n",
              " -0.002561712171882391,\n",
              " -0.024470413103699684,\n",
              " 0.015383892692625523,\n",
              " -0.02745567262172699,\n",
              " 0.02103845402598381,\n",
              " -0.020134160295128822,\n",
              " 0.03835077956318855,\n",
              " -0.0051533859223127365,\n",
              " 0.022509293630719185,\n",
              " -0.03745738044381142,\n",
              " 0.036651141941547394,\n",
              " 0.012006409466266632,\n",
              " -0.01735590770840645,\n",
              " 0.036999788135290146,\n",
              " 0.011864772997796535,\n",
              " 0.019088229164481163,\n",
              " 0.015035249292850494,\n",
              " 0.014686605893075466,\n",
              " 0.012769066728651524,\n",
              " -0.016102969646453857,\n",
              " -0.000838923326227814,\n",
              " -0.010154240764677525,\n",
              " 0.029002778232097626,\n",
              " 0.0028980986680835485,\n",
              " -0.00793163850903511,\n",
              " 0.02161589451134205,\n",
              " -0.03678188472986221,\n",
              " -0.02148515358567238,\n",
              " -0.039941467344760895,\n",
              " -0.06131766736507416,\n",
              " 0.004595011938363314,\n",
              " -0.07151548564434052,\n",
              " -0.021604999899864197,\n",
              " -0.0334261916577816,\n",
              " -0.0012720038648694754,\n",
              " 0.16761034727096558,\n",
              " 0.03451570123434067,\n",
              " 0.03630249947309494,\n",
              " 0.02182290144264698,\n",
              " -0.030353771522641182,\n",
              " 0.009293527342379093,\n",
              " 0.021866481751203537,\n",
              " 0.048330698162317276,\n",
              " -0.007517624646425247,\n",
              " 0.0031568575650453568,\n",
              " -0.022574663162231445,\n",
              " 0.05164281278848648,\n",
              " -0.02503695897758007,\n",
              " 0.009718436747789383,\n",
              " -0.003895001020282507,\n",
              " -0.012496689334511757,\n",
              " -0.018390942364931107,\n",
              " -0.011085771955549717,\n",
              " 0.04214227944612503,\n",
              " 0.01868510991334915,\n",
              " 0.022618243470788002,\n",
              " 0.0053113652393221855,\n",
              " 0.003451025579124689,\n",
              " -0.023838495835661888,\n",
              " 0.01519867591559887,\n",
              " 0.01044840831309557,\n",
              " 0.00881414208561182,\n",
              " -0.017127109691500664,\n",
              " -0.011516129598021507,\n",
              " 0.0029825358651578426,\n",
              " -0.017508437857031822,\n",
              " -0.012758171185851097,\n",
              " 0.008046037517488003,\n",
              " -0.018630634993314743,\n",
              " -0.011853877454996109,\n",
              " -0.020221320912241936,\n",
              " -0.0008770562126301229,\n",
              " -0.011744926683604717,\n",
              " -0.029395001009106636,\n",
              " 0.001237275660969317,\n",
              " -0.005300470162183046,\n",
              " 0.0011467101285234094,\n",
              " -0.05983593314886093,\n",
              " -0.011548814363777637,\n",
              " -0.007822687737643719,\n",
              " -0.015950437635183334,\n",
              " 0.008312967605888844,\n",
              " 0.016941893845796585,\n",
              " -0.02497158758342266,\n",
              " -0.018499894067645073,\n",
              " -0.0022307734470814466,\n",
              " -0.005959623958915472,\n",
              " -0.0007837668526917696,\n",
              " -0.0005168367060832679,\n",
              " 0.0073814354836940765,\n",
              " 0.004611354321241379,\n",
              " 0.005333155393600464,\n",
              " -0.007708288729190826,\n",
              " -0.013509933836758137,\n",
              " -0.018194830045104027,\n",
              " -0.016680410131812096,\n",
              " 0.03926596790552139,\n",
              " 0.01756291463971138,\n",
              " 0.018260201439261436,\n",
              " -0.0038486968260258436,\n",
              " -0.0008559469133615494,\n",
              " -0.0022893345449119806,\n",
              " 0.02608288824558258,\n",
              " -0.027346720919013023,\n",
              " 0.029569324105978012,\n",
              " -0.021125614643096924,\n",
              " 0.019436873495578766,\n",
              " -0.028523392975330353,\n",
              " 0.02471010573208332,\n",
              " 0.029917966574430466,\n",
              " -0.032598163932561874,\n",
              " 0.0001578939554747194,\n",
              " 0.0012508946238085628,\n",
              " -0.02425250969827175,\n",
              " 0.005774407181888819,\n",
              " -0.02758641354739666,\n",
              " 0.007849925197660923,\n",
              " -0.03255458176136017,\n",
              " 0.004050256218761206,\n",
              " 0.01657145842909813,\n",
              " -0.04355864226818085,\n",
              " 0.04135783016681671,\n",
              " -0.029852595180273056,\n",
              " 0.055216409265995026,\n",
              " 0.0003932453109882772,\n",
              " -0.04090023413300514,\n",
              " 0.02941679209470749,\n",
              " -0.029198888689279556,\n",
              " -0.03460286185145378,\n",
              " 0.01500256359577179,\n",
              " 0.008808694779872894,\n",
              " -0.0058615682646632195,\n",
              " 0.02778252586722374,\n",
              " 0.012148045003414154,\n",
              " 0.003878658404573798,\n",
              " -0.0015947713982313871,\n",
              " 0.021844692528247833,\n",
              " 0.0010554635664448142,\n",
              " -0.015514633618295193,\n",
              " -0.029961546882987022,\n",
              " 0.026823755353689194,\n",
              " -0.03521298989653587,\n",
              " 0.00412924587726593,\n",
              " 0.010094317607581615,\n",
              " 0.030375560745596886,\n",
              " 0.003175924066454172,\n",
              " -0.017345011234283447,\n",
              " 0.008732428774237633,\n",
              " -0.0025739693082869053,\n",
              " -0.018380047753453255,\n",
              " 0.02935142070055008,\n",
              " 0.0013659741962328553,\n",
              " 0.015133305452764034,\n",
              " -0.02405639924108982,\n",
              " 0.000532498408574611,\n",
              " 0.0037506408989429474,\n",
              " -0.01586327701807022,\n",
              " 0.0023833049926906824,\n",
              " 0.015699850395321846,\n",
              " -0.0030724203679710627,\n",
              " -0.030375560745596886,\n",
              " 0.019578509032726288,\n",
              " -0.004058427643030882,\n",
              " 0.01346635352820158,\n",
              " 0.008923093788325787,\n",
              " 0.009647618047893047,\n",
              " 0.007839030586183071,\n",
              " -0.001366655109450221,\n",
              " 0.020155949518084526,\n",
              " -0.007185323629528284,\n",
              " 0.010290429927408695,\n",
              " 0.024078188464045525,\n",
              " 0.03754454106092453,\n",
              " 0.0033257317263633013,\n",
              " -0.026780175045132637,\n",
              " 0.009228156879544258,\n",
              " 0.008623478002846241,\n",
              " 0.0111402478069067,\n",
              " -0.03771886229515076,\n",
              " 0.03750096261501312,\n",
              " -0.017802607268095016,\n",
              " 0.004461546894162893,\n",
              " 0.03118179924786091,\n",
              " -0.010617283172905445,\n",
              " -0.01888122223317623,\n",
              " -0.01809677481651306,\n",
              " 0.012322367168962955,\n",
              " 0.041641101241111755,\n",
              " 0.007871715351939201,\n",
              " -0.029983337968587875,\n",
              " 0.010143345221877098,\n",
              " 0.00683123292401433,\n",
              " -0.003502777311950922,\n",
              " -0.004919141065329313,\n",
              " 0.010639073327183723,\n",
              " 0.012518479488790035,\n",
              " 0.0030588016379624605,\n",
              " 0.004477889277040958,\n",
              " 0.013150395825505257,\n",
              " -0.029133519157767296,\n",
              " 0.0032767036464065313,\n",
              " 0.0025440077297389507,\n",
              " 0.007969771511852741,\n",
              " 0.00937524065375328,\n",
              " -0.008389233611524105,\n",
              " -0.021583208814263344,\n",
              " -0.08014441281557083,\n",
              " -0.047023285180330276,\n",
              " 0.015122409909963608,\n",
              " -0.024993378669023514,\n",
              " 0.0023056771606206894,\n",
              " 0.03577953577041626,\n",
              " -0.014860927127301693,\n",
              " -0.03776244446635246,\n",
              " -0.040464431047439575,\n",
              " 0.03911343961954117,\n",
              " -0.008672505617141724,\n",
              " -0.014141850173473358,\n",
              " -0.021528733894228935,\n",
              " 0.01907733455300331,\n",
              " -0.03296859562397003,\n",
              " 0.012333262711763382,\n",
              " 0.04802563786506653,\n",
              " -0.010225058533251286,\n",
              " 0.003603556891903281,\n",
              " 0.013172185979783535,\n",
              " -0.015841487795114517,\n",
              " -0.04567229375243187,\n",
              " -0.021463362500071526,\n",
              " 0.026627644896507263,\n",
              " 0.04615167900919914,\n",
              " 0.012093570083379745,\n",
              " -0.032271310687065125,\n",
              " -0.0511198453605175,\n",
              " 0.012365947477519512,\n",
              " 0.029329631477594376,\n",
              " -0.001563447993248701,\n",
              " 0.04048622027039528,\n",
              " 0.01958940364420414,\n",
              " -0.03793676570057869,\n",
              " -0.0019243484130129218,\n",
              " -0.04841785877943039,\n",
              " -0.00585067318752408,\n",
              " -0.016691304743289948,\n",
              " 0.0055428859777748585,\n",
              " -0.024274300783872604,\n",
              " -0.005605533253401518,\n",
              " -0.011396283283829689,\n",
              " 0.007577547803521156,\n",
              " 0.03532193973660469,\n",
              " 0.0010411638068035245,\n",
              " 0.024165349081158638,\n",
              " -0.010470198467373848,\n",
              " -0.004249092191457748,\n",
              " 0.015590899623930454,\n",
              " -0.031748343259096146,\n",
              " 0.015471053309738636,\n",
              " 0.03808929771184921,\n",
              " 0.03218415006995201,\n",
              " -0.018042298033833504,\n",
              " -0.021397992968559265,\n",
              " 0.014261696487665176,\n",
              " -0.031813714653253555,\n",
              " -0.022705405950546265,\n",
              " -0.026453321799635887,\n",
              " -0.0006237449124455452,\n",
              " 0.006667806301265955,\n",
              " -0.027368512004613876,\n",
              " -0.014937193132936954,\n",
              " -0.02830549143254757,\n",
              " 0.005371288396418095,\n",
              " 0.02346806228160858,\n",
              " 0.05948729068040848,\n",
              " -0.05151207000017166,\n",
              " -0.0028980986680835485,\n",
              " -0.026845546439290047,\n",
              " 0.039614614099264145,\n",
              " -0.009064730256795883,\n",
              " -0.0018807679880410433,\n",
              " -0.0034401302691549063,\n",
              " -0.016734885051846504,\n",
              " 0.0038732108660042286,\n",
              " -0.02484084665775299,\n",
              " 0.0314650721848011,\n",
              " 0.04501858726143837,\n",
              " -0.004761162213981152,\n",
              " -0.02621362917125225,\n",
              " 0.02529844082891941,\n",
              " -0.03582311421632767,\n",
              " -0.03706515580415726,\n",
              " -0.0216267891228199,\n",
              " 0.007468596566468477,\n",
              " 0.031879086047410965,\n",
              " 0.011951933614909649,\n",
              " 0.01808588020503521,\n",
              " 0.01519867591559887,\n",
              " -0.03270711377263069,\n",
              " 0.017377696931362152,\n",
              " 0.002109565306454897,\n",
              " -0.007032792083919048,\n",
              " -0.04628241807222366,\n",
              " 0.004306291230022907,\n",
              " -0.0038105640560388565,\n",
              " 0.0025780550204217434,\n",
              " 0.023489853367209435,\n",
              " -0.041052766144275665,\n",
              " 0.017257850617170334,\n",
              " -0.013716940768063068,\n",
              " 0.0034619206562638283,\n",
              " 0.018903013318777084,\n",
              " -0.026257209479808807,\n",
              " 0.024230720475316048,\n",
              " -0.010982268489897251,\n",
              " -0.007550309877842665,\n",
              " -0.019676564261317253,\n",
              " -0.033055756241083145,\n",
              " -0.038568682968616486,\n",
              " -0.007866268046200275,\n",
              " 0.01696368306875229,\n",
              " 0.03159581497311592,\n",
              " 0.04100918769836426,\n",
              " -0.04031189903616905,\n",
              " -0.0036553088575601578,\n",
              " 0.024928007274866104,\n",
              " 0.05229651927947998,\n",
              " 0.006803994998335838,\n",
              " -0.021180089563131332,\n",
              " 0.027564622461795807,\n",
              " 0.015536423772573471,\n",
              " 0.01555821392685175,\n",
              " -0.040399059653282166,\n",
              " 0.026104679331183434,\n",
              " -0.0030479065608233213,\n",
              " 0.028327280655503273,\n",
              " -0.015209570527076721,\n",
              " 0.03307754918932915,\n",
              " -0.03608459606766701,\n",
              " 0.029046358540654182,\n",
              " -0.05234009772539139,\n",
              " -0.022509293630719185,\n",
              " -0.019229866564273834,\n",
              " -0.04397265613079071,\n",
              " 0.006123050581663847,\n",
              " -0.02961290441453457,\n",
              " 0.03307754918932915,\n",
              " 0.012267891317605972,\n",
              " -0.023969236761331558,\n",
              " -0.017846187576651573,\n",
              " -0.012823542580008507,\n",
              " -0.023446273058652878,\n",
              " 0.00473392428830266,\n",
              " -0.03861226141452789,\n",
              " 0.011788506992161274,\n",
              " 0.00980015005916357,\n",
              " 0.017900662496685982,\n",
              " 0.004717581905424595,\n",
              " -0.0038269066717475653,\n",
              " 0.0360410176217556,\n",
              " 0.00520786177366972,\n",
              " -0.017650075256824493,\n",
              " -0.00437166215851903,\n",
              " 0.003867763327434659,\n",
              " -0.01676757074892521,\n",
              " 0.028545182198286057,\n",
              " -0.031617604196071625,\n",
              " 0.0035627002362161875,\n",
              " -0.023424481973052025,\n",
              " -0.035692375153303146,\n",
              " -0.0393313392996788,\n",
              " 0.0022157926578074694,\n",
              " -0.011472548358142376,\n",
              " -0.04959453269839287,\n",
              " -0.014534073881804943,\n",
              " -0.01389126293361187,\n",
              " 0.005319536663591862,\n",
              " -0.03872121497988701,\n",
              " -0.04083486646413803,\n",
              " -0.004979064222425222,\n",
              " -0.0070382398553192616,\n",
              " 0.03647682070732117,\n",
              " 0.003756088437512517,\n",
              " -0.02569066546857357,\n",
              " -0.00973477866500616,\n",
              " -0.029830805957317352,\n",
              " 0.05460628122091293,\n",
              " 0.011581500060856342,\n",
              " -0.024470413103699684,\n",
              " -0.024296090006828308,\n",
              " -0.03774065524339676,\n",
              " -0.0008586706826463342,\n",
              " 0.03054988384246826,\n",
              " 0.00111402478069067,\n",
              " -0.004646763671189547,\n",
              " -0.0160593893378973,\n",
              " -0.020428327843546867,\n",
              " -0.01008887030184269,\n",
              " -0.006896603386849165,\n",
              " 0.008884960785508156,\n",
              " -0.021931853145360947,\n",
              " 0.017061738297343254,\n",
              " 0.005959623958915472,\n",
              " 0.024753686040639877,\n",
              " 0.0065425122156739235,\n",
              " 0.03789318725466728,\n",
              " 0.024949796497821808,\n",
              " -0.005670903716236353,\n",
              " 0.09430805593729019,\n",
              " 0.0017241508467122912,\n",
              " 0.0058179874904453754,\n",
              " 0.0051506622694432735,\n",
              " 0.014512283727526665,\n",
              " -0.01742127723991871,\n",
              " -0.03172655403614044,\n",
              " -0.013444563373923302,\n",
              " 0.01972014643251896,\n",
              " 0.004883732181042433,\n",
              " 0.025647085160017014,\n",
              " 0.006564302369952202,\n",
              " 0.01986178196966648,\n",
              " 0.02089681662619114,\n",
              " 0.009462401270866394,\n",
              " -0.016168341040611267,\n",
              " -0.007844477891921997,\n",
              " -0.02771715447306633,\n",
              " -0.005867015570402145,\n",
              " -0.022051699459552765,\n",
              " 0.005774407181888819,\n",
              " 0.06510916352272034,\n",
              " 0.04837428033351898,\n",
              " 0.020090579986572266,\n",
              " 0.029896177351474762,\n",
              " -0.018630634993314743,\n",
              " -0.003867763327434659,\n",
              " 0.02824012003839016,\n",
              " -0.0014218116411939263,\n",
              " 0.007779106963425875,\n",
              " -0.008481841534376144,\n",
              " 0.0027115200646221638,\n",
              " 1.5246767361531965e-05,\n",
              " 0.00515883369371295,\n",
              " 0.006144840735942125,\n",
              " -0.043929073959589005,\n",
              " -0.007076372858136892,\n",
              " -0.022127963602542877,\n",
              " -0.02771715447306633,\n",
              " 0.019883573055267334,\n",
              " -0.004663106054067612,\n",
              " -0.0034319590777158737,\n",
              " 0.019360607489943504,\n",
              " 0.04238197207450867,\n",
              " -0.02464473433792591,\n",
              " 0.004791123792529106,\n",
              " 0.01137449312955141,\n",
              " 0.027412092313170433,\n",
              " 0.021648580208420753,\n",
              " -0.031203588470816612,\n",
              " -0.01104763988405466,\n",
              " 0.04068233445286751,\n",
              " 0.008884960785508156,\n",
              " 0.0044206902384757996,\n",
              " -0.03702157735824585,\n",
              " -0.0031704765278846025,\n",
              " -0.003780602477490902,\n",
              " 0.030484512448310852,\n",
              " -0.014632130041718483,\n",
              " 0.0014190878719091415,\n",
              " -0.03320828825235367,\n",
              " 0.0005641623283736408,\n",
              " 0.013749626465141773,\n",
              " -0.030310191214084625,\n",
              " -0.0353873111307621,\n",
              " -0.06480409950017929,\n",
              " 0.04029010981321335,\n",
              " -0.025864986702799797,\n",
              " 0.021071139723062515,\n",
              " -0.0012427233159542084,\n",
              " -0.0019447767408564687,\n",
              " -0.02221512608230114,\n",
              " 0.03532193973660469,\n",
              " 0.004379833582788706,\n",
              " -0.04549797251820564,\n",
              " 0.021397992968559265,\n",
              " -0.06833411753177643,\n",
              " 0.019959837198257446,\n",
              " 0.033513352274894714,\n",
              " -0.03715232014656067,\n",
              " -0.013651570305228233,\n",
              " 0.01228968147188425,\n",
              " 0.019818201661109924,\n",
              " 0.000984645332209766,\n",
              " 0.02739030122756958,\n",
              " -0.005932386498898268,\n",
              " -0.007348750252276659,\n",
              " -0.00019985713879577816,\n",
              " 0.03523477911949158,\n",
              " -0.02272719517350197,\n",
              " 0.025777826085686684,\n",
              " -0.01421811617910862,\n",
              " 0.03261995315551758,\n",
              " -0.01965477503836155,\n",
              " -0.009075624868273735,\n",
              " -0.040399059653282166,\n",
              " 0.010600940324366093,\n",
              " -0.030375560745596886,\n",
              " -0.03702157735824585,\n",
              " -0.0031623051036149263,\n",
              " 0.023163000121712685,\n",
              " -0.07291006296873093,\n",
              " 0.018521683290600777,\n",
              " -0.012834437191486359,\n",
              " 0.01885943114757538,\n",
              " -0.010001708753407001,\n",
              " 0.03314291685819626,\n",
              " -0.037784233689308167,\n",
              " 0.01697457768023014,\n",
              " 0.010377590544521809,\n",
              " 0.006646015681326389,\n",
              " 0.01723606139421463,\n",
              " 0.027956847101449966,\n",
              " 0.031247170642018318,\n",
              " 0.003282151184976101,\n",
              " 0.022945096716284752,\n",
              " 0.04005041718482971,\n",
              " 0.024470413103699684,\n",
              " 0.012126254849135876,\n",
              " -0.005954176653176546,\n",
              " -0.00897212140262127,\n",
              " 0.022966887801885605,\n",
              " 0.0035763191990554333,\n",
              " 0.013117710128426552,\n",
              " 0.016266396269202232,\n",
              " 0.016157444566488266,\n",
              " 0.0007006916566751897,\n",
              " 0.019709249958395958,\n",
              " 0.028065798804163933,\n",
              " 0.013183080591261387,\n",
              " 0.019055543467402458,\n",
              " 0.024165349081158638,\n",
              " 0.029046358540654182,\n",
              " 0.005384907126426697,\n",
              " -0.016560563817620277,\n",
              " 0.006956526543945074,\n",
              " -0.008732428774237633,\n",
              " 0.03007049858570099,\n",
              " 0.007582995109260082,\n",
              " -0.02575603500008583,\n",
              " -0.02274898625910282,\n",
              " 0.003666203934699297,\n",
              " 0.02490621618926525,\n",
              " -0.011156590655446053,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 텍스트를 임베딩하여 쿼리 결과를 생성합니다.\n",
        "query_result = cached_embeding.embed_query(\"임베딩 테스트를 하기 위한 샘플 문장입니다.\")\n",
        "query_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIj_wG7sQKYJ"
      },
      "source": [
        "- 캐시 지원 임베딩을 사용하여 텍스트 임베딩을 생성하는 과정을 실습합니다. 이는 임베딩 결과를 효율적으로 생성하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX4TTai9QKYJ"
      },
      "source": [
        "## 08-060 1024차원 임베딩 생성 및 길이 확인\n",
        "- 이 실습에서는 OpenAI의 임베딩 모델을 사용하여 1024차원의 임베딩을 생성하는 객체를 초기화합니다. 이후 주어진 텍스트에 대한 임베딩을 생성하고, 첫 번째 임베딩 벡터의 길이를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnILbUl6QKYK",
        "outputId": "3fd21586-1d61-4163-83ce-76cf9a3ba397"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# OpenAI의 \"text-embedding-3-small\" 모델을 사용하여 1024차원의 임베딩을 생성하는 객체를 초기화합니다.\n",
        "embeddings_1024 = OpenAIEmbeddings(model=\"text-embedding-3-small\", dimensions=1024)\n",
        "# 주어진 텍스트를 임베딩하고 첫 번째 임베딩 벡터의 길이를 반환합니다.\n",
        "len(embeddings_1024.embed_documents(['AI Essential'])[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRUqjwW4QKYK"
      },
      "source": [
        "- 1024차원 임베딩을 생성하고, 임베딩 벡터의 길이를 확인하는 과정을 실습합니다. 이는 임베딩의 차원 수를 설정하고 결과를 다루는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7hbdOBkQKYK"
      },
      "source": [
        "## 08-061 임베딩 대상 텍스트 정의\n",
        "- 이 실습에서는 임베딩을 생성할 텍스트 문장을 정의합니다. 다양한 인사말 및 문장을 포함하여 나중에 임베딩을 생성할 준비를 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf4xXf9hQKYK"
      },
      "outputs": [],
      "source": [
        "# 임베딩 대상 텍스트\n",
        "sentence1 = \"안녕하세요? 반갑습니다.\"\n",
        "sentence2 = \"안녕하세요? 반갑습니다!\"\n",
        "sentence3 = \"안녕하세요? 만나서 반가워요.\"\n",
        "sentence4 = \"Hi, nice to meet you.\"\n",
        "sentence5 = \"I like to eat apples.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F1sJ2cFQKYL"
      },
      "source": [
        "- 임베딩할 텍스트 문장을 정의하는 과정을 실습합니다. 이는 다양한 문장을 사용하여 임베딩의 성능을 테스트하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0lCATC5QKYL"
      },
      "source": [
        "## 08-062 임베딩 수행\n",
        "- 이 실습에서는 정의한 여러 문장을 임베딩하여 벡터로 변환합니다. embed_documents 메서드를 사용하여 문장 리스트에 대한 임베딩을 수행하고 결과를 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2HdLxxDQKYM"
      },
      "outputs": [],
      "source": [
        "# 임베딩 수행\n",
        "sentences = [sentence1, sentence2, sentence3, sentence4, sentence5]\n",
        "embedded_sentences = embeddings_1024.embed_documents(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4tnxkUYQKYM"
      },
      "source": [
        "- 여러 텍스트 문장을 임베딩하는 과정을 실습합니다. 이는 텍스트 데이터를 벡터 형태로 변환하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQhgFMNAQKYM"
      },
      "source": [
        "## 08-063 코사인 유사도 계산 함수 정의\n",
        "- 이 실습에서는 두 임베딩 벡터 간의 코사인 유사도를 계산하는 함수를 정의합니다. sklearn의 cosine_similarity 함수를 사용하여 두 벡터의 유사도를 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2npK6lYcQKYM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def similarity(a, b):\n",
        "    return cosine_similarity([a], [b])[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuE9mcMRQKYN"
      },
      "source": [
        "- 코사인 유사도를 계산하는 함수를 정의하는 과정을 실습합니다. 이는 벡터 간의 유사도를 평가하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihKS2NHGQKYN"
      },
      "source": [
        "## 08-064 유사도 계산 및 결과 출력\n",
        "- 이 실습에서는 정의된 문장 리스트에서 각 문장 쌍 간의 코사인 유사도를 계산하고 결과를 출력합니다. 두 문장 간의 유사도를 확인하기 위해 이중 루프를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ixqu_dMZQKYN",
        "outputId": "03df9b23-15de-4d53-b6c8-837146b44d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[유사도 0.9644] 안녕하세요? 반갑습니다. \t <=====> \t 안녕하세요? 반갑습니다!\n",
            "[유사도 0.8376] 안녕하세요? 반갑습니다. \t <=====> \t 안녕하세요? 만나서 반가워요.\n",
            "[유사도 0.5042] 안녕하세요? 반갑습니다. \t <=====> \t Hi, nice to meet you.\n",
            "[유사도 0.1362] 안녕하세요? 반갑습니다. \t <=====> \t I like to eat apples.\n",
            "[유사도 0.8142] 안녕하세요? 반갑습니다! \t <=====> \t 안녕하세요? 만나서 반가워요.\n",
            "[유사도 0.4790] 안녕하세요? 반갑습니다! \t <=====> \t Hi, nice to meet you.\n",
            "[유사도 0.1318] 안녕하세요? 반갑습니다! \t <=====> \t I like to eat apples.\n",
            "[유사도 0.5128] 안녕하세요? 만나서 반가워요. \t <=====> \t Hi, nice to meet you.\n",
            "[유사도 0.1409] 안녕하세요? 만나서 반가워요. \t <=====> \t I like to eat apples.\n",
            "[유사도 0.2249] Hi, nice to meet you. \t <=====> \t I like to eat apples.\n"
          ]
        }
      ],
      "source": [
        "# 유사도 계산\n",
        "for i, sentence in enumerate(embedded_sentences):\n",
        "    for j, other_sentence in enumerate(embedded_sentences):\n",
        "        if i < j:\n",
        "            print(\n",
        "                f\"[유사도 {similarity(sentence, other_sentence):.4f}] {sentences[i]} \\t <=====> \\t {sentences[j]}\"\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdguVuYxQKYO"
      },
      "source": [
        "- 여러 문장 간의 유사도를 계산하고 출력하는 과정을 실습합니다. 이는 문장 간의 의미적 유사성을 평가하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRisIF-LQKYO"
      },
      "source": [
        "## 08-065 JAEN에서 키워드 파일 다운로드\n",
        "- 이 실습에서는 JAEN 라이브러리를 사용하여 'nlp-keywords.txt'와 'finance-keywords.txt' 파일을 다운로드합니다. download_file 함수를 호출하여 해당 파일들을 다운로드하고, 이후에 사용할 수 있도록 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQGlNQXGQKYO",
        "outputId": "3693c028-6ba6-411d-e07f-6ea3b75a07b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파일이 성공적으로 다운로드되었습니다: nlp-keywords.txt\n",
            "절대 경로: /content/nlp-keywords.txt\n",
            "상대 경로: nlp-keywords.txt\n",
            "파일이 성공적으로 다운로드되었습니다: finance-keywords.txt\n",
            "절대 경로: /content/finance-keywords.txt\n",
            "상대 경로: finance-keywords.txt\n"
          ]
        }
      ],
      "source": [
        "from JAEN import download_file\n",
        "\n",
        "download_file('nlp-keywords') # nlp-keywords.txt\n",
        "download_file('finance-keywords') # finance-keywords.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZtxhN4DQKYO"
      },
      "source": [
        "- JAEN 라이브러리를 사용하여 두 개의 키워드 파일을 다운로드하는 과정을 실습합니다. 이는 특정 주제에 대한 키워드를 쉽게 가져오는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRRGVPvwQKYP"
      },
      "source": [
        "## 08-066 텍스트 파일 로드 및 문서 분할\n",
        "- 이 실습에서는 RecursiveCharacterTextSplitter를 사용하여 텍스트 파일을 문서로 로드하고 분할합니다. 각 텍스트 파일을 읽어와서 지정한 크기로 문서 조각으로 나누고, 분할된 문서의 개수를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrFGMDfPQKYP",
        "outputId": "1132ae04-2470-41cb-8f6e-7244722f78e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11, 6)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 텍스트 분할\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=0)\n",
        "\n",
        "# 텍스트 파일을 load -> List[Document] 형태로 변환\n",
        "loader1 = TextLoader(\"./nlp-keywords.txt\", encoding='utf-8')\n",
        "loader2 = TextLoader(\"./finance-keywords.txt\", encoding='utf-8')\n",
        "\n",
        "# 문서 분할\n",
        "split_doc1 = loader1.load_and_split(text_splitter)\n",
        "split_doc2 = loader2.load_and_split(text_splitter)\n",
        "\n",
        "# 문서 개수 확인\n",
        "len(split_doc1), len(split_doc2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ElsKRJSQKYP"
      },
      "source": [
        "- 텍스트 파일을 로드하고, 이를 문서로 분할하는 과정을 실습합니다. 이는 대량의 텍스트 데이터를 효과적으로 관리하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY_CDH_PQKYP"
      },
      "source": [
        "## 08-067 FAISS 벡터 스토어 및 임베딩 차원 크기 계산\n",
        "- 이 실습에서는 OpenAIEmbeddings를 사용하여 임베딩을 생성하고, 특정 텍스트에 대한 임베딩 차원 크기를 계산합니다. embed_query 메서드를 호출하여 임베딩 벡터의 크기를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEQKkN1fQKYQ",
        "outputId": "341b21e7-fdb6-48a2-902e-18e08c0d74f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1536\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# 임베딩\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# 임베딩 차원 크기를 계산\n",
        "dimension_size = len(embeddings.embed_query(\"hello world\"))\n",
        "print(dimension_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVkwli3MQKYQ"
      },
      "source": [
        "- FAISS 벡터 스토어와 함께 임베딩의 차원 크기를 계산하는 과정을 실습합니다. 이는 벡터 데이터를 다루는 데 필요한 차원 정보를 확인하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFhfbOKnQKYQ"
      },
      "source": [
        "## 08-068 FAISS 벡터 스토어 생성\n",
        "- 이 실습에서는 분할된 문서 리스트를 사용하여 FAISS 벡터 스토어를 생성합니다. from_documents 메서드를 호출하여 문서와 임베딩을 사용하여 벡터 스토어를 초기화합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EIUZenSQKYQ"
      },
      "outputs": [],
      "source": [
        "# DB 생성\n",
        "db = FAISS.from_documents(documents=split_doc1,\n",
        "                          embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9B9L-uVQKYR"
      },
      "source": [
        "- FAISS 벡터 스토어를 생성하는 과정을 실습합니다. 이는 문서 데이터의 벡터화를 통해 검색 및 유사도 계산을 효율적으로 처리하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHrU4HpkQKYR"
      },
      "source": [
        "## 08-069 FAISS DB 문서 저장소 ID 확인\n",
        "- 이 실습에서는 생성된 FAISS 벡터 스토어에서 문서 저장소 ID를 확인합니다. index_to_docstore_id 속성을 호출하여 각 문서의 ID와 관련된 정보를 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoXTvr4ZQKYR",
        "outputId": "9faf6ac5-ec3c-4a08-bb34-9751490ca612"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: '7571fedb-6a7a-4c37-995a-86f97b2c18f9',\n",
              " 1: '94c7ba7b-8d74-460e-81f1-38d0782f4732',\n",
              " 2: '71070d27-093f-48e7-bd13-4fd8532753c0',\n",
              " 3: '4d7f6b07-1f93-4429-bf54-8eb7eb9e1304',\n",
              " 4: '881dc941-9663-4a76-8181-a31168c05fcf',\n",
              " 5: '6a17f194-513e-4bca-9b8a-ed00b48237cb',\n",
              " 6: '66442259-b585-48a9-9270-4ad2c9996b21',\n",
              " 7: '164a9c58-cf8b-43a2-8800-4b163cdb3185',\n",
              " 8: 'b21e68b3-143d-4a5e-b4c8-48cc9bb878cb',\n",
              " 9: 'd081c3a4-1d8c-4004-934b-70d267aefc1d',\n",
              " 10: '623b193a-42bc-49fc-8ff8-424d0c312185'}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 문서 저장소 ID 확인\n",
        "db.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQTvgJCnQKYS"
      },
      "source": [
        "- FAISS DB에서 문서 저장소 ID를 확인하는 과정을 실습합니다. 이는 벡터 스토어 내의 문서 식별을 확인하는 데 유용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tq5PkKUQKYS"
      },
      "source": [
        "## 08-070 FAISS DB에서 저장된 문서 확인\n",
        "- 이 실습에서는 FAISS 벡터 스토어의 내부 문서 저장소에서 저장된 문서들을 확인합니다. _dict 속성을 호출하여 각 문서의 ID와 내용을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRj2oDsSQKYS",
        "outputId": "d13fd347-50f1-4b77-9a03-3b763a19b982"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'7571fedb-6a7a-4c37-995a-86f97b2c18f9': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer'),\n",
              " '94c7ba7b-8d74-460e-81f1-38d0782f4732': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\\n예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nVectorStore\\n\\n정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\\n예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\\n연관키워드: 임베딩, 데이터베이스, 벡터화\\n\\nSQL\\n\\n정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\\n예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리\\n\\nCSV'),\n",
              " '71070d27-093f-48e7-bd13-4fd8532753c0': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다. 표 형태의 데이터를 간단하게 저장하고 교환할 때 사용됩니다.\\n예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\\n연관키워드: 데이터 형식, 파일 처리, 데이터 교환\\n\\nJSON\\n\\n정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\\n예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\\n연관키워드: 데이터 교환, 웹 개발, API\\n\\nTransformer\\n\\n정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.\\n예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention\\n\\nHuggingFace'),\n",
              " '4d7f6b07-1f93-4429-bf54-8eb7eb9e1304': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\\n예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\\n연관키워드: 자연어 처리, 딥러닝, 라이브러리\\n\\nDigital Transformation\\n\\n정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\\n예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\\n연관키워드: 혁신, 기술, 비즈니스 모델\\n\\nCrawling\\n\\n정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\\n예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\\n\\nWord2Vec'),\n",
              " '881dc941-9663-4a76-8181-a31168c05fcf': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source'),\n",
              " '6a17f194-513e-4bca-9b8a-ed00b48237cb': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\\n예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\\n\\nStructured Data\\n\\n정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\\n예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\\n\\nParser\\n\\n정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\\n예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)'),\n",
              " '66442259-b585-48a9-9270-4ad2c9996b21': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'),\n",
              " '164a9c58-cf8b-43a2-8800-4b163cdb3185': Document(metadata={'source': './nlp-keywords.txt'}, page_content=\"정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.\\n예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.\\n연관키워드: 데이터 분석, 판다스, 데이터 처리\\n\\nAttention 메커니즘\\n\\n정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다. 이는 주로 시퀀스 데이터(예: 텍스트, 시계열 데이터)에서 사용됩니다.\\n예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\\n연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링\\n\\n판다스 (Pandas)\\n\\n정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.\\n예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리\"),\n",
              " 'b21e68b3-143d-4a5e-b4c8-48cc9bb878cb': Document(metadata={'source': './nlp-keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nInstructGPT\\n\\n정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\\n예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\\n연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\\n\\nKeyword Search'),\n",
              " 'd081c3a4-1d8c-4004-934b-70d267aefc1d': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\\n예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\\n연관키워드: 검색 엔진, 데이터 검색, 정보 검색\\n\\nPage Rank\\n\\n정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.\\n예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\\n연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석\\n\\n데이터 마이닝\\n\\n정의: 데이터 마이닝은 대량의 데이터에서 유용한 정보를 발굴하는 과정입니다. 이는 통계, 머신러닝, 패턴 인식 등의 기술을 활용합니다.\\n예시: 소매업체가 고객 구매 데이터를 분석하여 판매 전략을 수립하는 것은 데이터 마이닝의 예입니다.\\n연관키워드: 빅데이터, 패턴 인식, 예측 분석\\n\\n멀티모달 (Multimodal)'),\n",
              " '623b193a-42bc-49fc-8ff8-424d0c312185': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 멀티모달은 여러 종류의 데이터 모드(예: 텍스트, 이미지, 소리 등)를 결합하여 처리하는 기술입니다. 이는 서로 다른 형식의 데이터 간의 상호 작용을 통해 보다 풍부하고 정확한 정보를 추출하거나 예측하는 데 사용됩니다.\\n예시: 이미지와 설명 텍스트를 함께 분석하여 더 정확한 이미지 분류를 수행하는 시스템은 멀티모달 기술의 예입니다.\\n연관키워드: 데이터 융합, 인공지능, 딥러닝')}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 저장된 문서의 ID: Document 확인\n",
        "db.docstore._dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ROGlSoQQKYT"
      },
      "source": [
        "- FAISS DB에서 저장된 문서를 확인하는 과정을 실습합니다. 이는 벡터 스토어 내의 문서 내용을 검토하는 데 유용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDaYRqYJQKYT"
      },
      "source": [
        "## 08-071 FAISS DB 생성 - 문자열 리스트로\n",
        "- 이 실습에서는 문자열 리스트를 사용하여 FAISS 벡터 스토어를 생성합니다. from_texts 메서드를 사용하여 텍스트 데이터를 벡터화하고, 메타데이터 및 ID를 추가하여 문서 저장소를 초기화합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoKOXpMkQKYU"
      },
      "outputs": [],
      "source": [
        "# 문자열 리스트로 생성\n",
        "db2 = FAISS.from_texts(\n",
        "    [\"안녕하세요. 정말 반갑습니다.\", \"AI Essential 과정입니다\"],\n",
        "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
        "    metadatas=[{\"source\": \"텍스트문서\"}, {\"source\": \"텍스트문서\"}],\n",
        "    ids=[\"doc1\", \"doc2\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwFJwHFZQKYU"
      },
      "source": [
        "- 문자열 리스트를 기반으로 FAISS 벡터 스토어를 생성하는 과정을 실습합니다. 이는 간단한 텍스트 데이터 처리 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8welxaFQKYU"
      },
      "source": [
        "## 08-072 FAISS DB에서 저장된 내용 확인\n",
        "- 이 실습에서는 FAISS 벡터 스토어 db2에 저장된 내용을 확인합니다. docstore._dict 속성을 호출하여 각 문서의 ID 및 관련 내용을 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYBYRis0QKYV",
        "outputId": "ac358548-99e8-4eec-b4bb-4c786768799e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'doc1': Document(metadata={'source': '텍스트문서'}, page_content='안녕하세요. 정말 반갑습니다.'),\n",
              " 'doc2': Document(metadata={'source': '텍스트문서'}, page_content='AI Essential 과정입니다')}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 저장된 내용\n",
        "db2.docstore._dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOKvlOPFQKYW"
      },
      "source": [
        "- FAISS DB에서 저장된 내용을 확인하는 과정을 실습합니다. 이는 생성된 문서의 내용을 검토하는 데 유용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nNfElt0QKYW"
      },
      "source": [
        "## 08-073 FAISS DB에서 유사도 검색\n",
        "- 이 실습에서는 FAISS 벡터 스토어를 사용하여 주어진 질문에 대한 유사한 문서를 검색합니다. similarity_search 메서드를 호출하여 입력된 질문과 가장 유사한 문서들을 찾습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfJRlf6yQKYX",
        "outputId": "f3d73752-f6a6-4b5e-87b4-fcace00af82c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\\n예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\\n\\nStructured Data\\n\\n정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\\n예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\\n\\nParser\\n\\n정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\\n예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content=\"정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.\\n예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.\\n연관키워드: 데이터 분석, 판다스, 데이터 처리\\n\\nAttention 메커니즘\\n\\n정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다. 이는 주로 시퀀스 데이터(예: 텍스트, 시계열 데이터)에서 사용됩니다.\\n예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\\n연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링\\n\\n판다스 (Pandas)\\n\\n정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.\\n예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리\"),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다. 표 형태의 데이터를 간단하게 저장하고 교환할 때 사용됩니다.\\n예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\\n연관키워드: 데이터 형식, 파일 처리, 데이터 교환\\n\\nJSON\\n\\n정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\\n예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\\n연관키워드: 데이터 교환, 웹 개발, API\\n\\nTransformer\\n\\n정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.\\n예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention\\n\\nHuggingFace')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 유사도 검색\n",
        "db.similarity_search(\"TF IDF 에 대하여 알려줘\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGijsaLpQKYX"
      },
      "source": [
        "- FAISS DB에서 유사도 검색을 수행하는 과정을 실습합니다. 이는 벡터 스토어를 활용하여 문서 간의 유사성을 평가하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt_2gfpbQKYX"
      },
      "source": [
        "## 08-074 FAISS DB에서 k 값 지정하여 유사도 검색\n",
        "- 이 실습에서는 FAISS 벡터 스토어를 사용하여 주어진 질문에 대해 유사한 문서를 검색할 때 k 값을 지정합니다. similarity_search 메서드의 k 매개변수를 사용하여 반환할 유사한 문서의 수를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGpoCOzoQKYY",
        "outputId": "2ee5ae65-b64f-44c6-9acd-fdaa8347eabd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\\n예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\\n\\nStructured Data\\n\\n정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\\n예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\\n\\nParser\\n\\n정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\\n예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# k 값 지정\n",
        "db.similarity_search(\"TF IDF 에 대하여 알려줘\", k=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arKWs0BNQKYY"
      },
      "source": [
        "- k 값을 지정하여 FAISS DB에서 유사도 검색을 수행하는 과정을 실습합니다. 이는 원하는 수의 결과를 제어하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcry6rEkQKYZ"
      },
      "source": [
        "## 08-075 FAISS DB에 문서 추가\n",
        "- 이 실습에서는 FAISS 벡터 스토어에 새로운 문서를 추가합니다. Document 객체를 생성할 때 page_content와 metadata를 지정하고, add_documents 메서드를 사용하여 문서를 추가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWJXgBOHQKYZ",
        "outputId": "cb78f9ba-6637-442e-e7aa-11942ab8c6cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['new_doc1']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "# page_content, metadata 지정\n",
        "db.add_documents(\n",
        "    [\n",
        "        Document(\n",
        "            page_content=\"안녕하세요! 이번엔 도큐먼트를 새로 추가해 볼께요\",\n",
        "            metadata={\"source\": \"mydata.txt\"},\n",
        "        )\n",
        "    ],\n",
        "    ids=[\"new_doc1\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJOlZZjFQKYZ"
      },
      "source": [
        "- FAISS DB에 문서를 추가하는 과정을 실습합니다. 이는 벡터 스토어에 데이터를 확장하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CFMvmdwQKYa"
      },
      "source": [
        "## 08-076 FAISS DB에서 추가된 데이터 확인\n",
        "- 이 실습에서는 FAISS 벡터 스토어에 추가된 데이터를 확인하기 위해 similarity_search 메서드를 사용합니다. '안녕하세요'라는 쿼리를 입력하여 가장 유사한 문서를 검색하고 결과를 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PHZ6dNAQKYa",
        "outputId": "7d94bf19-3a10-4dd8-eeac-0d4215ee0d5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'mydata.txt'}, page_content='안녕하세요! 이번엔 도큐먼트를 새로 추가해 볼께요')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 추가된 데이터를 확인\n",
        "db.similarity_search(\"안녕하세요\", k=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RzJAJNLQKYb"
      },
      "source": [
        "- FAISS DB에서 추가된 데이터를 확인하는 과정을 실습합니다. 이는 추가한 문서의 유사성을 평가하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAjEZgh_QKYb"
      },
      "source": [
        "## 08-077 FAISS DB에 텍스트 데이터 추가\n",
        "- 이 실습에서는 FAISS 벡터 스토어에 텍스트 데이터를 추가합니다. add_texts 메서드를 사용하여 텍스트 리스트와 메타데이터, ID를 함께 추가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEIIKjfmQKYb",
        "outputId": "c54003ac-d928-4c12-f1f5-f47531fb523f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['new_doc2', 'new_doc3']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 신규 데이터를 추가\n",
        "db.add_texts(\n",
        "    [\"이번엔 텍스트 데이터를 추가합니다.\", \"추가한 2번째 텍스트 데이터 입니다.\"],\n",
        "    metadatas=[{\"source\": \"mydata.txt\"}, {\"source\": \"mydata.txt\"}],\n",
        "    ids=[\"new_doc2\", \"new_doc3\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7-SUTuEQKYb"
      },
      "source": [
        "- FAISS DB에 텍스트 데이터를 추가하는 과정을 실습합니다. 이는 다양한 형태의 데이터를 벡터 스토어에 저장하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrWBUJOyQKYb"
      },
      "source": [
        "## 08-078 FAISS DB에서 추가된 데이터의 ID 확인\n",
        "- 이 실습에서는 FAISS 벡터 스토어에서 추가된 데이터의 ID를 확인합니다. index_to_docstore_id 속성을 호출하여 각 문서의 ID와 관련된 정보를 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SVYCUkUQKYc",
        "outputId": "ca90ffb5-5117-4a86-8975-b8c6368194f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: '7571fedb-6a7a-4c37-995a-86f97b2c18f9',\n",
              " 1: '94c7ba7b-8d74-460e-81f1-38d0782f4732',\n",
              " 2: '71070d27-093f-48e7-bd13-4fd8532753c0',\n",
              " 3: '4d7f6b07-1f93-4429-bf54-8eb7eb9e1304',\n",
              " 4: '881dc941-9663-4a76-8181-a31168c05fcf',\n",
              " 5: '6a17f194-513e-4bca-9b8a-ed00b48237cb',\n",
              " 6: '66442259-b585-48a9-9270-4ad2c9996b21',\n",
              " 7: '164a9c58-cf8b-43a2-8800-4b163cdb3185',\n",
              " 8: 'b21e68b3-143d-4a5e-b4c8-48cc9bb878cb',\n",
              " 9: 'd081c3a4-1d8c-4004-934b-70d267aefc1d',\n",
              " 10: '623b193a-42bc-49fc-8ff8-424d0c312185',\n",
              " 11: 'new_doc1',\n",
              " 12: 'new_doc2',\n",
              " 13: 'new_doc3'}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 추가된 데이터를 확인\n",
        "db.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-JReuwuQKYc"
      },
      "source": [
        "- FAISS DB에서 추가된 데이터의 ID를 확인하는 과정을 실습합니다. 이는 벡터 스토어 내의 문서 식별을 확인하는 데 유용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM4H2PP1QKYc"
      },
      "source": [
        "## 08-079 FAISS DB에 삭제용 데이터 추가\n",
        "- 이 실습에서는 FAISS 벡터 스토어에 삭제할 데이터를 추가합니다. add_texts 메서드를 사용하여 텍스트 리스트와 메타데이터, ID를 함께 추가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m71B6nmLQKYc"
      },
      "outputs": [],
      "source": [
        "# 삭제용 데이터를 추가\n",
        "ids = db.add_texts(\n",
        "    [\"삭제용 데이터를 추가합니다.\", \"2번째 삭제용 데이터입니다.\"],\n",
        "    metadatas=[{\"source\": \"mydata.txt\"}, {\"source\": \"mydata.txt\"}],\n",
        "    ids=[\"delete_doc1\", \"delete_doc2\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtO-HdK7QKYd"
      },
      "source": [
        "- FAISS DB에 삭제용 데이터를 추가하는 과정을 실습합니다. 이는 나중에 데이터를 삭제하기 위해 식별할 수 있도록 데이터를 준비하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vosKO34hQKYd"
      },
      "source": [
        "## 08-080 FAISS DB에서 삭제할 ID 확인\n",
        "- 이 실습에서는 FAISS 벡터 스토어에 추가한 삭제용 데이터의 ID를 확인합니다. print() 함수를 사용하여 최근에 추가한 데이터의 ID 리스트를 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wFijixvQKYd",
        "outputId": "59032596-c862-4748-db8d-73455fe7c9d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['delete_doc1', 'delete_doc2']\n"
          ]
        }
      ],
      "source": [
        "# 삭제할 id 를 확인\n",
        "print(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLUj8k-tQKYd"
      },
      "source": [
        "- FAISS DB에서 삭제할 ID를 확인하는 과정을 실습합니다. 이는 삭제할 데이터의 식별을 확인하는 데 유용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_8OOFc8QKYd"
      },
      "source": [
        "## 08-081 FAISS DB에서 ID로 데이터 삭제\n",
        "- 이 실습에서는 FAISS 벡터 스토어에서 지정한 ID를 사용하여 데이터를 삭제합니다. delete 메서드를 호출하여 삭제할 ID 리스트를 전달합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcWHo2ynQKYe",
        "outputId": "5bd47812-ec58-4807-bdb8-64385625c562"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# id 로 삭제\n",
        "db.delete(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQb1rzEYQKYe"
      },
      "source": [
        "- FAISS DB에서 특정 ID를 사용하여 데이터를 삭제하는 과정을 실습합니다. 이는 벡터 스토어에서 불필요한 데이터를 관리하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyYqNkAXQKYe"
      },
      "source": [
        "## 08-082 FAISS DB에서 삭제된 결과 확인\n",
        "- 이 실습에서는 FAISS 벡터 스토어에서 삭제된 결과를 확인합니다. index_to_docstore_id 속성을 호출하여 현재 문서의 ID 리스트를 출력하고, 삭제된 데이터가 반영된 결과를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvSNaDxOQKYe",
        "outputId": "1fe46da9-2822-45a8-d1cb-1196193c1c45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: '7571fedb-6a7a-4c37-995a-86f97b2c18f9',\n",
              " 1: '94c7ba7b-8d74-460e-81f1-38d0782f4732',\n",
              " 2: '71070d27-093f-48e7-bd13-4fd8532753c0',\n",
              " 3: '4d7f6b07-1f93-4429-bf54-8eb7eb9e1304',\n",
              " 4: '881dc941-9663-4a76-8181-a31168c05fcf',\n",
              " 5: '6a17f194-513e-4bca-9b8a-ed00b48237cb',\n",
              " 6: '66442259-b585-48a9-9270-4ad2c9996b21',\n",
              " 7: '164a9c58-cf8b-43a2-8800-4b163cdb3185',\n",
              " 8: 'b21e68b3-143d-4a5e-b4c8-48cc9bb878cb',\n",
              " 9: 'd081c3a4-1d8c-4004-934b-70d267aefc1d',\n",
              " 10: '623b193a-42bc-49fc-8ff8-424d0c312185',\n",
              " 11: 'new_doc1',\n",
              " 12: 'new_doc2',\n",
              " 13: 'new_doc3'}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 삭제된 결과를 출력\n",
        "db.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rciIB4nkQKYe"
      },
      "source": [
        "- FAISS DB에서 삭제된 결과를 확인하는 과정을 실습합니다. 이는 데이터 삭제가 제대로 이루어졌는지 검토하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjPEl7UZQKYf"
      },
      "source": [
        "## 08-083 FAISS DB를 로컬 Disk에 저장\n",
        "- 이 실습에서는 FAISS 벡터 스토어를 로컬 디스크에 저장합니다. save_local 메서드를 사용하여 지정한 폴더와 인덱스 이름으로 데이터를 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5NDEMDjQKYf"
      },
      "outputs": [],
      "source": [
        "# 로컬 Disk 에 저장\n",
        "db.save_local(folder_path=\"faiss_db\", index_name=\"faiss_index\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbmoqtPqQKYf"
      },
      "source": [
        "- FAISS DB를 로컬 디스크에 저장하는 과정을 실습합니다. 이는 데이터 지속성을 확보하고 나중에 사용할 수 있도록 저장하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycPP4C9YQKYf"
      },
      "source": [
        "## 08-084 로컬 Disk에서 FAISS DB 로드\n",
        "- 이 실습에서는 로컬 디스크에 저장된 FAISS 벡터 스토어를 로드합니다. load_local 메서드를 사용하여 저장된 폴더와 인덱스 이름을 지정하고, 임베딩과 함께 로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69V5168hQKYf"
      },
      "outputs": [],
      "source": [
        "# 저장된 데이터를 로드\n",
        "loaded_db = FAISS.load_local(\n",
        "    folder_path=\"faiss_db\",\n",
        "    index_name=\"faiss_index\",\n",
        "    embeddings=embeddings,\n",
        "    allow_dangerous_deserialization=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXCwNccsQKYg"
      },
      "source": [
        "- 로컬 디스크에서 FAISS DB를 로드하는 과정을 실습합니다. 이는 저장된 데이터를 불러와 사용할 수 있도록 하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PVqzGGvQKYg"
      },
      "source": [
        "## 08-085 로드된 FAISS DB에서 데이터 확인\n",
        "- 이 실습에서는 로드된 FAISS 벡터 스토어에서 문서 저장소 ID를 확인합니다. index_to_docstore_id 속성을 호출하여 로드된 데이터의 ID 리스트를 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcxNi5szQKYg",
        "outputId": "c2fc3fe6-3e7d-47a4-891c-f3457442c8cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'b8209329-902a-4877-b426-8f3542b9ff09',\n",
              " 1: 'e50c6ac3-f1e4-4993-9b6c-097ce4f210b7',\n",
              " 2: '17191748-c607-437a-8704-288e370ec3ef',\n",
              " 3: '578d0004-99eb-4408-b7d7-c57c9bd126e4',\n",
              " 4: 'd94605ea-c8bd-475d-9171-a9e19d4864d6',\n",
              " 5: '3ef712f7-01b3-40d6-bec3-6a868c5b12a9',\n",
              " 6: '66dd291f-5f09-426e-9c46-53fc16da5fca',\n",
              " 7: '2dfb06ce-e758-42f1-92a2-ebb5b2666ffc',\n",
              " 8: 'e39027c2-eb66-4557-900f-4b91160b88db',\n",
              " 9: '1fe8ccfc-c75e-42dd-85bb-f8bf3f111443',\n",
              " 10: '67e15eb4-0cde-4890-988f-01b0dd673efc',\n",
              " 11: 'new_doc1',\n",
              " 12: 'new_doc2',\n",
              " 13: 'new_doc3'}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 로드된 데이터를 확인\n",
        "loaded_db.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKeJdud-QKYg"
      },
      "source": [
        "- 로드된 FAISS DB에서 데이터를 확인하는 과정을 실습합니다. 이는 데이터가 정상적으로 로드되었는지 검토하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYZK0PH0QKYg"
      },
      "source": [
        "## 08-086 새로운 FAISS 벡터 저장소 생성\n",
        "- 이 실습에서는 두 개의 분할된 문서 리스트(split_doc1과 split_doc2)를 사용하여 새로운 FAISS 벡터 저장소를 생성합니다. from_documents 메서드를 호출하여 문서와 임베딩을 기반으로 벡터 스토어를 초기화합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbqwHoLaQKYh"
      },
      "outputs": [],
      "source": [
        "# 새로운 FAISS 벡터 저장소 생성\n",
        "db = FAISS.from_documents(\n",
        "    documents=split_doc1 + split_doc2, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIaGDWnwQKYh"
      },
      "source": [
        "- 두 개의 문서 리스트를 결합하여 FAISS 벡터 저장소를 생성하는 과정을 실습합니다. 이는 여러 데이터 소스를 통합하여 벡터화를 수행하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7rfdWpkQKYh"
      },
      "source": [
        "## 08-087 FAISS DB를 검색기로 변환 및 검색 수행\n",
        "- 이 실습에서는 FAISS 벡터 저장소를 검색기로 변환하고, 주어진 쿼리를 사용하여 검색을 수행합니다. as_retriever 메서드를 호출하여 검색 기능을 활성화하고, invoke 메서드를 사용하여 검색 쿼리를 입력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fbV13MsQKYh",
        "outputId": "3f658d84-a3a4-4888-c734-799702bc2048"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\\n예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\\n연관키워드: 자연어 처리, 딥러닝, 라이브러리\\n\\nDigital Transformation\\n\\n정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\\n예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\\n연관키워드: 혁신, 기술, 비즈니스 모델\\n\\nCrawling\\n\\n정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\\n예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\\n\\nWord2Vec'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\\n예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nVectorStore\\n\\n정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\\n예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\\n연관키워드: 임베딩, 데이터베이스, 벡터화\\n\\nSQL\\n\\n정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\\n예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리\\n\\nCSV'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 검색기로 변환\n",
        "retriever = db.as_retriever()\n",
        "# 검색 수행\n",
        "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-FIi3LPQKYi"
      },
      "source": [
        "- FAISS DB를 검색기로 변환하고 검색을 수행하는 과정을 실습합니다. 이는 벡터 스토어를 활용하여 정보 검색을 가능하게 하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAWyWRkjQKYi"
      },
      "source": [
        "## 08-088 FAISS DB에서 MMR 검색 수행\n",
        "- 이 실습에서는 FAISS 벡터 저장소에서 MMR(Maximum Marginal Relevance) 검색을 수행합니다. 검색기를 생성할 때 search_type에 'mmr'을 지정하고, k, lambda_mult, fetch_k와 같은 검색 매개변수를 설정하여 유사성과 다양성을 조절합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lli1lNIfQKYi",
        "outputId": "ee13e0cb-c7fd-4836-9f2e-cba4b8ebd059"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nInstructGPT\\n\\n정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\\n예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\\n연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\\n\\nKeyword Search'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다. 표 형태의 데이터를 간단하게 저장하고 교환할 때 사용됩니다.\\n예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\\n연관키워드: 데이터 형식, 파일 처리, 데이터 교환\\n\\nJSON\\n\\n정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\\n예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\\n연관키워드: 데이터 교환, 웹 개발, API\\n\\nTransformer\\n\\n정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.\\n예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention\\n\\nHuggingFace'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 멀티모달은 여러 종류의 데이터 모드(예: 텍스트, 이미지, 소리 등)를 결합하여 처리하는 기술입니다. 이는 서로 다른 형식의 데이터 간의 상호 작용을 통해 보다 풍부하고 정확한 정보를 추출하거나 예측하는 데 사용됩니다.\\n예시: 이미지와 설명 텍스트를 함께 분석하여 더 정확한 이미지 분류를 수행하는 시스템은 멀티모달 기술의 예입니다.\\n연관키워드: 데이터 융합, 인공지능, 딥러닝'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\\n예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\\n연관키워드: 검색 엔진, 데이터 검색, 정보 검색\\n\\nPage Rank\\n\\n정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.\\n예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\\n연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석\\n\\n데이터 마이닝\\n\\n정의: 데이터 마이닝은 대량의 데이터에서 유용한 정보를 발굴하는 과정입니다. 이는 통계, 머신러닝, 패턴 인식 등의 기술을 활용합니다.\\n예시: 소매업체가 고객 구매 데이터를 분석하여 판매 전략을 수립하는 것은 데이터 마이닝의 예입니다.\\n연관키워드: 빅데이터, 패턴 인식, 예측 분석\\n\\n멀티모달 (Multimodal)')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# MMR 검색 수행\n",
        "# k: 최종 문서 수\n",
        "# lambda_mult: query와의 유사성과 문서 간의 다양성 조절, 1이면 유사성 only, 0이면 다양성 only\n",
        "# fetch_k: 후보 문서 수\n",
        "retriever = db.as_retriever(\n",
        "    search_type=\"mmr\", search_kwargs={\"k\": 6, \"lambda_mult\": 0.25, \"fetch_k\": 10}\n",
        ")\n",
        "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z-eBNMUQKYi"
      },
      "source": [
        "- FAISS DB에서 MMR 검색을 수행하는 과정을 실습합니다. 이는 검색 결과의 다양성과 관련성을 동시에 고려하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IATcdobQKYj"
      },
      "source": [
        "## 08-089 FAISS DB에서 MMR 검색 수행 (상위 2개만 반환)\n",
        "- 이 실습에서는 FAISS 벡터 저장소에서 MMR(Maximum Marginal Relevance) 검색을 수행하여 상위 2개의 문서만 반환합니다. search_kwargs를 설정하여 반환할 문서 수를 k로 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSS8u6dYQKYj",
        "outputId": "3f0a7c44-9ba9-471e-cbc7-73a175b0e43b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nInstructGPT\\n\\n정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\\n예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\\n연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\\n\\nKeyword Search')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# MMR 검색 수행, 상위 2개만 반환\n",
        "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2, \"fetch_k\": 10})\n",
        "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB-jOpYhQKYj"
      },
      "source": [
        "- FAISS DB에서 MMR 검색을 수행하고 상위 2개의 결과만 반환하는 과정을 실습합니다. 이는 검색 결과의 개수를 조정하여 더 구체적인 정보를 얻는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDqZZILzQKYj"
      },
      "source": [
        "## 08-090 FAISS DB에서 임계 값 기반 검색 수행\n",
        "- 이 실습에서는 FAISS 벡터 저장소에서 임계 값 기반 검색을 수행합니다. similarity_score_threshold 검색 유형을 사용하여 특정 유사도 점수 이상인 문서만 반환합니다. score_threshold 매개변수를 설정하여 필터링 기준을 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnvzxsvRQKYj",
        "outputId": "ad987902-4864-4222-eecb-9f5a96bb0645"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 임계 값 기반 검색 수행\n",
        "retriever = db.as_retriever(\n",
        "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.8}\n",
        ")\n",
        "\n",
        "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tZdT9j_QKYk"
      },
      "source": [
        "- FAISS DB에서 임계 값 기반 검색을 수행하는 과정을 실습합니다. 이는 유사도 점수를 기반으로 문서를 필터링하여 검색 결과를 최적화하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53jkqqwNQKYk"
      },
      "source": [
        "## 08-091 FAISS DB에서 가장 유사한 문서 검색\n",
        "- 이 실습에서는 FAISS 벡터 저장소에서 가장 유사한 문서 하나만 검색합니다. search_kwargs를 설정하여 k 값을 1로 지정하여 최상위 결과만 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPBlOy-JQKYk",
        "outputId": "bb16c51d-afbc-49d1-a7cf-c6918d945f07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# k=1 로 설정하여 가장 유사한 문서만 검색\n",
        "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
        "\n",
        "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFyMmFlZQKYl"
      },
      "source": [
        "- FAISS DB에서 가장 유사한 문서 하나를 검색하는 과정을 실습합니다. 이는 특정 쿼리에 대해 가장 관련성 높은 문서를 찾는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5xFrmJ_QKYl"
      },
      "source": [
        "## 08-092 JAEN에서 키워드 파일 다운로드\n",
        "- 이 실습에서는 JAEN 라이브러리를 사용하여 'appendix-keywords.txt' 파일을 다운로드합니다. download_file 함수를 호출하여 해당 파일을 다운로드하고, 이후에 사용할 수 있도록 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZIlYUyYQKYl",
        "outputId": "a7b5d465-256b-4cc9-e4ca-8dc2a0812f01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파일이 성공적으로 다운로드되었습니다: appendix-keywords.txt\n",
            "절대 경로: /content/appendix-keywords.txt\n",
            "상대 경로: appendix-keywords.txt\n"
          ]
        }
      ],
      "source": [
        "from JAEN import download_file\n",
        "\n",
        "download_file('appendix-keywords') # appendix-keywords.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQRwBDtNQKYl"
      },
      "source": [
        "- JAEN 라이브러리를 사용하여 추가 키워드 파일을 다운로드하는 과정을 실습합니다. 이는 특정 주제에 대한 키워드를 쉽게 가져오는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv5pxXxSQKYl"
      },
      "source": [
        "## 08-093 appendix-keywords.txt 파일 로드 및 FAISS 벡터 데이터베이스 생성\n",
        "- 이 실습에서는 appendix-keywords.txt 파일을 로드하여 내용을 문서로 읽고, CharacterTextSplitter를 사용하여 문서를 지정된 크기로 분할합니다. 이후 OpenAIEmbeddings를 사용하여 문서의 임베딩을 생성하고, FAISS 벡터 데이터베이스를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaHewMZfQKYm"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "# TextLoader를 사용하여 파일을 로드합니다.\n",
        "loader = TextLoader(\"appendix-keywords.txt\", encoding='utf-8')\n",
        "\n",
        "# 문서를 로드합니다.\n",
        "documents = loader.load()\n",
        "\n",
        "# 문자 기반으로 텍스트를 분할하는 CharacterTextSplitter를 생성합니다. 청크 크기는 300이고 청크 간 중복은 없습니다.\n",
        "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
        "\n",
        "# 로드된 문서를 분할합니다.\n",
        "split_docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# OpenAI 임베딩을 생성합니다.\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# 분할된 텍스트와 임베딩을 사용하여 FAISS 벡터 데이터베이스를 생성합니다.\n",
        "db = FAISS.from_documents(split_docs, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3I5mfW9QKYm"
      },
      "source": [
        "- 텍스트 파일을 로드하고, 문서로 분할한 후 FAISS 벡터 데이터베이스를 생성하는 과정을 실습합니다. 이는 다양한 문서 데이터를 벡터화하여 검색 및 유사도 평가를 가능하게 하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deOVcgfAQKYm"
      },
      "source": [
        "## 08-094 FAISS DB를 검색기로 변환\n",
        "- 이 실습에서는 FAISS 벡터 데이터베이스를 검색기로 변환합니다. as_retriever 메서드를 호출하여 검색 기능을 활성화하고, 검색 작업에 사용할 retriever 변수를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTWyQ5COQKYn"
      },
      "outputs": [],
      "source": [
        "# 데이터베이스를 검색기로 사용하기 위해 retriever 변수에 할당\n",
        "retriever = db.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hzs8fcWHQKYn"
      },
      "source": [
        "- FAISS DB를 검색기로 변환하는 과정을 실습합니다. 이는 저장된 데이터를 효과적으로 검색할 수 있는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B4QjawjQKYn"
      },
      "source": [
        "## 08-095 질문-답변 프롬프트 템플릿 생성\n",
        "- 이 실습에서는 질문-답변을 위한 프롬프트 템플릿을 생성합니다. 주어진 질문과 문맥에 따라 적절한 답변을 유도하는 형식을 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-o-CxH_QKYo"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\n",
        "검색된 다음 문맥(context) 을 사용하여 질문(question) 에 답하세요. 만약, 주어진 문맥(context) 에서 답을 찾을 수 없다면, 답을 모른다면 주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다 라고 답하세요.\n",
        "한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요.\n",
        "\n",
        "#Question:\n",
        "{question}\n",
        "\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On6FW9SmQKYo"
      },
      "source": [
        "- 질문-답변 프롬프트 템플릿을 생성하여 AI 어시스턴트가 사용자 질문에 대한 응답을 제공하는 방법을 실습합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg_S_BVDQKYo"
      },
      "source": [
        "## 08-096 RAG 체인 생성\n",
        "- 이 실습에서는 질문-답변 체인을 생성하기 위해 RAG(Retrieval-Augmented Generation) 체인을 설정합니다. retriever와 prompt를 결합하여 질문과 관련된 문맥을 바탕으로 답변을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDsdfRMeQKYp"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# 체인을 생성합니다.\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Muy0MsW5QKYp"
      },
      "source": [
        "- RAG 체인을 생성하여 검색된 문맥을 활용하여 질문에 대한 응답을 생성하는 과정을 실습합니다. 이는 정보 검색과 생성적 응답을 통합하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UokkxaRQKYp"
      },
      "source": [
        "## 08-097 RunnablePassthrough 사용 예제\n",
        "- 이 실습에서는 RunnablePassthrough를 사용하여 다양한 형식의 입력 데이터를 그대로 통과시키는 예제를 보여줍니다. invoke 메서드를 호출하여 데이터의 원본 형태를 유지하며 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKqUniIhQKYq",
        "outputId": "9ae67ba4-6e29-4f1d-cba9-24d2a5ea607e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'name': 'AI Essential', 'Class': 1}\n",
            "[10, 20, 30, 40, 50]\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "result = RunnablePassthrough().invoke({'name': 'AI Essential', 'Class': 1})\n",
        "print(result)\n",
        "result = RunnablePassthrough().invoke([10, 20, 30, 40, 50])\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1gUQMPMQKYq"
      },
      "source": [
        "- RunnablePassthrough를 사용하여 입력 데이터를 그대로 반환하는 과정을 실습합니다. 이는 데이터 흐름을 유지하면서 추가 처리를 하지 않고 원본 데이터를 사용할 수 있도록 하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnytwVFuQKYq"
      },
      "source": [
        "## 08-098 LLM과 StrOutputParser 결합 사용\n",
        "- 이 실습에서는 LLM(대형 언어 모델)과 StrOutputParser를 결합하여 주어진 질문에 대한 답변을 생성합니다. invoke 메서드를 호출하여 '임베딩에 대해 알려줘'라는 질문에 대한 응답을 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9maC1KIQKYq",
        "outputId": "6d2732d1-dcea-4350-9758-d1a261b625ab"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'임베딩(embedding)은 고차원 데이터를 저차원 공간에 매핑하는 방법으로, 주로 자연어 처리(NLP), 이미지 처리, 추천 시스템 등 다양한 분야에서 사용됩니다. 임베딩의 주요 목적은 데이터의 의미를 보존하면서 더 효율적으로 처리할 수 있도록 하는 것입니다.\\n\\n### 1. 자연어 처리에서의 임베딩\\n자연어 처리에서는 단어, 문장, 또는 문서와 같은 텍스트 데이터를 벡터 형태로 변환하는 데 사용됩니다. 대표적인 예로는 다음과 같은 것들이 있습니다:\\n\\n- **Word2Vec**: 단어를 고차원 공간의 벡터로 변환하여 단어 간의 의미적 유사성을 포착합니다. 주로 CBOW(Continuous Bag of Words)와 Skip-gram 모델이 사용됩니다.\\n- **GloVe (Global Vectors for Word Representation)**: 단어의 동시 발생 행렬을 기반으로 단어 벡터를 생성합니다.\\n- **FastText**: 단어를 n-그램으로 분해하여 더 세밀한 의미를 포착할 수 있도록 합니다.\\n\\n### 2. 이미지 처리에서의 임베딩\\n이미지 데이터를 저차원 벡터로 변환하여 이미지 간의 유사성을 측정하거나 분류하는 데 사용됩니다. 예를 들어, CNN(Convolutional Neural Networks)을 사용하여 이미지의 특징을 추출하고 이를 벡터로 표현할 수 있습니다.\\n\\n### 3. 추천 시스템에서의 임베딩\\n사용자와 아이템(예: 영화, 상품 등)을 벡터로 표현하여 유사한 사용자나 아이템을 찾는 데 사용됩니다. 이를 통해 개인화된 추천을 제공할 수 있습니다.\\n\\n### 4. 임베딩의 장점\\n- **차원 축소**: 고차원 데이터를 저차원으로 변환하여 계산 효율성을 높입니다.\\n- **유사성 측정**: 벡터 간의 거리(예: 코사인 유사도)를 통해 데이터 간의 유사성을 쉽게 측정할 수 있습니다.\\n- **의미 보존**: 데이터의 의미적 관계를 유지하면서 표현할 수 있습니다.\\n\\n임베딩은 다양한 분야에서 데이터의 표현과 처리를 효율적으로 만들어 주는 중요한 기술입니다.'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "(llm | StrOutputParser()).invoke(\"임베딩에 대해 알려줘\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NamLIovXQKYq"
      },
      "source": [
        "- LLM과 StrOutputParser를 결합하여 질문에 대한 응답을 생성하는 과정을 실습합니다. 이는 언어 모델의 출력을 간단하게 파싱하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1Vv-HwnQKYr"
      },
      "source": [
        "## 08-099 RAG 체인 사용하여 질문에 대한 응답 생성\n",
        "- 이 실습에서는 RAG 체인을 사용하여 '임베딩에 대해 알려줘'라는 질문에 대한 응답을 생성합니다. invoke 메서드를 호출하여 검색된 문맥을 기반으로 언어 모델이 답변을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHtpcNZzQKYr",
        "outputId": "3bf6e329-d35d-4edb-973d-d229f1b582e0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 됩니다. 예를 들어, \"사과\"라는 단어는 [0.65, -0.23, 0.17]과 같은 벡터로 표현될 수 있습니다. 임베딩은 자연어 처리, 벡터화, 딥러닝과 관련된 기술입니다.'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rag_chain.invoke('임베딩에 대해 알려줘')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gy_zMypQKYr"
      },
      "source": [
        "- RAG 체인을 통해 주어진 질문에 대한 응답을 생성하는 과정을 실습합니다. 이는 검색된 정보를 바탕으로 생성적 응답을 제공하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR0qeL58h0Up"
      },
      "source": [
        "# Agent/Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBAh9zT-h0Uq"
      },
      "source": [
        "## 08-100 다양한 LangChain 모듈 임포트\n",
        "- 이 실습에서는 LangChain의 다양한 모듈을 임포트합니다. 각 모듈은 텍스트 처리, 문서 로드, 임베딩 생성, 검색 도구, 에이전트 생성 등 여러 기능을 제공합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2SdPIlZh0Uq"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQgnkBWQh0Uq"
      },
      "source": [
        "- LangChain 모듈을 임포트하여 텍스트와 문서를 처리하고 검색 및 에이전트 기능을 사용할 수 있도록 준비하는 과정을 실습합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7PGgbhAh0Ur"
      },
      "source": [
        "## 08-101 TavilySearchResults 인스턴스 생성\n",
        "- 이 실습에서는 TavilySearchResults 클래스의 인스턴스를 생성하여 검색 기능을 설정합니다. 환경 변수를 사용하여 TAVILY_API_KEY를 설정하고, k 값을 통해 반환할 결과의 수를 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYUeUzDch0Ut"
      },
      "outputs": [],
      "source": [
        "# TavilySearchResults 클래스의 인스턴스를 생성\n",
        "import os\n",
        "os.environ['TAVILY_API_KEY'] = \"\"\n",
        "search = TavilySearchResults(k=5, description='온디바이스 AI 기술 동향을 제외한 요청에 이 도구를 사용하세요.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXV-oWH6h0Ut"
      },
      "source": [
        "- TavilySearchResults 인스턴스를 생성하여 검색 도구의 설정을 실습합니다. 이는 특정 검색 쿼리에 대한 응답을 효율적으로 처리하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFnoA7Tvh0Ut"
      },
      "source": [
        "## 08-102 TavilySearchResults 외부 검색 예시\n",
        "- 이 실습에서는 TavilySearchResults 인스턴스를 사용하여 외부 검색을 수행합니다. invoke 메서드를 호출하여 '삼성전자 비스포크에 대해서 알려줘'라는 쿼리로 검색을 수행하고, 결과를 반환받습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRNcgCPoh0Ut"
      },
      "outputs": [],
      "source": [
        "# 외부 검색 예시\n",
        "search.invoke('삼성전자 비스포크에 대해서 알려줘')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC2F78gyh0Ut"
      },
      "source": [
        "- TavilySearchResults를 사용하여 특정 쿼리에 대한 외부 검색을 수행하는 과정을 실습합니다. 이는 외부 데이터 소스를 활용하여 정보를 검색하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qimVvyxh0Uu"
      },
      "source": [
        "## 08-103 TavilySearchResults 외부 검색 예시\n",
        "- 이 실습에서는 TavilySearchResults 인스턴스를 사용하여 외부 검색을 수행합니다. invoke 메서드를 호출하여 '2024년 리뷰가 있는 인계동 주변 맛집에 대해 알려줘'라는 쿼리로 검색을 수행하고, 관련된 결과를 반환받습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD9feQzBh0Uu"
      },
      "outputs": [],
      "source": [
        "# 외부 검색 예시\n",
        "search.invoke('2024년 리뷰가 있는 인계동 주변 맛집에 대해 알려줘')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2_waMsmh0Uu"
      },
      "source": [
        "- TavilySearchResults를 활용하여 특정 쿼리에 대한 외부 검색을 수행하는 과정을 실습합니다. 이는 특정 조건을 만족하는 정보를 찾는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCplMJdih0Uu"
      },
      "source": [
        "## 08-104 PDF 파일 다운로드\n",
        "- 이 실습에서는 JAEN 라이브러리를 사용하여 지정된 PDF 파일을 다운로드합니다. download_file 함수를 호출하여 '온디바이스 AI 기술동향 및 발전방향.pdf' 파일을 로컬에 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NLnIu7Ch0Uu"
      },
      "outputs": [],
      "source": [
        "from JAEN import download_file\n",
        "download_file('PDF') # 온디바이스 AI 기술동향 및 발전방향.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx9PDVKvh0Uu"
      },
      "source": [
        "- PDF 파일을 다운로드하는 과정을 실습합니다. 이는 외부 자료를 가져와 활용할 수 있도록 준비하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6mFVud6h0Uu"
      },
      "source": [
        "## 08-105 PDF 파일 로드 및 벡터 스토어 생성\n",
        "- 이 실습에서는 PyPDFLoader를 사용하여 PDF 파일을 로드하고, RecursiveCharacterTextSplitter를 사용하여 문서를 지정된 크기로 분할합니다. 이후 FAISS를 사용하여 분할된 문서로 벡터 스토어를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3fo0zz_h0Uu"
      },
      "outputs": [],
      "source": [
        "# PDF 파일 로드\n",
        "loader = PyPDFLoader(\"온디바이스 AI 기술동향 및 발전방향.pdf\")\n",
        "\n",
        "# 텍스트 분할기를 사용하여 문서를 분할\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "# 문서를 로드하고 분할\n",
        "split_docs = loader.load_and_split(text_splitter)\n",
        "\n",
        "# VectorStore를 생성\n",
        "vector = FAISS.from_documents(split_docs, OpenAIEmbeddings(model='text-embedding-3-small'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT3CQL5kh0Uu"
      },
      "source": [
        "- PDF 파일을 로드하고, 문서를 분할한 후 FAISS 벡터 스토어를 생성하는 과정을 실습합니다. 이는 PDF에서 정보를 효과적으로 추출하고 검색할 수 있는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHn4mx6yh0Uu"
      },
      "source": [
        "## 08-106 Retriever 생성 및 검색 도구 생성\n",
        "- 이 실습에서는 생성된 벡터 스토어를 기반으로 retriever를 생성합니다. 이후 langchain의 tools 모듈을 사용하여 PDF 문서에서 검색할 수 있는 도구를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1Lxzdh1h0Uu"
      },
      "outputs": [],
      "source": [
        "# Retriever를 생성합니다.\n",
        "retriever = vector.as_retriever()\n",
        "\n",
        "# langchain 패키지의 tools 모듈에서 retriever 도구를 생성\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    name=\"pdf_search\",\n",
        "    # 도구에 대한 설명을 자세히 기입해야 합니다!!!\n",
        "    description=\"온디바이스 AI 기술동향 및 발전방향을 PDF 문서에서 검색합니다. 온디바이스 AI의 전반적인 기술동향 또는 특정 국가의 온디바이스 AI 동향과 관련된 질문은 이 도구를 사용해야 합니다!\",\n",
        ")\n",
        "retriever_tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tesMlz_Eh0Uv"
      },
      "source": [
        "- Retriever를 생성하고 이를 사용하여 PDF 문서에서 정보를 검색하는 도구를 만드는 과정을 실습합니다. 이는 문서 검색 기능을 손쉽게 사용할 수 있도록 설정하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezS8DSsih0Uv"
      },
      "source": [
        "## 08-107 Tools 리스트에 검색 도구 추가\n",
        "- 이 실습에서는 기존에 생성한 검색 도구(search)와 PDF 문서 검색 도구(retriever_tool)를 하나의 리스트로 묶습니다. 이를 통해 두 개의 도구를 함께 사용할 수 있도록 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOIvNJ_Th0Uv"
      },
      "outputs": [],
      "source": [
        "# tools 리스트에 search와 retriever_tool을 추가합니다.\n",
        "tools = [search, retriever_tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlKwIXxKh0Uv"
      },
      "source": [
        "- search와 retriever_tool을 tools 리스트에 추가하여 다양한 검색 기능을 통합하는 과정을 실습합니다. 이는 여러 도구를 효율적으로 관리하고 사용할 수 있도록 하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KozJSNTrh0Uv"
      },
      "source": [
        "## 08-108 LLM 모델 생성\n",
        "- 이 실습에서는 ChatOpenAI 클래스를 사용하여 LLM(대형 언어 모델) 인스턴스를 생성합니다. 모델의 파라미터로는 'gpt-4o-mini'를 사용하고, temperature 값을 0으로 설정하여 더 예측 가능한 응답을 유도합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8IuC8uvh0Uw"
      },
      "outputs": [],
      "source": [
        "# LLM 모델을 생성합니다.\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhOqXgGmh0Uw"
      },
      "source": [
        "- LLM 모델을 생성하여 후속 작업에서 사용할 준비를 하는 과정을 실습합니다. 이는 자연어 처리 작업을 수행하기 위한 기본 모델 설정을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vX4B6mBh0Uw"
      },
      "source": [
        "## 08-109 Hub에서 Prompt 가져오기\n",
        "- 이 실습에서는 LangChain Hub에서 지정된 prompt를 가져옵니다. hub.pull 메서드를 사용하여 미리 정의된 프롬프트를 쉽게 불러올 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBxDJOvkh0Ux"
      },
      "outputs": [],
      "source": [
        "# hub에서 prompt를 가져옴\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON3y78hBh0Ux"
      },
      "source": [
        "- Hub에서 prompt를 가져오는 과정을 실습합니다. 이는 사용자 정의 작업을 쉽게 수행하기 위해 사전 정의된 프롬프트를 활용하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoCM0o_Zh0Ux"
      },
      "source": [
        "## 08-110 OpenAI 함수 기반 에이전트 생성\n",
        "- 이 실습에서는 생성된 LLM, 검색 도구 리스트, 및 가져온 프롬프트를 사용하여 OpenAI 함수 기반 에이전트를 생성합니다. 이를 통해 다양한 질문에 대해 자동으로 응답할 수 있는 시스템을 구축합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQRHZ6lHh0Ux"
      },
      "outputs": [],
      "source": [
        "# OpenAI 함수 기반 에이전트를 생성합니다.\n",
        "# llm, tools, prompt를 인자로 사용합니다.\n",
        "agents = create_openai_functions_agent(llm, tools, prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQIyEjseh0Ux"
      },
      "source": [
        "- OpenAI 함수 기반 에이전트를 생성하여 여러 도구와 LLM을 활용한 자동 응답 시스템을 구축하는 과정을 실습합니다. 이는 다양한 입력에 대해 적절한 행동을 수행하도록 에이전트를 설정하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olYB5HS5h0Uy"
      },
      "source": [
        "## 08-111 AgentExecutor 설정\n",
        "- 이 실습에서는 AgentExecutor 클래스를 사용하여 생성한 에이전트와 도구를 설정합니다. verbose 모드를 True로 설정하여 에이전트 실행 과정에서 발생하는 로그를 자세히 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFVRnBBWh0Uy"
      },
      "outputs": [],
      "source": [
        "# AgentExecutor 클래스를 사용하여 agent와 tools를 설정하고, 상세한 로그를 출력하도록 verbose를 True로 설정합니다.\n",
        "agent_executor = AgentExecutor(agent=agents, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bWt6aSch0Uy"
      },
      "source": [
        "- AgentExecutor를 설정하여 질문-응답 시스템을 구축하는 방법을 실습합니다. 이는 에이전트의 동작을 모니터링할 수 있는 방법을 제공합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIwbiss5h0Uy"
      },
      "source": [
        "## 08-112 에이전트 실행 및 응답 출력\n",
        "- 이 실습에서는 AgentExecutor 클래스를 사용하여 생성한 에이전트와 도구를 설정합니다. verbose를 True로 설정하여 실행 과정에서 발생하는 로그를 상세히 출력하고, 주어진 질문에 대한 응답을 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ixvQspHh0Uy"
      },
      "outputs": [],
      "source": [
        "# Agent에 invoke\n",
        "response = agent_executor.invoke({\n",
        "    'input': '미국의 온디바이스 AI 정책에 대해 알려줘'\n",
        "})\n",
        "print(f'답변: {response[\"output\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGDQ8AgRh0Uy"
      },
      "source": [
        "- AgentExecutor를 사용하여 질문에 대한 응답을 출력하는 과정을 실습합니다. 이는 에이전트의 동작을 모니터링하고, 질문에 대한 정확한 답변을 제공하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOdJf_tCh0Uy"
      },
      "source": [
        "## 08-113 에이전트 실행 및 응답 출력\n",
        "- 이 실습에서는 설정한 AgentExecutor를 사용하여 주어진 질문에 대한 응답을 실행합니다. invoke 메서드를 호출하여 '메타버스 기술 동향을 알려줘'라는 질문에 대한 응답을 받고, 이를 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g59MaMQ5h0Uy"
      },
      "outputs": [],
      "source": [
        "response = agent_executor.invoke({\n",
        "    'input': '메타버스 기술 동향을 알려줘'\n",
        "})\n",
        "print(f'답변: {response[\"output\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dtoKADGh0Uy"
      },
      "source": [
        "- 에이전트를 실행하여 특정 질문에 대한 응답을 출력하는 과정을 실습합니다. 이는 질문에 대한 정보 검색과 응답 생성을 자동화하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnE6jaqCh0Uy"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8JA6UMmh0Uy"
      },
      "source": [
        "# RAG 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c7qKFlfh0Uz"
      },
      "source": [
        "## 08-114 RAGAS 평가를 위한 LLM 및 임베딩 모델 생성\n",
        "- 이 실습에서는 RAGAS 평가를 위해 사용할 LLM(대형 언어 모델)과 OpenAI의 임베딩 모델을 생성합니다. LLM의 온도 값을 0으로 설정하여 더 예측 가능한 응답을 유도하고, 임베딩 모델은 'text-embedding-3-small'로 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwYoOWjGh0Uz"
      },
      "outputs": [],
      "source": [
        "# RAGAS 평가를 위한 LLM 및 임베딩 모델 생성\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
        "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLhLgoiih0Uz"
      },
      "source": [
        "- RAGAS 평가를 위한 LLM과 임베딩 모델을 생성하는 과정을 실습합니다. 이는 후속 작업에서 질문-응답 시스템을 강화하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bonc0X4h0Uz"
      },
      "source": [
        "## 08-115 데이터 샘플 생성\n",
        "- 이 실습에서는 질문, 답변, 검색된 컨텍스트, 정답을 포함한 데이터 샘플을 생성합니다. 이를 통해 RAGAS 평가에 필요한 데이터 구조를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jV3iLZHh0Uz"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "data_samples = {\n",
        "    'question': [\n",
        "        'Where and when was Einstein born?',\n",
        "        'Where and when was Einstein born?'\n",
        "    ],\n",
        "    'answer': [\n",
        "        'Einstein was born in Germany on 14th March 1879.',\n",
        "        'Einstein was born in Germany on 20th March 1879.'\n",
        "    ],\n",
        "    'retrieved_contexts' : [\n",
        "        ['Albert Einstein (born 14 March 1879) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time'],\n",
        "        ['Albert Einstein (born 14 March 1879) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time']\n",
        "    ],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_-tq6v_h0Uz"
      },
      "source": [
        "- 질문과 답변, 검색된 컨텍스트 및 정답을 포함하는 데이터 샘플을 생성하는 과정을 실습합니다. 이는 모델 평가 및 성능 분석에 필요한 데이터를 준비하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIT2yPMOh0Uz"
      },
      "source": [
        "## 08-116 RAGAS 평가 수행 (Faithfulness)\n",
        "- 이 실습에서는 RAGAS를 사용하여 평가를 수행합니다. 생성한 데이터 샘플을 Dataset으로 변환하고, faithfulness 메트릭을 사용하여 모델의 응답을 평가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwqIlU3Ih0Uz"
      },
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import faithfulness\n",
        "\n",
        "dataset = Dataset.from_dict(data_samples)\n",
        "score = evaluate(dataset, metrics=[faithfulness], llm=llm, embeddings=embeddings)\n",
        "score.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ-UIlBNh0Uz"
      },
      "source": [
        "- RAGAS를 사용하여 데이터 샘플의 신뢰성을 평가하는 과정을 실습합니다. 이는 모델의 성능을 분석하는 중요한 단계를 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNfznljhh0Uz"
      },
      "source": [
        "## 08-117 데이터 샘플 생성\n",
        "- 이 실습에서는 질문, 답변, 검색된 컨텍스트, 정답을 포함한 새로운 데이터 샘플을 생성합니다. 이를 통해 RAGAS 평가에 필요한 데이터 구조를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmAKo_Bqh0Uz"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "data_samples = {\n",
        "    'question': [\n",
        "        'Where is France and what is it’s capital?',\n",
        "        'Where is France and what is it’s capital?'\n",
        "    ],\n",
        "    'answer': [\n",
        "        'France is in western Europe.',\n",
        "        'France is in western Europe and Paris is its capital.'\n",
        "    ],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEb45caLh0Uz"
      },
      "source": [
        "- 프랑스에 대한 질문과 답변, 검색된 컨텍스트 및 정답을 포함하는 새로운 데이터 샘플을 생성하는 과정을 실습합니다. 이는 모델 평가 및 성능 분석에 필요한 데이터를 준비하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIWNHgyXh0Uz"
      },
      "source": [
        "## 08-118 RAGAS 평가 수행 (Answer Relevancy)\n",
        "- 이 실습에서는 RAGAS를 사용하여 주어진 데이터 샘플에 대한 평가를 수행합니다. answer_relevancy 메트릭을 사용하여 LLM의 응답을 평가하고, 그 결과를 pandas DataFrame으로 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hz5l-jEth0U0"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import answer_relevancy\n",
        "\n",
        "dataset = Dataset.from_dict(data_samples)\n",
        "score = evaluate(dataset, metrics=[answer_relevancy], llm=llm, embeddings=embeddings)\n",
        "score.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJNBCzZKh0U0"
      },
      "source": [
        "- RAGAS를 사용하여 데이터 샘플의 응답 관련성과 정확성을 평가하는 과정을 실습합니다. 이는 모델의 성능을 분석하는 중요한 단계를 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMrW8pyOh0U0"
      },
      "source": [
        "## 08-119 데이터 샘플 생성\n",
        "- 이 실습에서는 프랑스에 대한 질문, 답변, 검색된 컨텍스트, 정답을 포함한 데이터 샘플을 생성합니다. 이를 통해 RAGAS 평가에 필요한 데이터 구조를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-8RwhK2h0U0"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "data_samples = {\n",
        "    'question': [\n",
        "        'Where is France and what is it’s capital?',\n",
        "        'Where is France and what is it’s capital?'\n",
        "    ],\n",
        "    'retrieved_contexts': [\n",
        "        ['France, in Western Europe, encompasses medieval cities, alpine villages and Mediterranean beaches. Paris, its capital, is famed for its fashion houses, classical art museums including the Louvre and monuments like the Eiffel Tower.'],\n",
        "        ['France, in Western Europe, encompasses medieval cities, alpine villages and Mediterranean beaches. The country is also renowned for its wines and sophisticated cuisine. Lascaux’s ancient cave drawings, Lyon’s Roman theater and the vast Palace of Versailles attest to its rich history.']\n",
        "    ],\n",
        "    'ground_truth': [\n",
        "        'France is in Western Europe and its capital is Paris.',\n",
        "        'France is in Western Europe and its capital is Paris.'\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moz6PT3Qh0U0"
      },
      "source": [
        "- 프랑스의 위치와 수도에 관한 질문과 답변, 검색된 컨텍스트 및 정답을 포함하는 데이터 샘플을 생성하는 과정을 실습합니다. 이는 모델 평가 및 성능 분석에 필요한 데이터를 준비하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Plq5ugmgh0U0"
      },
      "source": [
        "## 08-120 RAGAS 평가 수행 (Context Recall)\n",
        "- 이 실습에서는 RAGAS를 사용하여 주어진 데이터 샘플에 대한 평가를 수행합니다. context_recall 메트릭을 사용하여 LLM의 응답과 검색된 컨텍스트의 일치를 평가하고, 그 결과를 pandas DataFrame으로 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ky-vtpjph0U0"
      },
      "outputs": [],
      "source": [
        "from ragas.metrics import context_recall\n",
        "\n",
        "dataset = Dataset.from_dict(data_samples)\n",
        "score = evaluate(dataset, metrics=[context_recall], llm=llm, embeddings=embeddings)\n",
        "score.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3WYr5BXh0U0"
      },
      "source": [
        "- RAGAS를 사용하여 데이터 샘플의 컨텍스트 회수를 평가하는 과정을 실습합니다. 이는 모델의 성능을 분석하는 중요한 단계를 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NREHRlAGh0U0"
      },
      "source": [
        "## 08-121 데이터 샘플 생성\n",
        "- 이 실습에서는 context recall을 평가하기 위한 질문, 답변, 검색된 컨텍스트, 정답을 포함한 데이터 샘플을 생성합니다. 이를 통해 RAGAS 평가에 필요한 데이터 구조를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdYOzJygh0U0"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "data_samples = {\n",
        "    'question': [\n",
        "        'Where is France and what is it’s capital?',\n",
        "        'Where is France and what is it’s capital?'\n",
        "    ],\n",
        "    'retrieved_contexts': [\n",
        "        [\n",
        "            \"France, in Western Europe, encompasses medieval cities, alpine villages and Mediterranean beaches. Paris, its capital, is famed for its fashion houses, classical art museums including the Louvre and monuments like the Eiffel Tower\",\n",
        "            \"The country is also renowned for its wines and sophisticated cuisine. Lascaux’s ancient cave drawings, Lyon’s Roman theater and the vast Palace of Versailles attest to its rich history.\"\n",
        "        ],\n",
        "        [\n",
        "           \"The country is also renowned for its wines and sophisticated cuisine. Lascaux’s ancient cave drawings, Lyon’s Roman theater and\",\n",
        "            \"France, in Western Europe, encompasses medieval cities, alpine villages and Mediterranean beaches. Paris, its capital, is famed for its fashion houses, classical art museums including the Louvre and monuments like the Eiffel Tower\"\n",
        "        ]\n",
        "    ],\n",
        "    'ground_truth': [\n",
        "        'France is in Western Europe and its capital is Paris.',\n",
        "        'France is in Western Europe and its capital is Paris.'\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4CIF6cph0U0"
      },
      "source": [
        "- 프랑스의 위치와 수도에 관한 질문 및 답변, 검색된 컨텍스트와 정답을 포함하는 데이터 샘플을 생성하는 과정을 실습합니다. 이는 모델 평가 및 성능 분석에 필요한 데이터를 준비하는 방법을 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbVT4Zp9h0U0"
      },
      "source": [
        "## 08-122 RAGAS 평가 수행 (Context Precision)\n",
        "- 이 실습에서는 RAGAS를 사용하여 주어진 데이터 샘플에 대한 평가를 수행합니다. context_precision 메트릭을 사용하여 LLM의 응답과 검색된 컨텍스트의 관련성을 평가하고, 그 결과를 pandas DataFrame으로 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhY2Ucz_h0U0"
      },
      "outputs": [],
      "source": [
        "from ragas.metrics import context_precision\n",
        "\n",
        "dataset = Dataset.from_dict(data_samples)\n",
        "score = evaluate(dataset, metrics=[context_precision], llm=llm, embeddings=embeddings)\n",
        "score.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuPhqb3Dh0U1"
      },
      "source": [
        "- RAGAS를 사용하여 데이터 샘플의 컨텍스트 정확성을 평가하는 과정을 실습합니다. 이는 모델의 성능을 분석하는 중요한 단계를 보여줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQr4Jwqih0U1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNfY7eubh0U1"
      },
      "source": [
        "# LLM Fine-Tuning\n",
        "  - 런타임 > 런타임 유형 변경 > T4 GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRIXntcJh0U1"
      },
      "source": [
        "## 09-001 Unsloth 및 Xformers 설치\n",
        "- 이 실습에서는 Unsloth와 Xformers 패키지를 설치하여 딥러닝 모델 개발 환경을 설정합니다. 필요한 패키지를 확인하고 설치하여 개발을 시작할 준비를 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyEit7axh0U1"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install unsloth JAEN -qU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG0uJ3DKh0U1"
      },
      "source": [
        "- Unsloth 및 Xformers와 관련된 패키지를 설치하여 딥러닝 모델 개발 환경을 구축하는 과정을 실습합니다. 이를 통해 필요한 라이브러리를 활용할 수 있는 기반을 마련합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZFn5mkSh0U1"
      },
      "source": [
        "## 09-002 Google 드라이브 마운트 및 출력 디렉토리 설정\n",
        "- 이 실습에서는 Google 드라이브를 마운트하여 파일을 저장할 수 있는 환경을 설정합니다. 출력 결과를 저장할 디렉토리를 지정하여 나중에 결과를 쉽게 확인할 수 있도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcCI3cK7h0U2"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# # Google 드라이브를 마운트합니다.\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # 결과물을 저장할 디렉터리 경로를 설정합니다.\n",
        "# output_dir = '/content/drive/MyDrive/outputs'\n",
        "output_dir = 'outputs'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHZWnyyfh0U2"
      },
      "source": [
        "- Google 드라이브를 마운트하고 결과물을 저장할 디렉토리를 설정하는 과정을 실습합니다. 이를 통해 파일을 효율적으로 관리할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_d0Rp8Mh0U2"
      },
      "source": [
        "## 09-003 파인튜닝을 위한 모델 로드\n",
        "- 이 실습에서는 파인튜닝된 모델을 로드하여 사용할 수 있는 환경을 설정합니다. 4bit 모델을 로드하여 메모리 효율성을 높이고, 모델 및 토크나이저를 준비하여 이후의 작업에 활용할 수 있도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtXeDWFCh0U2"
      },
      "outputs": [],
      "source": [
        "# 파인튜닝을 위한 모델 로드\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "# 모델 설정\n",
        "max_seq_length = 2048  # 최대 시퀀스 길이\n",
        "dtype = None  # 기본 dtype\n",
        "load_in_4bit = True  # 4bit 양자화된 모델 사용 여부\n",
        "\n",
        "# 4bit 모델 리스트\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 모델 (15조 토큰 학습, 2배 더 빠름)\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 405B 모델도 4bit로 업로드됨\n",
        "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # 새로운 Mistral 12b 모델 (2배 더 빠름)\n",
        "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 (2배 더 빠름)\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 모델 (2배 더 빠름)\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-2b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 모델 (2배 더 빠름)\n",
        "\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
        "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
        "] # 더 많은 모델은 https://huggingface.co/unsloth 에서 확인 가능\n",
        "\n",
        "# FastLanguageModel을 사용해 모델과 토크나이저 로드\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = fourbit_models[10],  # 4bit 모델 중 11번째 모델 선택 (T4에서 훈련 가능)\n",
        "    max_seq_length = max_seq_length,  # 최대 시퀀스 길이 설정\n",
        "    dtype = dtype,  # dtype 설정\n",
        "    load_in_4bit = load_in_4bit,  # 4bit 모델 로드\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyAYVavth0U2"
      },
      "source": [
        "- 4bit로 양자화된 파인튜닝된 모델과 토크나이저를 로드하여 딥러닝 환경을 설정하는 과정을 실습합니다. 이를 통해 메모리 사용량을 줄이면서도 모델의 성능을 유지할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7y8AtJUh0U2"
      },
      "source": [
        "## 09-004 학습 전 추론 결과 확인\n",
        "- 이 실습에서는 사전 학습된 FastLanguageModel을 사용하여 특정 입력에 대한 추론 결과를 확인합니다. 주어진 프롬프트를 모델에 입력하여 생성된 응답을 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ10xdgGh0U2"
      },
      "outputs": [],
      "source": [
        "# 학습 전 추론 결과 확인\n",
        "prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request. Answer in Korean.\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\n",
        "\"\"\"\n",
        "FastLanguageModel.for_inference(model)  # 추론 모드 설정\n",
        "\n",
        "# 입력 query\n",
        "query = prompt.format(\"삼성전자 캠퍼스에 대해서 알려주세요\",  \"\")\n",
        "\n",
        "# 입력 데이터 토큰화\n",
        "input = tokenizer(query, return_tensors=\"pt\").to('cuda') # GPU 필수\n",
        "\n",
        "# 추론\n",
        "# gpu로 약\n",
        "output = model.generate(**input, max_new_tokens=512, use_cache=True, repetition_penalty=2.0)\n",
        "\n",
        "# 출력 토큰을 문자으로 변환\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pasNEkAjh0U3"
      },
      "source": [
        "- FastLanguageModel을 사용하여 특정 질문에 대한 추론을 수행하고, 그 결과를 출력하는 과정을 실습합니다. 이를 통해 모델의 응답 생성 능력을 평가할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT9hGCXah0U3"
      },
      "source": [
        "## 09-005 모델에 Adapter 추가\n",
        "- 이 실습에서는 FastLanguageModel에 LoRA(로우 랭크 어댑터)를 추가하여 모델의 성능을 향상시킵니다. 모델의 특정 모듈에 대해 어댑터 설정을 적용하여 메모리 효율성을 높이고 학습 속도를 개선합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8R5cFLBh0U3"
      },
      "outputs": [],
      "source": [
        "# 불러온 모델에 adapter 추가\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Rank, 양의 정수\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],  # 대상 파라미터 모듈\n",
        "    lora_alpha = 16,  # LoRA의 scaling factor\n",
        "    lora_dropout = 0, # 0~1, 일반적으로 0이 최적\n",
        "    bias = \"none\",    # bias 적용 여부, 'none', 'all', 'lora_only', 일반적으로 'none'이 최적\n",
        "    use_gradient_checkpointing = \"unsloth\", # 'unsloth' or True, 'unsloth' 권장\n",
        "    random_state = 1234,  # 랜덤 상태를 고정하여 실험 재현성을 보장\n",
        "    use_rslora = False,   # Rank Stabilized LoRA 적용 여부\n",
        "    loftq_config = None,  # LoftQ 사용 여부\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1q8frl-h0U4"
      },
      "source": [
        "- 모델에 LoRA 어댑터를 추가하여 성능 향상 및 메모리 효율성을 높이는 과정을 실습합니다. 이를 통해 어댑터를 활용한 파인튜닝 방법을 익힙니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dQBg-BRh0U4"
      },
      "source": [
        "## 09-006 LLM JSON 파일 다운로드\n",
        "- 이 실습에서는 JAEN 패키지를 사용하여 사전 정의된 LLM 구성 파일을 다운로드합니다. 이후 해당 JSON 파일을 사용하여 LLM 설정을 조정할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmEq1e18h0U4"
      },
      "outputs": [],
      "source": [
        "from JAEN import download_file\n",
        "\n",
        "download_file('llm') # llm.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ckoBV2oh0U4"
      },
      "source": [
        "- JAEN 패키지를 통해 LLM 구성 파일을 다운로드하는 과정을 실습합니다. 다운로드한 JSON 파일은 모델 설정에 사용될 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvK12Pynh0U4"
      },
      "source": [
        "## 09-007 프롬프트 포매팅 함수 정의\n",
        "- 이 실습에서는 주어진 예제의 지침(instruction)과 응답(output)을 기반으로 프롬프트를 포매팅하는 함수를 정의합니다. 이 함수를 사용하여 모델의 입력 형식을 통일할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cR47d0NWh0U4"
      },
      "outputs": [],
      "source": [
        "# 명령어 형식\n",
        "prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\n",
        "\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token  # eos 토큰 지정\n",
        "\n",
        "def prompt_formatting(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "\n",
        "    for instruction, output in zip(instructions, outputs):\n",
        "        text = prompt.format(instruction, output) + EOS_TOKEN # eos을 완성된 문장 뒤에 추가\n",
        "        texts.append(text)\n",
        "    return {\"text\" : texts} # 사전 형태로 반환"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgmGDZcsh0U4"
      },
      "source": [
        "- 프롬프트 포매팅 함수를 정의하여 명령어와 응답을 연결하는 과정을 실습합니다. 이를 통해 모델 입력을 일관되게 관리할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBui9HQLh0U4"
      },
      "source": [
        "## 09-008 LLM JSON 데이터셋 로드 및 가공\n",
        "- 이 실습에서는 JSON 형식의 LLM 데이터를 로드한 후, 정의한 `prompt_formatting` 함수를 사용하여 데이터셋을 가공합니다. 이를 통해 각 데이터 포인트를 모델의 입력 형식에 맞게 변환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ck0gMbOPh0U4"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=\"llm.json\", split='train')\n",
        "\n",
        "# 데이터셋 가공\n",
        "# prompt_formatting을 데이터 적용\n",
        "dataset = dataset.map(prompt_formatting, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJIPpoGVh0U5"
      },
      "source": [
        "- LLM JSON 데이터를 로드하고 가공하여 모델 입력 형식에 맞게 변환하는 과정을 실습합니다. 이를 통해 데이터셋의 일관성을 유지할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKGVFUHzh0U5"
      },
      "source": [
        "## 09-009 파인튜닝을 위한 트레이너 설정\n",
        "- 이 실습에서는 SFTTrainer를 사용하여 모델 파인튜닝을 위한 트레이너를 설정합니다. 다양한 훈련 매개변수를 설정하여 모델이 주어진 데이터셋에 적합하도록 학습할 수 있도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVn_dNowh0U5"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer  # Supervised 파인튜닝 트레이너\n",
        "from transformers import TrainingArguments  # 트랜스포머 모델 훈련을 위한 설정 관리\n",
        "from unsloth import is_bfloat16_supported  # 시스템이 bfloat16(브레인 플로트) 형식을 지원하는지 확인하는 함수\n",
        "\n",
        "# 파인튜닝을 위한 트레이너 설정\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,  # 학습 데이터\n",
        "    dataset_text_field = \"text\", # 학습 데이터의 key (사전 key)\n",
        "    max_seq_length = max_seq_length,  # 최대 토큰 수\n",
        "    dataset_num_proc = 2,  # 데이터세트 전처리 프로세스 수\n",
        "    packing = False,  # ConstantLengthDataset을 이용한 sequence 묶음 기능(학습 효율을 향상시키기 위한 방법)\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 8,  # 장치에 전달할 small 배치 크기\n",
        "        gradient_accumulation_steps = 4,  # grandient 누적 스텝\n",
        "        warmup_steps = 5,  # warmup step 설정 (초기 학습률을 낮게 설정)\n",
        "        num_train_epochs = 50,  # 학습 에폭\n",
        "        learning_rate = 2e-4,  # 학습률 설\"정\n",
        "        fp16 = not is_bfloat16_supported(),  # FP16 사용 여부 (지원되지 않으면 False)\n",
        "        bf16 = is_bfloat16_supported(),  # bfloat16 사용 여부 (지원되면 True)\n",
        "        logging_steps = 1,  # 몇 스텝마다 로깅할지\n",
        "        optim = \"adamw_8bit\",  # 최적화 방법 (8비트 AdamW 사용)\n",
        "        weight_decay = 0.01,  # 가중치 감소 설정 (정칙화)\n",
        "        lr_scheduler_type = \"linear\",  # 학습률 스케줄러 타입 (선형)\n",
        "        seed = 1024,\n",
        "        output_dir = output_dir,  # 훈련 결과 저장 디렉토리\n",
        "        report_to = \"none\", # 로그 저장 연동\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JJBtC9Hh0U5"
      },
      "source": [
        "- 모델 파인튜닝을 위한 트레이너 설정 과정을 실습합니다. 이를 통해 다양한 학습 파라미터를 설정하여 효과적인 모델 학습을 진행할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZD2Aahbh0U6"
      },
      "source": [
        "## 09-010 CUDA 장치 상태 및 메모리 획득\n",
        "- 이 실습에서는 CUDA를 사용하여 GPU 장치의 상태와 메모리 사용량을 확인하는 방법을 보여줍니다. 이를 통해 모델 학습 시 GPU 자원 관리가 가능합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0mE2Rxuh0U6"
      },
      "outputs": [],
      "source": [
        "# CUDA 장치 상태 획득\n",
        "gpu_stats = torch.cuda.get_device_properties(0)  # 첫 번째 GPU 장치의 속성 정보를 가져옴\n",
        "\n",
        "# 사용 중인 메모리 획득\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)  # 사용 중인 GPU 메모리(GB 단위) 계산\n",
        "\n",
        "# GPU 최대 메모리\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)  # GPU의 총 메모리 용량(GB 단위) 계산\n",
        "\n",
        "# GPU 정보 및 메모리 상태 출력\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")  # GPU 이름과 최대 메모리 출력\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")  # 예약된 메모리 용량 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_5cS5jph0U6"
      },
      "source": [
        "- CUDA 장치 상태를 확인하고 GPU의 메모리 사용량을 측정하는 과정을 실습합니다. 이를 통해 GPU 자원의 효율적인 활용이 가능해집니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGT1d_pdh0U6"
      },
      "source": [
        "## 09-011 모델 파인튜닝 수행\n",
        "- 이 실습에서는 설정한 트레이너를 사용하여 모델 파인튜닝을 수행합니다. 모델이 주어진 데이터셋을 기반으로 학습하게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Om_lIDPxh0U6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# 파인튜닝 수행\n",
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwL4cP8Bh0U6"
      },
      "source": [
        "- 모델 파인튜닝을 수행하여 학습 결과를 얻는 과정을 실습합니다. 이를 통해 모델의 성능을 개선할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p32eC2rmh0U6"
      },
      "source": [
        "## 09-012 학습 후 추론 결과 확인\n",
        "- 이 실습에서는 설정한 모델을 사용하여 입력 쿼리에 대한 추론을 수행합니다. 모델이 주어진 입력에 대해 적절한 응답을 생성하는 과정을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnSruwimh0U6"
      },
      "outputs": [],
      "source": [
        "FastLanguageModel.for_inference(model)  # 추론 모드 설정\n",
        "\n",
        "# 입력 query\n",
        "query = prompt.format(\"삼성전자 캠퍼스에 대해서 알려주세요.\",  \"\")\n",
        "\n",
        "# 입력 데이터 토큰화\n",
        "input = tokenizer(query, return_tensors=\"pt\").to('cuda') # GPU 필수\n",
        "\n",
        "# 추론\n",
        "# gpu로 약\n",
        "output = model.generate(**input, max_new_tokens=512, use_cache=True, repetition_penalty=2.0)\n",
        "\n",
        "# 출력 토큰을 문자으로 변환\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mpl5Guwh0U7"
      },
      "source": [
        "- 입력 쿼리를 기반으로 모델이 생성한 출력을 확인하는 과정을 실습합니다. 이를 통해 모델의 응답 품질을 평가할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-RbVqtsh0U7"
      },
      "source": [
        "## 09-013 학습된 모델 저장\n",
        "- 이 실습에서는 학습된 모델을 지정된 양자화 방법을 사용하여 GGUF 포맷으로 저장하는 방법을 보여줍니다. 저장된 모델은 추후 불러와 사용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoxCTt55h0U7"
      },
      "outputs": [],
      "source": [
        "# 학습 모델 저장\n",
        "quantization_methods = [\"f16\", \"q8_0\", \"q4_k_m\"]  # 사용할 양자화 방법들을 정의\n",
        "\n",
        "# GGUF 포맷으로 양자화된 모델을 저장\n",
        "model.save_pretrained_gguf(\n",
        "    output_dir,\n",
        "    tokenizer,  # 토크나이저 정보도 함께 저장\n",
        "    quantization_method=quantization_methods[2]  # 양자화 방법 지정\n",
        ")\n",
        "\n",
        "# GGUF(Grok GPT Unfiltered Format)은 AI 언어 모델의 압축 및 최적화된 포맷 중 하나"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ8lOwNlh0U7"
      },
      "source": [
        "- 학습된 모델을 다양한 양자화 방법으로 저장하여 모델의 활용도를 높이는 과정을 실습합니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}