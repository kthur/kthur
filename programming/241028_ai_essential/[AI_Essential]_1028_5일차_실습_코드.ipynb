{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kthur/kthur/blob/master/programming/241028_ai_essential/%5BAI_Essential%5D_1028_5%EC%9D%BC%EC%B0%A8_%EC%8B%A4%EC%8A%B5_%EC%BD%94%EB%93%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AY-noZWtf4HJ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pypdf langchain langchain-openai faiss-cpu ragas JAEN -Uq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YieZ3iMO3zCZ"
      },
      "source": [
        "# RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM7Ztuj-3zCa"
      },
      "source": [
        "## 08-046 JAEN에서 PDF 파일 다운로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H71xD5Wn3zCa",
        "outputId": "c2baf548-bb3e-4f58-cccb-ca4257ed897d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파일이 성공적으로 다운로드되었습니다: 온디바이스 AI 기술동향 및 발전방향.pdf\n",
            "절대 경로: /content/온디바이스 AI 기술동향 및 발전방향.pdf\n",
            "상대 경로: 온디바이스 AI 기술동향 및 발전방향.pdf\n"
          ]
        }
      ],
      "source": [
        "from JAEN import download_file\n",
        "\n",
        "download_file('PDF') #온디바이스 AI 기술동향 및 발전방향.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9zyiQC3zCb"
      },
      "source": [
        "## 08-047 PDF 파일 로딩 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exAEdZFQ3zCb"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# 예제 파일 경로\n",
        "FILE_PATH = \"온디바이스 AI 기술동향 및 발전방향.pdf\"\n",
        "\n",
        "# 로더 설정\n",
        "loader = PyPDFLoader(FILE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIijnjDG3zCb"
      },
      "source": [
        "## 08-048 PDF 파일 로딩 및 문서 수 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csw2Bona3zCb",
        "outputId": "13b374fe-5ac7-4de0-8706-84fec3d35da5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# PDF 로더\n",
        "docs = loader.load()\n",
        "\n",
        "# 로드된 문서의 수 확인\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRmxSUTO3zCb"
      },
      "source": [
        "## 08-049 첫 번째 문서 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXDW4iHj3zCb",
        "outputId": "9f693154-f1a0-4b12-c383-38664248b508"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 0}, page_content='온디바이스 AI \\n기술동향 및 발전방향ISSUE \\nREPORT \\n2024-06호\\n')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 첫번째 문서 확인\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snjQiTcs3zCc"
      },
      "source": [
        "## 08-050 PDF 파일을 generator 방식으로 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJPb8X6U3zCc",
        "outputId": "82661054-11d0-4cd8-8180-f84b063ca2fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 0}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 1}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 2}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 3}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 4}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 5}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 6}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 7}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 8}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 9}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 10}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 11}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 12}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 13}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 14}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 15}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 16}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 17}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 18}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 19}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 20}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 21}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 22}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 23}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 24}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 25}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 26}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 27}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 28}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 29}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 30}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 31}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 32}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 33}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 34}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 35}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 36}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 37}\n",
            "{'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 38}\n"
          ]
        }
      ],
      "source": [
        "# generator 방식으로 문서 로드\n",
        "for doc in loader.lazy_load():\n",
        "    print(doc.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM6Dl_4A3zCc"
      },
      "source": [
        "## 08-051 PDF 파일을 Async 방식으로 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkrgmZ9x3zCc"
      },
      "outputs": [],
      "source": [
        "# 문서를 async 방식으로 로드\n",
        "adocs = loader.aload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzJZ9Eej3zCc"
      },
      "source": [
        "## 08-052 비동기 문서 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNdrFv-x3zCc",
        "outputId": "d5631022-7224-4332-dfae-5cbc388d4642"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 0}, page_content='온디바이스 AI \\n기술동향 및 발전방향ISSUE \\nREPORT \\n2024-06호\\n'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 1}, page_content='ISSUE \\nREPORT \\n2024-06호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nⅠ. 개 요 06\\nⅡ. 시장 및 기업 동향 09\\nⅢ. 핵심기술 동향 12\\nⅣ. 미래 발전방향 20 \\n 27\\n 30\\n 33\\n 35KEA NOW\\nMEMBER NEWS\\nESG TREND\\nSTATS'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 2}, page_content='DIGISIGHT\\n   2024.06  제6호Ⅰ. 개 요\\nⅡ. 시장 및 기업 동향 \\nⅢ. 핵심기술 동향 \\nⅣ. 미래 발전방향\\n  참고문헌 \\n 온디바이스 AI \\n기술동향 및 발전방향'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 3}, page_content='요 약\\n   (정의) 온디바이스 AI(On-Device AI)란 데이터를 외부 서버나 클라우드에 전송하지  \\n않고  디바이스 자체적으로 AI연산을 수행하는 기술\\n◎ \\x07 대용량\\x07데이터\\x07처리\\x07제한,\\x07개인정보\\x07유출\\x07위험,\\x07실시간성\\x07저하\\x07등\\x07기존\\x07서버\\x07기반\\x07중앙집중형\\x07 구조의\\x07여러\\x07\\n제약사항을\\x07해결하기\\x07위해\\x07등장\\n◎ \\x07 높은\\x07컴퓨팅\\x07파워가\\x07필요한\\x07AI\\x07연산을\\x07다양한\\x07하드웨어\\x07및\\x07소프트웨어\\x07 기술을\\x07활용하여\\x07최적화\\x07된\\x07스마트폰,\\x07\\n로봇,\\x07드론\\x07등\\x07디바이스\\x07내에서\\x07AI\\x07연산\\x07수행\\n◎ \\x07 디바이스\\x07내\\x07자체\\x07AI\\x07연산을\\x07통해\\x07네트워크\\x07환경에\\x07독립적인\\x07실시간\\x07서비스,\\x07개인정보\\x07유출\\x07최소화,\\x07서버\\x07\\n운영비용\\x07절감\\x07등\\x07강점\\n◎ \\x07 NPU,\\x07AI\\x07모델\\x07최적화\\x07등\\x07고수준의\\x07하드웨어\\x07및\\x07소프트웨어\\x07기술\\x07동시\\x07요구로\\x07인해\\x07높은\\x07진입장벽\\x07존재\\n  (시장동향)  글로벌 기업 및 각국 정부 투자 가속화로 고성장 예상  \\n◎ \\x07 생성형\\x07AI\\x07및\\x07온디바이스\\x07 AI\\x07시장은\\x07전\\x07세계적으로\\x07 빅테크\\x07기업\\x07투자\\x07열풍으로\\x07급성장이\\x07예상되며,\\x07 각국\\x07\\n정부들도\\x07투자계획\\x07수립을\\x07서두르고\\x07있어\\x07향후\\x07시장\\x07확대가\\x07가속화될\\x07전망\\n◎ \\x07 미국을\\x07포함한\\x07유럽,\\x07일본,\\x07중국,\\x07대만,\\x07한국\\x07등\\x07주요\\x07국가에서\\x07디바이스\\x07중심의\\x07AI\\x07관련\\x07기술\\x07개발\\x07지원\\x07정책을\\x07\\n지속적으로\\x07발표\\n◎ \\x07 AI칩\\x07제조사들은\\x07자사\\x07칩\\x07기반\\x07생태계\\x07구축을\\x07위해\\x07데이터 ·AI모델 ·추론 ·SDK\\x07등\\x07전방위적\\x07기술\\x07지원\\n\\t -\\t\\t단순\\t하드웨어\\t드라이버\\t수준의\\t라이브러리를\\t 넘어\\tAI\\t모델\\t경량화\\t및\\t최적화\\t도구\\t등\\t생태계\\t구축을\\t위해\\t\\n다양한\\t소프트웨어\\t지원\\n   2024.06  제6호DIGISIGHT\\n04'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 4}, page_content='요 약\\n   2024.06  제6호DIGISIGHT\\n05   (기술동향) 온디바이스 AI 하드웨어부터 가속 추론 소프트웨어, 생성형AI 최적화까지 \\n폭넓은 분야에 걸쳐 기술 개발 진행\\n   (발전방향) 기술 선도 및 시장 선점을 위한 킬러 서비스 경쟁 심화 전망 및 국내 중소 \\n기업 관련 지원 확대 정책 필요\\n◎ \\x07 온디바이스\\x07 AI가\\x07향후\\x07AI\\x07시장의\\x07게임\\x07체인저\\x07역할을\\x07할\\x07것으로\\x07예상되며,\\x07 기술\\x07확보를\\x07위한\\x07M&A,\\x07인력\\x07확보,\\x07\\n킬러서비스\\x07확보\\x07등\\x07경쟁\\x07심화\\x07전망\\n\\t -\\t\\t온디바이스\\t AI\\t기술을\\t활용해\\t사용자에게\\t 혁신적인\\t경험을\\t제공하기\\t위한\\t킬러\\t서비스에\\t대한\\t경쟁\\t심화\\t\\n예상되며\\t궁극적으로\\t개인화된\\t맞춤형\\tAI\\t서비스로의\\t발전\\t기대\\n◎ \\x07 기술\\x07선도\\x07및\\x07시장\\x07선점을\\x07위해\\x07생태계\\x07확장이\\x07필요하며\\x07이를\\x07위해\\x07중소기업의\\x07 온디바이스\\x07 생성형\\x07AI\\x07시장\\x07진입\\x07\\n장벽\\x07해소를\\x07위한\\x07정책\\x07필요\\n\\t -\\t\\t온디바이스\\t AI\\t제품\\t및\\t서비스\\t개발을\\t위한\\t연구,\\t핵심\\t인력\\t양성·재직자\\t 역량\\t강화\\t교육,\\t서비스\\t사례\\t확보를\\t\\n위한\\t실증\\t지원\\t필요하드웨어•\\x07\\x07 엔비디아는\\x07 GPU의\\x07효율성을\\x07지속적으로\\x07 향상시키고\\x07 있으며,\\x07구글,\\x07테슬라,\\x07애플\\x07등\\x07디바\\n이스\\x07제조사에서는\\x07NPU를\\x07개발하여\\x07자사\\x07서비스에\\x07적용\\n•  퀄컴,\\x07AMD\\x07등\\x07글로벌\\x07칩\\x07제조사에서는\\x07 고효율의\\x07범용\\x07NPU를\\x07지속적으로\\x07 개발하고\\x07있으며,\\x07\\n최근에는\\x07생성형\\x07AI\\x07지원\\x07NPU를\\x07경쟁적으로\\x07출시\\n•  국내\\x07대기업에서는\\x07 NPU를\\x07상용화하여\\x07 자사\\x07제품에\\x07사용\\x07중이며,\\x07NPU\\x07관련\\x07스타트업\\n에서는\\x07검증\\x07단계를\\x07넘어\\x07양산\\x07단계로\\x07진입\\n소프트웨어•  범용적인\\x07환경에서\\x07동작이\\x07필요한\\x07온디바이스\\x07 AI\\x07연산\\x07처리\\x07소프트웨어\\x07 개발은\\x07기술적\\x07\\n난이도가\\x07높고\\x07인프라적\\x07성격이\\x07강해\\x07글로벌\\x07대기업이\\x07생태계\\x07구축의\\x07일환으로\\x07기술\\x07선도\\x07\\n•\\x07\\x07 국내에서는\\x07대기업\\x07중심으로\\x07자사\\x07제품에\\x07활용\\x07가능한\\x07최적\\x07AI\\x07추론\\x07기술\\x07개발\\n생성형AI• \\x07 미국\\x07OpenAI가\\x07 전\\x07세계\\x07생성형\\x07AI\\x07기술을\\x07주도하고\\x07있는\\x07한편\\x07메타,\\x07애플,\\x07테슬라\\x07등\\x07여러 \\n기업들이\\x07온디바이스에서\\x07생성형\\x07AI\\x07지원을\\x07위해\\x07기술\\x07개발\\x07추진\\n•  국내에서는\\x07 대기업에서\\x07 한국어\\x07특화\\x07생성형\\x07AI\\x07개발\\x07및\\x07경량화를\\x07진행\\x07중이며,\\x07자사\\x07제품이  \\n적용을\\x07목표로\\x07기술개발\\x07진행'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 5}, page_content='06\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATSⅠ. 개 요\\n1개념정의\\n◎ \\x07 높은\\x07컴퓨팅\\x07파워가\\x07필요한\\x07AI\\x07연산을\\x07다양한\\x07하드웨어\\x07및\\x07소프트웨어\\x07 기술을\\x07활용하여\\x07최적화\\x07된\\x07스마트폰,\\x07 로봇,\\x07드론\\x07\\n등\\x07디바이스\\x07내에서\\x07AI\\x07연산\\x07수행\\n\\t -\\t\\t저전력으로\\t AI\\t연산\\t수행을\\t위해\\t최적화된\\t지능형\\t반도체\\tNPU(Neural\\t Unit)*와\\tAI\\t모델\\t경량화를\\t위한\\t양자화,\\tAI\\t\\n모델\\t추론\\t가속을\\t위한\\tTensorFlow\\tLite\\t등\\t다양한\\t기술\\t활용\\n*\\t\\t기존\\tAI\\t네트워크\\t연산에\\t사용되던\\tGPU와\\t유사한\\t구조나\\tAI\\t기술에\\t특화해\\t연산\\t혹은\\t에너지\\t효율을\\t높여\\t개발한\\t칩\\n\\t -\\t\\t일반적으로\\t온디바이스\\tAI는\\t추론에\\t집중되어\\t있으며\\t연산량이\\t훨씬\\t높은\\t모델\\t학습은\\t서버에서\\t진행온디바이스 AI(On-Device AI) 란 데이터를 외부 서버나 클라우드에 전송하지 않고 디바이스 자체적으로 AI\\n연산을 수행하는 기술을 의미\\n온디바이스 AI 기술 정의 \\n서버\\n사용자 사용자 디바이스 디바이스데이터 AI\\x07연산\\n결과\\n데이터\\x07입력 데이터\\x07입력\\nAI\\x07연산\\x07결과 AI\\x07연산\\x07결과대용량 AI 모델\\nNPU 등 지능형 반도체 탑재\\n추론 가속 엔진 탑재경량화된 AI 모델 탑재고성능 컴퓨팅 환경\\n클라우드 인프라AS-IS   중앙집중형 AI TO-BE   온디바이스 AI'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 6}, page_content='07\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS2등장배경\\n◎  딥러닝\\x07기반\\x07AI\\x07연산은\\x07태생적으로\\x07높은\\x07연산량이\\x07필요\\n\\t -\\t\\t딥러닝\\t모델은\\t매우\\t많은\\t양의\\t학습\\t데이터를\\t학습하여\\t높은\\t정확도의\\t예측을\\t수행하기\\t위해\\t수많은\\t노드와\\t깊은\\t\\n레이어로\\t구성된\\t거대한\\t네트워크\\t구조\\n\\t -\\t\\t학습\\t뿐\\t아니라\\t추론\\t과정에도\\t높은\\t연산량이\\t요구됨에\\t따라\\t고성능\\t서버\\t중심의\\t중앙집중형\\t AI\\t서비스\\t구조가\\t보편화\\n◎  디바이스\\x07및\\x07AI\\x07기술\\x07수준의\\x07발달로\\x07인해\\x07기존\\x07서버\\x07중심의\\x07중앙집중형\\x07구조에서\\x07다양한\\x07제약사항\\x07발생\\n\\t -\\t\\t디바이스의\\t 역할이\\t단순한\\t센싱,\\t통신\\t등에\\t국한된\\t환경에서는\\t 디바이스가\\t 생산하는\\t데이터의\\t크기가\\t제한적이어서 \\t\\n일반적으로\\t서버로\\t모든\\t데이터를\\t송신한\\t다음,\\t서버에서\\tAI\\t연산을\\t수행하는\\t구조\\t가능\\n\\t -\\t\\t디바이스\\t및\\tAI\\t기술\\t발달로\\t인해\\t대용량\\t데이터\\t처리,\\t개인정보\\t유출\\t방지,\\t실시간\\t서비스\\t등의\\t요구사항이\\t 발생하면서 \\t\\n기존\\t서버\\t기반\\t중앙집중형\\t구조에서\\t여러\\t제약사항\\t발생\\n   •  (고해상도 데이터 처리 제한) 고성능\\t디바이스\\t수가\\t증가함에\\t따라\\t대용량\\t데이터\\t처리\\t시\\t네트워크와\\t 클라우드\\t등에\\t\\n부하가\\t증가하여\\t서비스\\t품질\\t저하\\t및\\t통신 ·서버\\t등\\t서비스\\t초기\\t구축\\t및\\t유지관리\\t비용\\t증가\\n   •  (개인정보 유출 우려) 영상,\\t음성,\\t텍스트\\t등\\t민감\\t정보가\\t서버로\\t전송되므로\\t개인정보\\t남 ·오용\\t우려\\n   •  (실시간성 저하) 데이터\\t전송\\t및\\t처리\\t결과\\t수신으로\\t인한\\t지연이\\t발생해\\t실시간\\t서비스가\\t힘들며\\t네트워크\\t연결\\t환경\\t강제\\n◎  이를\\x07해결하기\\x07위한\\x07대안으로\\x07온디바이스\\x07AI\\x07기술의\\x07등장\\n\\t -\\t\\t이전부터\\t“엣지\\tAI”라는\\t용어로\\t디바이스\\t뿐만\\t아니라\\t분산\\t컴퓨팅\\t환경의\\t엣지\\t서버\\t엣지\\t게이트웨이\\t 등\\t컴퓨팅\\t\\n리소스가\\t제한된\\t환경에서\\tAI\\t연산\\t수행에\\t대한\\t연구\\t진행온디바이스 AI 기술의 필요성\\n디바이스 및 AI 기술 발달로 인한 환경 변화\\n고해상도 대용량 데이터 처리 필요\\n•\\t\\t4K\\t카메라,\\tLiDAR\\t등\\t고해상도\\t센서를\\t탑재한 \\t\\n고성능\\t디바\\t이스\\t보급\\n•\\t\\t고성능\\t디바이스가\\t대규모로\\t운용되어\\t통신망\\t및 \\t\\n클라우드\\t과부화\\t문제가\\t발생하는\\t인프라\\t환경\\t등장\\n(스마트시티\\t등)\\n개인정보 유출 우려\\n•\\t\\tCCTV,\\t전자도어락\\t등\\t민감정보가\\t많이\\t존재하는 \\t\\n스마트홈\\t등\\t개인\\t프라이버시\\t환경\\n•\\t\\t개인정보\\t유출\\t방지를\\t위해\\t클라우드\\t개입을 \\t\\n최소화하는\\t디바이스\\t내\\t자체\\t서비스\\t수행\\t필요\\n실시간 서비스 요구\\n•\\t\\tAI\\t서비스가\\t보편화됨에\\t따라\\t사용자에게\\t보다 \\t\\n즉각적인\\t서비스\\t결과\\t제공\\t필요\\n•\\t\\t스마트폰,\\t드론,\\t로봇,\\t자율차\\t등의\\t디바이스 \\t\\n환경에서\\t실시간\\t영상처리,\\t음성인식,\\t자연어처리 \\t\\n등의\\t서비스\\t요구사항\\t증대\\n“디바이스 내 자체적인 AI 연산 수행 필요 ”'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 7}, page_content='08\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS\\t -\\t\\tAI\\t연산에\\t최적화된\\tNPU의\\t등장으로\\t스마트폰,\\t 로봇,\\t드론\\t등\\t배터리\\t기반의\\t이동형\\t기기에서도\\t 자체적인\\tAI\\t연산\\t\\n수행을\\t통한\\t서비스\\t제공이\\t실현되면서\\t디바이스\\t환경에서의\\tAI\\t연산에\\t보다\\t집중한\\t온디바이스\\tAI\\t기술\\t등장\\n\\t -\\t\\t’23년\\t스마트폰에서\\t생성형\\tAI\\t서비스가\\t지원되며\\t온디바이스\\tAI\\t기술의\\t시장\\t확대\\t가속화\\n3주요특징\\n  디바이스 내 자체 AI 연산 가능\\n◎  네트워크\\x07환경에\\x07독립적인\\x07고신뢰성\\x07실시간\\x07서비스\\x07제공\\n\\t -\\t\\t외부와의\\t통신\\t없이\\tAI\\t연산\\t수행을\\t통해\\t통신\\t요청\\t및\\t응답으로\\t인한\\t지연\\t없이\\t실시간\\t서비스\\t제공\\n\\t -\\t\\t네트워크\\t환경에\\t따라\\t서비스의\\t품질이\\t좌우되지\\t않는\\t안정적인\\t서비스\\t제공\\n◎  개인정보\\x07유출\\x07위험\\x07최소화를\\x07통한\\x07사용자\\x07만족도\\x07및\\x07서비스\\x07비용\\x07절감\\n\\t -\\t\\t사용자의\\t영상,\\t음성\\t등\\t민감한\\t개인정보가\\t 서버로의\\t전송\\t없이\\t디바이스에서만\\t 처리하여\\t개인정보\\t유출\\t위험이\\t\\n낮아지며\\t이에\\t따라\\t사용자의\\t불안감\\t최소화\\n\\t -\\t\\t디바이스와\\t 서버\\t간\\t개인정보\\t통신이\\t없어\\t데이터\\t전송에\\t대한\\t암호화,\\t보안\\t등이\\t불필요하여\\t AI\\t서비스\\t구축\\t및\\t\\n유지관리를\\t위한\\t비용\\t절감\\n◎  서버\\x07의존성\\x07탈피로\\x07인한\\x07경제적인\\x07AI\\x07서비스\\x07제공\\n\\t -\\t\\t수많은\\t사용자의\\tAI\\t연산\\t수행을\\t서버에서\\t감당하기\\t위해\\t높은\\t비용의\\t클라우드\\t컴퓨팅\\t시스템을\\t운영하는\\t대신\\t\\n디바이스에서\\tAI\\t연산을\\t각자\\t수행하여\\t비용\\t절감\\t가능\\n  고수준의 하드웨어 및 소프트웨어 기술\\n◎  NPU\\x07기반\\x07하드웨어\\x07구성\\x07및\\x07활용을\\x07위한\\x07다양한\\x07애로사항\\x07존재\\n\\t -\\t\\t디바이스\\tAI를\\t위한\\t하드웨어\\t개발을\\t위해\\t저전력·저비용의\\t NPU\\t기반\\t디바이스\\t구성이\\t필요하나,\\t NPU\\t시장의\\t\\n성숙도가\\t높지\\t않아\\t중소기업이\\tNPU\\t기반\\t디바이스를\\t상용화\\t수준으로\\t개발하는데\\t많은\\t난관\\t존재\\n\\t -\\t\\t일반적으로\\t AI\\t서비스를\\t위해\\t사용하는\\t딥러닝\\t모델은\\tGPU\\t기반으로\\t개발되어\\t있어\\t이를\\tNPU에서\\t 활용하기\\t\\n위해서는\\t모델과\\tNPU의\\t특성에\\t대한\\t이해를\\t기반으로\\t하는\\t고난이도\\t이식\\t작업\\t필요\\n◎  AI\\x07모델\\x07경량화를\\x07통해\\x07정확도와\\x07효율성\\x07간\\x07최적화\\x07필요\\n\\t -\\t\\t높은\\t정확도의\\t딥러닝\\t모델을\\t디바이스\\t자원만으로\\t 동작하기\\t위해서는\\t모델의\\t입력\\t데이터\\t크기를\\t줄이거나\\t모델\\t\\n자체의\\t크기를\\t줄이는\\t등\\t경량화가\\t필요하나,\\t이는\\t정확도의\\t저하를\\t동반\\n\\t -\\t\\t최소한의\\t정확도\\t손실로\\tAI\\t모델을\\t최대한\\t경량화하기\\t위해\\t고수준의\\t최적화\\t필요'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 8}, page_content='09\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATSⅡ. 시장 및 기업 동향\\n1글로벌 시장\\n◎  생성형\\x07AI\\x07및\\x07온디바이스\\x07 AI\\x07시장은\\x07전\\x07세계적으로\\x07 빅테크\\x07기업\\x07투자\\x07열풍으로\\x07급성장이\\x07예상,\\x07각국\\x07정부들도\\x07투자계획\\x07\\n수립을\\x07서두르고\\x07있어\\x07향후\\x07시장\\x07확대가\\x07가속화될\\x07것으로\\x07예상\\n\\t -\\t\\t디바이스\\tAI\\t시장은\\t스마트폰,\\t자동차,\\t드론\\t등\\t다양한\\t기기에\\t탑재되어\\t신산업을\\t이끄는\\t차세대\\tAI\\t시장으로\\t주목되어\\t\\n’24년\\t271억\\t달러\\t규모에서\\t’30년\\t1,738억\\t달러로\\t연평균\\t37.7%\\t성장\\t전망\\n -  온디바이스\\t AI\\t시장을\\t열고\\t있는\\t생성형\\tAI\\t스마트폰\\t시장\\t규모는\\t’27년\\t5억\\t2,200만대로\\t 추산되며,\\t ’24년부터\\t ’27년\\t\\n까지\\t연평균\\t성장률은\\t83%에\\t이르는\\t고성장\\t전망온디바이스 AI 시장 규모(달러)\\n*\\t출처\\t:\\t마켓츠앤마켓츠(’23)184억\\n7,900만271억\\n3,800만383억\\n4,200만526억\\n9,100만718억\\n5,600만972억\\n2,700만1,360억\\n1,000만1,738억\\n7,900만\\n연 평균\\n37.7%  성장\\n2023년 2024년 2025년 2026년 2027년 2028년 2029년 2030년\\n생성형 AI 스마트폰 시장 규모(백만대, %)\\n*\\t출처\\t:\\t카운터포인트리서치(’23)FORECAST2023년 2024년 2025년CAGR Volume Growth\\nFrom 2023 to 2027\\n47 Mn522 Mn\\n2026년 2027년83%Share of GenAI Smartphones,\\nGlobal Smartphone Market\\n2027년\\n2024년\\n2023년40%\\n8%\\n4%\\n'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 9}, page_content='10\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS\\t -\\t\\t글로벌\\t생성형\\tAI\\t시장\\t규모는\\t’22~’32년에\\t 연평균\\t42%\\t고성장,\\t’32년의\\t시장\\t규모는\\t1조\\t3,040억\\t달러로\\t’22년\\t\\n대비\\t30배\\t이상\\t성장\\t전망\\n2국가별 정책\\n◎  미국을\\x07포함한\\x07주요\\x07국가에서\\x07디바이스\\x07중심의\\x07AI\\x07관련\\x07기술\\x07개발\\x07지원\\x07정책을\\x07지속적으로\\x07발표생성형 AI 시장 규모(억 달러)\\n*\\t출처\\t:\\t블룸버그인텔리전스(’23)2020년 2021년 2022년 2023년 2024년 2025년 2026년 2027년 2028년 2029년 2030년 2031년 2032년140 230 400 6701,3702,1703,0403,9905,4807,2808,97010,79013,040\\nCAGR 42%\\n국\\x07가 정책\\x07동향\\n•  미국\\x07과학기술정책국(OSTP)의\\x07「국가\\x07AI\\x07R&D\\x07전략\\x07계획」에\\x07대한\\x07’23년\\x07업데이트\\x07발표에서\\x07장기적으로\\x07투자할\\x07차세대\\x07AI\\x07분야에 \\x07\\n온디바이스\\x07시스템과\\x07같은\\x07제한된\\x07하드웨어\\x07및\\x07에너지\\x07리소스를\\x07고려하는\\x07연구분야\\x07포함(’23)\\n *\\t\\t하드웨어\\t성능\\t개선\\t및\\t리소스\\t사용\\t최적화를\\t위한\\tAI\\t시스템\\t개발과\\t에너지\\t소비를\\t비롯한\\t지속\\t가능성을\\t고려하는\\t리소스\\t중심 \\t\\nAI\\t알고리즘\\t및\\t시스템\\t고려\\n•  독일은\\x07「연방정부의\\x07인공지능\\x07전략\\x072020\\x07업데이트」에서\\x07연구지원\\x07분야로\\x07온디바이스\\x07AI\\x07기술의\\x07활용도가\\x07높은\\x07헬스케어, \\x07\\n모빌리티,\\x07에너지,\\x07농업\\x07\\x07분야에\\x07대한\\x07다양한\\x07지원\\x07정책\\x07발표(’20)\\n•  영국은\\x07「인공지능\\x0710개년\\x07국가전략\\x07계획」을\\x07통해\\x07영국AI\\x07시장\\x07트렌드를\\x07선도하는\\x07헬스케어\\x07분야\\x07온디바이스\\x07AI\\x07기술\\x07개발\\x07지원과 \\x07\\n글로벌화\\x07계획\\x07발표(’21)\\n•  경제산업성은\\x07「반도체 ·디지털\\x07산업\\x07전략」에서\\x07개인별\\x07최적화된\\x07IT\\x07디바이스\\x07시스템\\x07기반\\x07디지털\\x07기술\\x07혁신을\\x07통해\\x07경제성장을 \\x07\\n실현하기\\x07위한\\x07전략\\x07발표(’23.5)\\n•  「AI\\x07전략\\x072021」을\\x07발표하여\\x07다양한\\x07온디바이스\\x07시스템이\\x07적용될\\x07건강\\x07및\\x07의료,\\x07농업,\\x07스마트시티,\\x07제조업\\x07등\\x07다양한\\x07분야에서 \\x07\\n인공지능을\\x07도입하고\\x07상용화\\x07가속\\x07대응\\x07방안\\x07개선\\x07추진\\x07시작(’21.6)\\n•  국산\\x07AI\\x07반도체를\\x07기반으로\\x07초기시장\\x07단계인\\x07온디바이스AI\\x07시장\\x07선점을\\x07위한\\x07「(가칭)온디바이스AI\\x07활성화\\x07전략(안)」\\x07계획\\x07발표\\n\\x07\\x07(과기정통부,\\x07 ’24.2)\\n•  중소벤처기업부에서\\x07LG전자\\x07등과\\x07손잡고\\x07온디바이스\\x07AI\\x07스타트업\\x07육성을\\x07위해\\x07「온디바이스(On-Device)\\x07AI\\x07초격차\\x07챌린지」 \\x07\\n출범식\\x07개최( ’24.3)\\n•  NPU\\x07고도화,\\x07PIM ·뉴로모픽\\x07혁신,\\x07신소자\\x07및\\x07첨단패키징\\x07등에\\x07기반한\\x07저전력\\x07AI반도체로\\x07클라우드\\x07AI데이터센터\\x07고도화, \\x07\\n온디바이스\\x07AI\\x07신격차\\x07확보\\x07전략을\\x07포함하는\\x07「AI·디지털\\x07혁신성장\\x07전략」\\x07발표(과기정통부,\\x07 ’24.4)\\n미국\\n유럽연합\\n한국\\n일본'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 10}, page_content='11\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS3국가별 정책\\n◎  자사\\x07AI\\x07칩\\x07기반의\\x07생태계\\x07구축을\\x07위해\\x07데이터·AI\\x07모델·추론기술·SDK*를\\x07아우르는\\x07전방위적 \\x07기술\\x07지원\\n     *\\t\\t소프트웨어를\\t개발하는\\t도구로\\t소프트웨어\\t개발자가\\t특정\\t운영체제용\\t응용프로그램을\\t만들\\t수\\t있는\\t소스와\\t도구\\t패키지\\n◎  (애플) 자사의\\x07하드웨어\\x07환경에서\\x07애플의\\x07뉴럴\\x07엔진을\\x07활용하여\\x07온디바이스\\x07 AI를\\x07수행할\\x07수\\x07있도록\\x07Core\\x07ML\\x07라이브러리\\x07 제공\\n\\t -\\t\\t이\\t라이브러리는\\t 이미지,\\t비디오,\\t사운드\\t등\\t미디어\\t분석을\\t위해\\t설계된\\t첨단\\t신경망과\\t같은\\tAI모델을\\t지원하며,\\t\\nTensorFlow나\\tPyTorch와\\t같은\\t라이브러리의\\t모델을\\tCore\\tML로\\t변환하는\\t기능도\\t제공\\n◎  (퀄컴) 자사\\x07스냅드래곤\\x07 AP에서\\x07효율적인\\x07AI\\x07연산\\x07수행을\\x07위한\\x07라이브러리와\\x07 하드웨어·소프트웨어\\x07 환경에\\x07맞게\\x07사전\\x07\\n학습된\\x07AI\\x07모델을\\x07제공하는\\x07AI\\x07Hub\\x07제공\\n\\t -\\t\\tAI\\tHub는\\t개발자가\\tAI\\t연산을\\t수행할\\t환경을\\t선택하면\\t이에\\t따라\\t기\\t학습된\\t75여\\t가지의\\t인기\\t있는\\tAI\\t및\\t생성형\\tAI\\t\\n모델을\\t제공하여\\t손쉬운\\tAI\\t서비스\\t구축\\t지원\\n◎  (AMD) 자사\\x07칩셋에\\x07최적화된\\x07AI\\x07연산\\x07추론\\x07라이브러리\\x07 ZenDNN과\\x07 AI\\x07모델의\\x07생성부터\\x07최적화,\\x07추론\\x07가속까지\\x07전과정을\\x07\\n지원하는\\x07Vitis\\x07AI\\x07플랫폼\\x07제공\\n\\t -\\t\\tVitis\\tAI\\t플랫폼은\\tAI\\t모델\\t경량화\\t뿐만\\t아니라\\t프로파일러를\\t 통해\\t모델의\\t특성을\\t분석하고\\t최적화를\\t할\\t수\\t있는\\t도구를\\t\\n제공하며,\\t기\\t학습된\\tAI\\t모델\\t또한\\t지원\\n◎  (인텔) 자사\\x07칩셋에서\\x07AI\\x07연산을\\x07최대한\\x07효율적으로\\x07 수행하기\\x07위해\\x07OpenVINO\\x07 프로젝트를\\x07 출시했으며,\\x07 개발자를\\x07위한\\x07\\nEdge\\x07AI\\x07Reference\\x07Kits를\\x07오픈소스로\\x07제공\\n -  기\\t학습된\\t모델부터\\t직접\\t모델을\\t개발할\\t수\\t있도록\\t최적화\\t도구\\t일체를\\t제공하며,\\t자사\\t칩셋\\t환경에서의\\t 추론\\t가속\\t엔진\\t지원\\n◎  (엔비디아) AI\\x07모델\\x07경량화를\\x07위한\\x07Tensor\\x07RT\\x07외\\x07AI\\x07연산을\\x07위해\\x07필요한\\x07도구\\x07일체\\x07지원을\\x07통해\\x07성공적으로\\x07 생태계\\x07구축\\n\\t -\\t\\t’18년부터\\t 엔비디아는\\t 생태계\\t확장\\t및\\t기술개발\\t참여\\t유도를\\t위해\\tAI\\t추론\\t가속기\\tHW\\t및\\tSW\\t아키텍처를\\t NVDLA\\t\\n(NVIDIA\\tDeep\\tLearning\\tAccelerator)라는\\t오픈소스로\\t공유\\n◎  이\\x07외\\x07헤일로,\\x07딥엑스,\\x07모빌린트,\\x07 크네론\\x07등\\x07NPU\\x07제조\\x07스타트업도\\x07 단순히\\x07하드웨어\\x07드라이버\\x07수준의\\x07라이브러리를\\x07 넘어\\x07\\nAI\\x07모델\\x07경량화\\x07및\\x07최적화\\x07도구\\x07등\\x07생태계\\x07구축을\\x07위해\\x07다양한\\x07소프트웨어\\x07지원국\\x07가 정책\\x07동향\\n•  「중공중앙\\x07국민경제사회발전\\x07제14차\\x075개년\\x07규획(2021~2025)」과\\x07’35년\\x07장기목표에\\x07대한\\x07초안에서\\x07차세대\\x07IT\\x07산업의\\x07세부산업 \\x07\\n육성\\x07전략에\\x07AI\\x07분야에서\\x07스마트\\x07의료장비,\\x07스마트\\x07인식\\x07시스템\\x07등\\x07온디바이스\\x07AI\\x07기술이\\x07필요한\\x07산업\\x07분야를\\x07선정\\x07( ’21.3)\\n•  국가과학기술위원회(NSTC)는\\x07자국에\\x07특화된\\x07AI\\x07언어모델\\x07TAIDE\\x07개발\\x07프로젝트에\\x07온디바이스\\x07환경에서\\x07동작\\x07가능한\\x07작은\\x07모델 \\x07\\n개발\\x07계획이\\x07포함됨을\\x07발표\\x07( ’24.1)\\n중국\\n대만'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 11}, page_content='12\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATSⅢ. 핵심 기술 동향\\n1기술 개요\\n◎  하드웨어부터\\x07AI\\x07모델까지\\x07폭넓은\\x07분야에\\x07걸쳐\\x07기술\\x07개발\\x07진행\\n◎  (온디바이스 AI 하드웨어) AI\\x07연산에\\x07최적화된\\x07지능형\\x07반도체인\\x07NPU와\\x07사람의\\x07뇌\\x07구조를\\x07모사한\\x07뉴로모픽\\x07칩이\\x07대표\\x07기술\\n -  NPU는\\tGPU와\\t유사한\\t병렬연산에\\t 최적화\\t된\\t반도체이나,\\t 그래픽\\t등\\t일반적인\\t연산\\t타겟의\\tGPU와\\t달리\\tAI\\t연산만을\\t\\n위해\\t설계되어\\t효율성은\\t높으나\\tGPU\\t대비\\t유연성은\\t부족\\n -  뉴로모픽\\t칩은\\t행렬\\t연산\\t기반의\\t딥러닝\\t모델과는\\t달리\\t인간의\\t뇌와\\t유사한\\t스파이킹\\t뉴런\\t모델과\\t시냅스\\t모델로\\t\\n동작하며,\\tGPU\\t및\\tNPU보다\\t전력\\t소모량이\\t매우\\t적을\\t것으로\\t기대되나\\t아직\\t상용화\\t수준에는\\t미도달\\n◎  (온디바이스 AI 소프트웨어) 제한된\\x07리소스\\x07내\\x07AI\\x07모델을\\x07최대한\\x07효율적으로\\x07 동작시키기\\x07 위해\\x07하드웨어·운영체제\\x07 등\\x07\\n시스템\\x07레벨의\\x07AI\\x07연산\\x07엔진\\n -  대표적으로\\t구글의\\tTensorFlow\\tLite가\\t있으며,\\t기술\\t난이도가\\t높아\\t글로벌\\t대기업\\t위주로\\t기술\\t개발\\n◎  (온디바이스 AI 모델) AI\\x07모델의\\x07필요\\x07없는\\x07파라미터를\\x07 제거하는\\x07프루닝,\\x07데이터\\x07해상도를\\x07낮추는\\x07양자화\\x07등\\x07다양한\\x07\\n기술을\\x07통해\\x07온디바이스\\x07환경에서\\x07동작\\x07가능한\\x07수준의\\x07경량화된\\x07딥러닝\\x07모델\\n온디바이스 AI 기술 분야\\nLightweight AI Model AI Inference SW\\nNeuromorphic Chip\\nNPUPruning Arm NN Framework NVIDIA Tensor RT\\nNepes NM500\\nGoogle Edge TPU Samsung Exynos APQualcomm ZerothGoogle TensorFlowLite Binarization\\nOn-Device AI Model\\nOn-Device AI SW\\nOn-Device AI HW'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 12}, page_content='13\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS2하드웨어 기술\\n  해 외\\n◎  엔비디아는\\x07 GPU의\\x07효율성을\\x07지속적으로\\x07 향상시키고\\x07 있으며,\\x07구글,\\x07테슬라,\\x07애플\\x07등\\x07디바이스\\x07제조사에서는\\x07 NPU를\\x07\\n개발하여\\x07자사\\x07서비스에\\x07적용\\n◎  퀄컴,\\x07AMD\\x07등\\x07칩\\x07제조사에서는\\x07 고효율의\\x07범용\\x07NPU를\\x07지속적으로\\x07 개발하고\\x07있으며,\\x07최근에는\\x07생성형\\x07AI\\x07지원\\x07NPU를\\x07\\n경쟁적으로\\x07출시\\n기업명 기술\\x07동향\\n•  임베디드\\x07환경에서의\\x07온디바이스\\x07AI를\\x07위한\\x07Jetson\\x07Orin\\x07시리즈는\\x07다성능의\\x07디바이스를\\x07지원 \\x07\\n하기\\x07위해\\x0720\\x07TOPS\\x07성능의\\x07Nano부터\\x07200\\x07TOPS\\x07성능의\\x07AGX까지\\x073단계\\x07성능의\\x07솔루션\\x07출시\\n•  얼굴인식,\\x07음성인식으로\\x07대표되는\\x07자사의\\x07AI\\x07서비스\\x07품질\\x07향상을\\x07위해\\x07뉴럴엔진이라는\\x07NPU를  \\n독자적으로\\x07 개발하여\\x07AP(Application\\x07 Processor)와\\x07 통합된\\x07형태로\\x07제품을\\x07출시해\\x07왔으며,\\x07 ’23년\\x07\\nA17\\x07Pro에\\x07탑재된\\x077세대\\x07뉴럴엔진에서는\\x07전작\\x07대비\\x07약\\x072배\\x07성능을\\x07향상시켜\\x0735\\x07TOPS\\x07달성\\n•  서버\\x07환경에서의\\x07AI\\x07가속을\\x07위한\\x07체온\\x07프로세스\\x07등\\x07고성능\\x07CPU\\x07기술\\x07개발\\x07경험을\\x07토대로 \\x07\\n신경망\\x07프로세서\\x07및\\x07비전\\x07처리\\x07장치를\\x07개발함으로써\\x07점차적으로\\x07온디바이스AI\\x07수행을\\x07위한 \\x07\\n하드웨어\\x07기술로\\x07확장\\n•  디바이스\\x07환경에서\\x07영상처리\\x07관련\\x07AI\\x07수행에\\x07최적화된\\x07MovidiusMyraidX\\x07VPU(Vision \\x07\\nProcessing\\x07Unit)를\\x07USB\\x07기반\\x07모듈\\x07형태로\\x07만든\\x07뉴럴컴퓨트스틱2\\x07출시,\\x07‘23년에는\\x073세대 \\x07\\n3700VC\\x07VPU를\\x07출시했으며,\\x07VPU가\\x07내장된\\x0714세대\\x07CPU\\x07메테오레이크\\x07공개\\n•  저전력\\x07프로세서\\x07기반\\x07AI\\x07연산을\\x07위한\\x07Edge\\x07TPU\\x07(Tensor\\x07Processing\\x07Unit)를\\x07출시했으며, \\x07\\nUSB\\x07및\\x07PCIe/M.2\\x07형태의\\x07HW를\\x07제공하여\\x07라즈베리파이,\\x07아두이노와같은\\x07IoT\\x07기기에서의 \\x07\\nAI\\x07추론을\\x07간편한\\x07형태로\\x07지원\\n•  ’18년\\x07스냅드래곤855부터\\x07전용\\x07텐서가속기가\\x07hexagon\\x07DSP에\\x07탑재,\\x07최근\\x07hexagon\\x07DSP \\x07\\n대신\\x07hexagon\\x07NPU라고\\x07명칭을\\x07변경하여\\x07AI\\x07가속에\\x07집중\\n•  온디바이스AI를\\x07위한\\x07microNPU제품군\\x07개발,\\x07클라우드부터\\x07엣지에서\\x07사용가능한\\x07고\\x07사양의 \\x07\\nEthos-N\\x07시리즈와\\x07디바이스에서\\x07사용\\x07가능한\\x07저전력의\\x07Ethos-U\\x07시리즈를\\x07공개했으며\\x07’24\\n년\\x07Ethos-U85\\x07출시\\n엔비디아\\n애플\\n인텔\\n구글\\n퀄컴\\nARM'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 13}, page_content='14\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS  국 내\\n◎  대기업에서는\\x07 NPU를\\x07상용화하여\\x07 자사\\x07제품에\\x07사용\\x07중이며,\\x07NPU\\x07관련\\x07스타트업에서는\\x07 검증\\x07단계를\\x07넘어\\x07양산\\x07단계로\\x07진입기업명 기술\\x07동향\\n•  로봇,\\x07드론\\x07등\\x07임베디드\\x07환경에서의\\x07AI\\x07연산\\x07수행을\\x07위해\\x07NPU와\\x07DSP를\\x07포함하는\\x07Versal\\x07AI \\x07\\nEdge\\x07시리즈\\x07출시,\\x075\\x07TOPS부터\\x07202\\x07TOPS까지\\x077단계의\\x07선택지\\x07제공\\n•  ’20년\\x0726TOPS\\x07성능의\\x07Hailo-8를,\\x07’23년에는\\x07외부\\x07메모리가\\x07필요\\x07없어\\x07구성이\\x07손쉬우며 \\x07\\n저전력으로\\x07동작하는\\x0713TOPS\\x07성능의\\x07Hailo-8L을\\x07발표,\\x07M.2,\\x07mPCIe\\x07등\\x07다양한 \\x07\\n인터페이스의\\x07엣지향\\x07NPU\\x07모듈\\x07판매\\n•  ’24년\\x07생성형\\x07AI를\\x07지원하는\\x07Hailo-10\\x07출시\\n•  자사의\\x07핵심\\x07기능인\\x07자율\\x07주행을\\x07위해\\x07NPU를\\x07탑재한\\x07자체\\x07칩인\\x07FSD\\x07칩(Full\\x07Self-Driving) \\x07\\n개발\\x07중,\\x07  ’22년\\x07향상된\\x07성능의\\x07HW4.0\\x07출시\\n•  모바일\\x07AP\\x07타겟의\\x07NPU인\\x07APU\\x07(AI\\x07Processing\\x07Unit)을\\x07지속적으로\\x07개발.\\x07’24년\\x07생성형\\x07AI \\x07\\n타겟의\\x07APU790을\\x07탑재한\\x07모바일\\x07AP\\x07디멘시티\\x079300+\\x07공개\\n•  저전력의\\x07Ara-1과\\x07생성형\\x07AI를\\x07지원하는\\x07고성능의\\x07Ara-2\\x07NPU\\x07출시,\\x07USB,\\x07M.2,\\x07PCIE\\x073\\n가지\\x07폼팩터의\\x07모듈\\x07판매\\n•  레노버와\\x07협력해\\x07소형\\x07컨텐츠\\x07제작용\\x07데스크톱\\x07씽크센터에\\x07NPU\\x07탑재\\n•  자사의\\x07다양한\\x07제품에\\x07탑재하여\\x07임베디드\\x07환경\\x07AI\\x07연산\\x07수행을\\x07위한\\x07eIQ\\x07Neutron\\x07NPU\\x07출시, \\x07\\x07\\n용도에\\x07따라\\x07다양한\\x07성능으로\\x07구성\\x07가능\\n•  MCX\\x07N\\x07MCU,\\x07i.MX\\x0795\\x07AP\\x07등이\\x07NPU를\\x07탑재한\\x07대표적인\\x07제품\\nAMD\\n헤일로\\n테슬라\\n미디어텍\\n키나라\\nNXP\\n기업명 기술\\x07동향\\n삼성전자•  NPU\\x07시장선점을\\x07위해\\x07지속적인\\x07투자를\\x07통해\\x07리딩,\\x07’18년\\x0711월\\x07공개한\\x07엑시노스9820에 \\x07\\n처음으로\\x07NPU\\x07탑재를\\x07시작으로\\x07최신\\x0720시리즈\\x07(엑시노스2100~2400)까지\\x07모두\\x07NPU\\x07탑재\\n•  최근에는\\x07차량용\\x07프로세서인\\x07엑시노스오토\\x07V920을\\x07발표하여\\x07현대자동차와\\x07협력해\\x07’25년 \\x07\\n실적용을\\x07목표로\\x07개발\\nLG전자•  가전\\x07등에서\\x07온디바이스AI를\\x07수행하도록\\x07비전\\x07관련\\x07작업\\x07가속기\\x07및\\x07음성\\x07관련\\x07작업\\x07가속기를 \\x07\\n탑재해\\x07가전에서\\x07필요한\\x07영상\\x07및\\x07음성\\x07AI\\x07분석을\\x07지원하는\\x07LG8111\\x07AI\\x07SoC\\x07솔루션\\x07개발,\\x07’23년 \\x07\\n에는\\x07신규\\x07NPU\\x07개발\\x07착수를\\x07공개해\\x07개발\\x07완료\\x07후\\x07스마트\\x07TV의\\x07알파10\\x07칩에\\x07적용\\x07예정\\n'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 14}, page_content='15\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS3소프트웨어 기술\\n  해 외\\n◎  범용적인\\x07환경에서\\x07동작이\\x07필요한\\x07온디바이스\\x07 AI\\x07연산\\x07처리\\x07소프트웨어\\x07 개발은\\x07기술적\\x07난이도가\\x07높고\\x07인프라적\\x07성격이\\x07\\n강해\\x07글로벌\\x07대기업이\\x07생태계\\x07구축의\\x07일환으로\\x07기술\\x07선도기업명 기술\\x07동향\\n사피온•  SKT에서\\x07분사하여\\x07데이터센터\\x07및\\x07디바이스\\x07대상\\x07NPU를\\x07개발\\x07중,\\x07’20년에\\x07데이터센터용 \\x07\\nNPU\\x07X220,\\x07’23년\\x07X330\\x07출시\\n•  ’24년\\x07디바이스\\x07및\\x07자율주행차\\x07대상\\x07X300\\x07Edge,\\x07X300\\x07Auto\\x07등\\x07출시\\x07예정\\n딥엑스•  엣지향\\x07및\\x07서버향\\x07NPU를\\x07개발하는\\x07팹리스\\x07기업으로\\x07세계\\x07최고\\x07수준의\\x07다양한\\x07신규 \\x07\\n알고리즘들을\\x07높은\\x07전성비/정확도를\\x07기반으로\\x07동작하는\\x07NPU\\x07개발을\\x07목표로\\x07함. \\x07\\n\\x07\\x07\\x07\\x07’23년\\x07DX-L1/L2/M1/H1의\\x0712\\x07TOPS부터\\x071600\\x07TOPS급의\\x074가지\\x07NPU를\\x07발표했으며, \\x07\\n’24년\\x07양산\\x07예정\\n넥스트칩•  차량,\\x07보행자,\\x07차선\\x07등을\\x07인식\\x07및\\x07검출하는\\x07프로세서로,\\x07최첨단\\x07운전자\\x07지원\\x07시스템(ADAS)향 \\x07\\n스마트\\x07센싱\\x07카메라에\\x07적합한\\x07영상기반\\x07이미지\\x07처리\\x07지원\\x07비젼프로세서\\x07개발\\n모빌린트•  가격\\x07측면에서\\x07최소\\x074배\\x07이상\\x07엔비디아\\x07제품보다\\x07뛰어난\\x07성능으로\\x07구현한다는\\x07목표를\\x07세우고 \\x07\\nARIES\\x07NPU를\\x07개발,\\x07온디바이스\\x07AI\\x07중에서도\\x07비교적\\x07큰\\x07기기,\\x07산업용\\x07로봇이나\\x07서빙\\x07로봇, \\x07\\n스마트\\x07팩토리\\x07등의\\x07시장을\\x07타깃으로\\x07MLA100,\\x07MLX-A1\\x072가지\\x07폼팩터의\\x07제품\\x07출시\\n•  ’24년\\x073월\\x07디자인하우스\\x07세미파이브와\\x07협력하여\\x07칩\\x07양산에\\x07돌입했다고\\x07발표\\n기업명 기술\\x07동향\\n•  경량\\x07딥러닝\\x07네트워크\\x07추론\\x07엔진인\\x07TensorFlow\\x07 Lite를\\x07개발해\\x07스마트폰과\\x07 같은\\x07엣지디바이스 \\x07\\n에서\\x07리소스\\x07사용을\\x07최소화하면서\\x07AI\\x07추론\\x07지원\\n•  최근\\x07생성형\\x07AI의\\x07손쉬운\\x07지원을\\x07위해\\x07MediaPipe,\\x07TensorFlow\\x07Lite,\\x07Gemini\\x07나노를 \\x07\\n포함하는\\x07엔드\\x07투\\x07엔드\\x07스택인\\x07Google\\x07AI\\x07Edge\\x07출시\\n•  수\\x07KB\\x07수준의\\x07메모리를\\x07가진\\x07MCU\\x07타겟의\\x07TensorFlow\\x07for\\x07Microcontollers를\\x07실험\\x07기능으로\\x07제공\\n•  엔비디아\\x07TensorRT는\\x07고성능\\x07딥러닝\\x07추론을\\x07위한\\x07SDK로\\x07임베디드\\x07환경에서\\x07학습된\\x07모델을 \\x07\\n기반으로\\x07실시간\\x07추론\\x07및\\x07실시간\\x07모델\\x07업데이트\\x07기능\\x07제공\\n구글\\n엔비디아'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 15}, page_content='16\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS  국 내\\n◎  대기업\\x07중심으로\\x07자사\\x07제품에\\x07활용\\x07가능한\\x07최적\\x07AI\\x07추론\\x07기술\\x07개발기업명 기술\\x07동향\\n•  자사의\\x07하드웨어에\\x07최적화하여\\x07온디바이스환경\\x07비전\\x07및\\x07AI\\x07분석을\\x07지원하는\\x07라이브러리 \\x07\\nACL(Arm\\x07Compute\\x07Library)\\x07제공\\n•  자사의\\x07Cortex-A\\x07CPU,\\x07Mail\\x07GPU,\\x07Ethos\\x07NPU에\\x07최적화된\\x07머신러닝구동을\\x07위해\\x07NN \\x07\\nFrameworks를\\x07오픈소스로\\x07제공\\n•  모바일에서\\x07자주\\x07사용되는\\x07비전\\x07분석\\x07기능을\\x07최적화한\\x07FastCV라이브러리를\\x07개발,\\x07자사 \\x07\\n스냅드래곤\\x07AP에서\\x07고효율\\x07AI\\x07모델\\x07처리를\\x07지원하는\\x07SNPE\\x07(Snapdragon\\x07Neural \\x07\\nProcessing\\x07Engine)과\\x07AI\\x07모델\\x07압축\\x07및\\x07양자화를\\x07수행하여\\x07온디바이스\\x07AI를\\x07지원하는 \\x07\\nAIMET(AI\\x07Model\\x07Efficiency\\x07Toolkit)\\x07개발\\n•  자사\\x07칩셋\\x07타겟의\\x07OpenVINO\\x07프로젝트를\\x07통해\\x07Xeon\\x07CPU부터\\x07Arm\\x07코어까지\\x07다양한 \\x07\\n디바이스\\x07환경에서\\x07AI\\x07연산을\\x07효과적으로\\x07수행하기\\x07위한\\x07OpenVINO\\x07Runtime\\x07API\\x07제공\\n•  최근\\x07생성형\\x07AI\\x07지원을\\x07위한\\x07기능\\x07추가\\nARM\\n퀄컴\\n인텔\\n기업명 기술\\x07동향\\n삼성전자•  뉴럴\\x07네트워크\\x07연산을\\x07효율적으로\\x07처리하기\\x07위한\\x07AI\\x07추론\\x07엔진인\\x07ONE(On-device\\x07Neural \\x07\\nEngine)\\x07개발,\\x07효율적인\\x07추론을\\x07위해\\x07모델\\x07컴파일을\\x07위한\\x07컴파일러와\\x07모델\\x07수행을\\x07위한 \\x07\\n런타임\\x07파트로\\x07나누어\\x07개발\\n삼성리서치•  리눅스의\\x07영상\\x07파이프라인\\x07프레임워크인\\x07GStreamer를\\x07기반으로\\x07뉴럴네트워크\\x07파이프라인 \\x07\\n프레임워크인\\x07NNStreamer를\\x07오픈소스로\\x07개발,\\x07온디바이스학습을\\x07위한\\x07NNTrainer도 \\x07\\n오픈소스로\\x07공개\\n노타•  AI\\x07하드웨어의\\x07특성에\\x07따라\\x07AI\\x07모델을\\x07경량화하는\\x07넷츠프레소\\x07솔루션\\x07출시,\\x07접근성\\x07향상을 \\x07\\n위해\\x07웹\\x07기반\\x07넷츠프레소\\x07사용\\x07지원을\\x07위한\\x07LaunchX\\x07웹\\x07어플리케이션\\x07서비스\\x07출시\\n제틱에이아이•  기존\\x07딥러닝\\x07모델을\\x07온디바이스\\x07환경에서\\x07동작할\\x07수\\x07있도록\\x07경량화\\x07도구\\x07및\\x07추론\\x07가속 \\x07\\n파이프라인을\\x07포함한\\x07제틱\\x07멜란지\\x07출시\\n'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 16}, page_content='17\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS4생성형 AI 기술\\n  해 외\\n◎  미국\\x07OpenAI가\\x07 전\\x07세계\\x07생성형\\x07AI\\x07기술을\\x07주도하고\\x07있는\\x07한편\\x07메타,\\x07애플,\\x07테슬라\\x07등\\x07여러\\x07기업들이\\x07온디바이스에서 \\x07\\n생성형\\x07AI\\x07지원을\\x07위해\\x07기술\\x07개발\\x07추진\\n기업명 기술\\x07동향\\n•  이미지를\\x07인식할\\x07수\\x07있는\\x07멀티모달\\x07지원\\x07‘ChatGPT-4’\\x07출시.\\x07이를\\x07기반으로\\x07온라인\\x07서비스인\\x07플러그인\\x07기능을\\x07추가해\\x07현재\\x07오픈\\nAI\\x07플러그인\\x07스토어에\\x071,000여\\x07개의\\x07플러그인이\\x07탑재되는\\x07등\\x07AI\\x07생태계의\\x07주력\\x07트렌드로\\x07자리\\x07잡음.\\x07최근\\x07응답\\x07속도를\\x07비약적으로 \\x07\\n향상시킨\\x07‘ChatGPT-4o’\\x07출시\\n•  현\\x07시점에서는\\x07GPT2\\x07기반\\x07모델\\x07크기\\x07500M~1G급으로\\x07약\\x0720토큰\\x07처리하는\\x07데\\x0710s\\x07정도\\x07수준의\\x07기술\\x07보유,\\x07조만간\\x07GPT\\x07모델 \\x07\\n경량화와\\x07domain\\x07specific\\x07model\\x07finetuning\\x07지원\\x07온디바이스\\x07GPT\\x07지원\\x07계획\\x07발표.\\x07‘23년\\x07메타와\\x07협력하여\\x07메타의\\x07생성형\\x07AI인 \\x07\\n거대언어모델(LLM)\\x07라마2를\\x07온디바이스에서\\x07지원하기\\x07위해\\x07최적화를\\x07수행하기로\\x07발표한\\x07후\\x07당해\\x0710월\\x07생성형\\x07AI를\\x07반도체\\x07칩에 \\x07\\n내장한\\x07‘스냅드래곤\\x078’\\x073세대\\x07발표\\n•  ’24년\\x07메타가\\x07공개한\\x07최신\\x07LLM\\x07라마3를\\x07스냅드래곤\\x07플래그십\\x07플랫폼의\\x07온디바이스\\x07환경에서\\x07동작시키기\\x07위해\\x07최적화\\x07수행\\x07계획\\x07발표\\n•  대규모\\x07AI\\x07언어\\x07모델인\\x07‘라마(LLaMa)’를\\x07공개하면서\\x07최적화를\\x07통해\\x07특정\\x07분야에\\x07한정하여\\x07작은\\x07용량으로\\x07고수준의\\x07언어\\x07처리를 \\x07\\n지원하는\\x07sLLM도\\x07함께\\x07공개,\\x07이를\\x07기반으로\\x07노트북이나\\x07휴대폰에서\\x07동작하는\\x07sLLM\\x07응용도\\x07공개\\n•  자사에서\\x07설립한\\x07AI\\x07스타트업\\x07xAI가\\x07ChatGPT와\\x07같은\\x07생성형\\x07AI\\x07‘그록(Grok)’\\x07공개\\n•  딥마인드와\\x07협력하여\\x07텍스트,\\x07오디오,\\x07이미지\\x07등을\\x07지원하는\\x07멀티모달\\x07생성형\\x07AI\\x07모델\\x07‘제미나이’를\\x07개발했으며,\\x07온디바이스\\x07AI \\x07\\n지원을\\x07위해\\x07경량화된\\x07‘제미나이\\x07나노’도\\x07함께\\x07개발\\n•  ’24년\\x07삼성전자와\\x07협력하여\\x07‘제미나이\\x07나노\\x072.0’을\\x07갤럭시\\x07S24에\\x07탑재\\n•  ’24년\\x07iOS에서\\x07개인\\x07맞춤형\\x07생성형\\x07AI를\\x07지원하는\\x07애플\\x07인텔리젼스를\\x07발표하면서\\x07자체\\x07개발\\x07생성형\\x07AI\\x07모델인\\x07‘에이잭스(Ajax)’와 \\x07\\n함께\\x07오픈\\x07AI와\\x07협력하여\\x07자사\\x07음성\\x07AI\\x07비서\\x07시리에\\x07ChatGPT-4o를\\x07접목한다고\\x07발표\\n•  단,\\x07모든\\x07처리를\\x07디바이스에서\\x07처리하는\\x07대신\\x07상황에\\x07따라\\x07강화된\\x07보안이\\x07적용된\\x07프라이빗\\x07클라우드에서\\x07AI\\x07연산\\x07수행\\x07가능\\n•  대부분의\\x07MS\\x07제품에\\x07생성형\\x07AI를\\x07결합하여\\x07‘MS365\\x07Copilot’,\\x07‘Security\\x07Copilot’\\x07등\\x07신제품\\x07출시\\x07중,\\x07’24년\\x07온디바이스\\x07AI를 \\x07\\n지원하는\\x07인공지능\\x07피씨인\\x07Copilot+\\x07PC\\x07공개\\n•  ’23년\\x07디지털\\x07솔루션\\x07기업으로\\x07퀄컴의\\x07플랫폼을\\x07기반으로\\x07자사\\x07핸드헬드\\x07모바일\\x07컴퓨터\\x07및\\x07태블릿\\x07등\\x07온디바이스\\x07환경에서 \\x07\\n클라우드와의\\x07연결\\x07없이\\x07대형언어모델\\x07및\\x07생성형\\x07AI를\\x07구현하는데\\x07성공했다고\\x07공개\\n•  자체클라우드\\x07LLM인\\x07Pangu와\\x07디바이스\\x07내\\x07AI비서인\\x07Cella가\\x07연결되며,\\x07’23년\\x078월\\x07HamonyOS\\x074에\\x07LLM을\\x07탑재할\\x07것을\\x07발표\\n•  자체\\x07LLM인\\x07AndesGPT를\\x07기반으로\\x07AI비서인\\x07Xiaobu를\\x07외부테스트를\\x07수행\\x07중이며,\\x07향후\\x07스마트폰\\x07등에\\x07탑재\\x07예정\\n오포\\n화웨이\\n지브라\\nOpenAI\\n퀄컴\\n메타\\n테슬라\\nMS\\n애플\\n구글'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 17}, page_content='18\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS  국 내\\n◎  대기업에서\\x07한국어\\x07특화\\x07생성형\\x07AI\\x07개발\\x07및\\x07경량화를\\x07진행\\x07중이며,\\x07자사\\x07제품이\\x07적용을\\x07목표로\\x07기술개발\\x07진행\\n5활용 서비스 사례\\n◎  사용자와\\x07상시\\x07연결되어\\x07즉각적인\\x07AI\\x07서비스\\x07제공이\\x07가능한\\x07모바일·웨어러블\\x07 기기를\\x07중심으로\\x07온디바이스\\x07 생성형\\x07AI를\\x07\\n탑재한\\x07제품\\x07개발\\x07및\\x07출시기업명 기술\\x07동향\\n삼성전자 •  ’23년\\x07온디바이스\\x07환경에서\\x07생성형\\x07AI\\x07서비스\\x07제공을\\x07위한\\x07’삼성\\x07가우스’를\\x07공개,\\x07’24년부터\\x07갤럭시S24\\x07등의\\x07제품에\\x07탑재\\n카카오•  한국어\\x07특화\\x07AI\\x07언어모델인\\x07‘KoGPT’를\\x07’21년\\x07공개했으며\\x07구글의\\x07텐서\\x07처리\\x07장치를\\x07활용,\\x07연산속도\\x07고도화.\\x07’24년\\x071월\\x07새\\x07언어모델 \\x07\\n‘허니비’를\\x07공개하였으며\\x07문자와\\x07이미지를\\x07동시에\\x07학습하고\\x07연산할\\x07수\\x07있는\\x07멀티모달(다중모델)\\x07기반의\\x07대규모\\x07언어모델(LLM)을 \\x07\\n오픈소스\\x07형태로\\x07구현 \\x07\\n네이버 •  블로그,\\x07카페,\\x07지식\\x07IN\\x07등\\x07자사\\x07서비스의\\x07대규모\\x07데이터를\\x07활용해\\x07한국어\\x07대용량\\x07데이터를\\x07구축한\\x07‘하이퍼\\x07클로버’를\\x07  ’21년\\x07공개\\nLG전자 •  멀티모달\\x07연산이\\x07가능한\\x07초거대\\x07AI\\x07‘EXAONE\\x072.0’\\x07공개\\nLGCNS •  대규모\\x07언어모델(LLM)을\\x07탑재한\\x07생성형\\x07AI\\x07서비스\\x07플래폼\\x07‘DAP\\x07GenAI’\\x07구축\\nLGU+•  ’24년\\x07LG\\x07AI\\x07연구원과\\x07협업해\\x07통신,\\x07플랫폼,\\x07금융\\x07등\\x07다양한\\x07분야에\\x07적용\\x07가능한\\x07생성형\\x07AI\\x07모델인\\x07‘익시젠(ixi-GEN)’개발\\x07계획 \\x07\\n공개.\\x07딥엑스와\\x07협력하여\\x07추후\\x07온디바이스\\x07환경에서도\\x07익시젠\\x07기반\\x07서비스를\\x07제공하기로\\x07발표\\nSKC&C •  네이버와\\x07협력하여\\x07‘한국형\\x07AI\\x07서비스’를\\x07공동개발하여\\x07기업\\x07맞춤형\\x07보고서\\x07제작\\x07솔루션\\x07개발\\n삼성SDS •  기업\\x07내\\x07업무\\x07생산성을\\x07높이기\\x07위한\\x07생산형\\x07AI\\x07플랫폼\\x07‘브리티\\x07코파일럿(Brity\\x07Copilot)’과\\x07‘패브릭스(Fabrix)’공개\\n적용분야 사례\\x07및\\x07주요내용\\n웨어러블\\n온디바이스         휴메인(Humane) / AI 핀\\n•  퀄컴\\x07모바일\\x07AI반도체\\x07기반\\x07생성형\\x07지능\\x07탑재한\\x07퍼스널\\x07디지털\\x07디바이스(’23.12,\\x07발표, \\x07\\n’24년\\x07국내\\x07출시\\x07예정) \\x07\\n•  생성AI\\x07탑재를\\x07통해\\x07통번역,\\x07전화\\x07송수신,\\x07건강 ·영양,\\x07사진촬영,\\x07검색,\\x07이메일\\x07요약, \\x07\\n음악재생\\x07등\\x07서비스\\x07제공\\n         틴에이저엔지니어링(TeenageEngineering) / Rabbit R1\\n•  대형\\x07액션모델\\x07기반으로\\x07휴대폰\\x07앱구동\\x07AI에이전트\\x07장치(’24.1,\\x07출시)\\n•  사용자\\x07음성을\\x07통해\\x07쇼핑,\\x07호텔\\x07예약,\\x07메시지\\x07송신\\x07등\\x07서비스\\x07제공\\n'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 18}, page_content='19\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS적용분야 사례\\x07및\\x07주요내용\\n웨어러블\\n온디바이스         메타(Meta) / 스마트 (AI) 안경\\n•  스마트안경\\x07레이밴\\x07스토리\\x07출시(’23.10\\x07발표,\\x07미출시)\\n•  메타\\x07생성형\\x07AI\\x07탑재를\\x07통해\\x07사용자\\x07시선의\\x07사물에\\x07대한\\x07실시간\\x07정보\\x07제공\\n         삼성전자 / 갤럭시링\\n•  반지\\x07형태의\\x07스마트링(’24.1\\x07발표,\\x078월\\x07출시\\x07예정)\\n•  심박수,\\x07혈압,\\x07산소포화도,\\x07수면\\x07품질\\x07등\\x07실시간\\x07측정,\\x07지능형\\x07헬스\\x07기능을\\x07통한\\x07맞춤형\\x07건강 \\x07\\n가이드\\x07제공\\n         탭AI(TabAI) / AI 펜던트\\n•  작은\\x07원형\\x07팬던트\\x07(’24.1,\\x07국내\\x07미출시)\\n•  30시간\\x07지속\\x07배터리,\\x07마이크와\\x07블루투스\\x07사용해\\x07오디오를\\x07수집\\x07및\\x07스마트\\x07폰과\\x07연동하여 \\x07\\n클라우드\\x07전송,\\x07ChatGPT를\\x07활용하여\\x07다양한\\x07통찰력\\x07제공\\n         오우라헬스(Oura Health) / 오우라링(3세대)\\n•  반지\\x07형태의\\x07스마트링(’21년말,\\x07국내\\x07미출시)\\n•  수면\\x07추적(체온,\\x07심박,\\x07심박변이\\x07등),\\x07활동\\x07추적(3D가속도를\\x07통한\\x07운동·활동\\x07모니터링\\x07등)\\x07등\\n모빌리티\\n온디바이스         유토피아(UTOPIA) / 전기자전거 퓨전(Fusion)\\n•  생성형AI\\x07연동\\x07애플\\x07디자이너와\\x07협업된\\x07제품\\x07전기자전거(’23.7,\\x07발표)\\n•  사용자\\x07음성을\\x07통한\\x07정보(수리,\\x07영양플랜,\\x07부상회복),\\x07GPS(여행경로,\\x07도난방지),\\x07건강(심박)  \\n등\\x07서비스\\x07제공\\n스마트\\n오피스·홈\\n온디바이스         플라우드 노트(PLAUD NOTE) / 플라우드 노트\\n•  ChatGPT\\x07기반의\\x07스마트\\x07레코더(’23.11,\\x07출시)\\n•  녹음(통화,\\x07일반)\\x07및\\x07녹음내용의\\x07실시간\\x07텍스트\\x07번역,\\x07\\x07요점정리,\\x07마인드맵\\x07정리,\\x07메일\\x07발송\\x07등  \\n서비스\\x07제공\\n         LG전자 / 가전\\n•  멀티모달\\x07센서와\\x07온디바이스\\x07AI\\x07적용한\\x07초개인화\\x07가전\\x07스마트\\x07홈\\x07에이전트\\x07공개(’24.1,\\x07CES)\\n•  가전용\\x07AI\\x07칩\\x07개발\\n스마트폰\\n온디바이스         삼성전자 / 갤럭시S24\\n•  삼성전자의\\x07생성형\\x07AI\\x07모델(삼성\\x07가우스)을\\x07탑재한\\x07스마트폰(’24.1,\\x07출시)\\n•  통화중\\x07실시간\\x07통역(13개국),\\x07실시간\\x07문자\\x07번역(13개국),\\x07사용자\\x07언어를\\x07통한\\x07검색,\\x07문서\\x07요약  \\n등\\x07서비스\\x07제공\\n         구글 / 픽셀8 Pro\\n•  LLM\\x07온디바이스\\x07모델(나노)를\\x07탑재한\\x07스마트폰(’23.12,\\x07출시)\\n•  생성형\\x07AI\\x07기반\\x07망연동\\x07없는\\x07녹음내용\\x07요약,\\x07대화\\x07맥락\\x07분석을\\x07통한\\x07답변\\x07제안,\\x07영상\\x07교정\\x07등  \\n서비스\\x07지원\\n'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 19}, page_content='20\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATSⅣ. 미래 발전 방향\\n1향후 전망\\n  (시장) 온디바이스 AI 기술은 AI 시장의 중심이 될 것으로 기대\\n◎  개인정보\\x07보호,\\x07안정적인\\x07실시간\\x07서비스,\\x07서버\\x07운영비용\\x07절감\\x07등\\x07온디바이스\\x07 AI의\\x07다양한\\x07강점으로\\x07인해\\x07향후\\x07AI\\x07시장의\\x07\\n게임\\x07체인저\\x07역할\\x07예상\\n -  온디바이스\\t AI\\t기술은\\t대규모\\t클라우드\\t서버\\t운영이\\t필요\\t없어\\t비용\\t절감\\t측면에서\\t혁신적인\\t기술이며,\\t 나아가\\t데이터\\t\\n센터의\\t에너지\\t소모\\t절감\\t가능\\n   •\\t\\t오픈AI는\\t’23년\\t매출이\\t2조\\t원이\\t넘었으나\\t하루\\t약\\t9억\\t원으로\\t추산되는\\t막대한\\t운영비용으로\\t수익\\t실패\\n -  글로벌\\t빅테크들은\\t경쟁적으로\\t온디바이스\\tAI\\t기술\\t실현에\\t앞장서고\\t있으며,\\t지속적인\\t투자\\t계획\\t발표\\n◎   현재\\x07온디바이스\\x07 AI\\x07분야로\\x07대표되는\\x07스마트폰\\x07외\\x07웨어러블\\x07기기,\\x07로봇,\\x07디지털\\x07헬스케어,\\x07 스마트\\x07홈\\x07등\\x07다양한\\x07산업에서\\x07\\n폭넓게\\x07활용될\\x07것으로\\x07전망\\n -  AI\\t서비스가\\t일상에\\t깊숙이\\t침투함에\\t따라\\t개인정보\\t보호에\\t대한\\t중요성은\\t나날이\\t증대\\n   •\\t\\t지능형\\t블랙박스 ·인공지능(AI)\\t 스피커 ·지능형\\tCCTV\\t등\\t일상\\t속\\tAI\\t서비스에는\\t 사용자의\\t음성,\\t영상\\t등이\\t입력\\t\\n데이터로\\t활용되며,\\t이러한\\t개인정보에\\t대한\\t보호\\t조치\\t필요\\n -  온디바이스\\tAI를\\t활용해\\t개인정보\\t보호\\t문제없이\\t사용자\\t맞춤형\\tAI\\t서비스를\\t제공할\\t수\\t있어\\t활용성\\t클\\t것으로\\t기대\\n  (업계) 기술확보를 위한 M&A 및 AI 관련 인력 확보 전쟁 심화\\n◎  미래\\x07산업으로의\\x07전환을\\x07위해\\x07전\\x07산업에서의\\x07AI분야\\x07M&A\\x07활발히\\x07진행\\n\\t -\\t\\tAI가\\t타산업의\\t발전을\\t가속화하는\\t 기반\\t기술로\\t부상하며\\t로봇,\\t헬스케어,\\t 모빌리티,\\t 게임·엔터\\t 등\\t전\\t산업에\\t적용되고\\t\\n영향력\\t확대됨에\\t따라\\tAI를\\t중심으로\\t기술\\t융합과\\t혁신\\t진행\\n     *\\t\\t최초\\t보급\\t후\\t10년차\\t침투율(PWC·Bessemer\\tVC,\\t%)\\t:\\t(생성형AI)66,\\t(스마트폰)55,\\t(SW\\t내\\t클라우드)31'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 20}, page_content='21\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS\\t -\\t\\t경기\\t불확실성에도\\t첨단기술인\\tAI(온디바이스AI,\\t메타버스\\t기술\\t및\\t하드웨어)에\\t대한\\t투자에\\t집중해\\t미래\\t산업\\t대응\\n   •\\t\\t(테크)\\t온디바이스\\tAI,\\t메타버스,\\t하드웨어\\t등\\tAI\\t관련\\t기술\\t확보를\\t위한\\tM&A\\t진행\\n   •\\t\\t(통신)\\t데이터센터,\\t AI,\\t로봇,\\t클라우드\\t등\\t미래\\t기술에\\t대한\\t투자\\t지속\\t및\\t디지털화·커넥티드\\t 역량\\t확보를\\t위해\\t\\n소프트웨어,\\t모빌리티,\\t기계\\t업종\\t등과의\\t제휴\\t증가\\n   •\\t\\t(미디어)\\t빅테크의\\t파운데이션\\t개발\\t투자,\\t스타트업\\t지분\\t투자·M&A\\t통해\\t생성형\\tAI\\t기반\\t다양한\\t수익모델\\t시도\\n◎   AI관련\\x07핵심\\x07인재\\x07확보를\\x07위한\\x07빅테크\\x07기업\\x07간\\x07경쟁\\x07심화\\n -  OpenAI,\\t구글,\\tMS,\\t애플,\\t메타\\t등\\t빅테크\\t기업들은\\tAI\\t인력에게\\t연봉,\\t스톡옵션\\t등\\t막대한\\t조건을\\t제시하여\\t공격적인\\t\\n영입\\t제시하며\\tAI\\t인재\\t확보에\\t총력\\n     *\\t\\t글로벌\\t빅테크\\tAI\\t연구원(‘23년\\t신규\\t박사급\\tAI\\t연구원\\t기준)\\t초봉(한국경제·로라,\\t만\\t달러) \\t\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t:\\t(오픈AI)86.5,\\t(엔스로픽)85.5,\\t(인플렉션AI)82.5,\\t(테슬라)78,\\t(아마존)71.9,\\t(구글브레인)69.5 \\t산업별 AI 영향도\\n산업 영향도\\n로봇 •  AI\\x07접목된\\x07로봇은\\x07최종적으로는\\x07인간의\\x07개입을\\x07필요로\\x07하지\\x07않는\\x07‘무인화’\\x07로봇,\\x07즉\\x07스스로\\x07활동할\\x07수\\x07있는\\x07‘휴머노이드\\x07로봇’으로\\x07발전\\n헬스케어•  (신약개발)\\x07딥러닝을\\x07통한\\x07단백질\\x07구조\\x07해독\\x07등으로\\x07신약개발에\\x07소요되는\\x07시간\\x07획기적\\x07단축\\n•  (진단/치료)\\x07딥러닝으로\\x07환자\\x07유전자\\x07데이터를\\x07분석,\\x07대규모\\x07의료영상\\x07빠르게\\x07처리\\x07→\\x07질병\\x07판독\\x07및\\x07의료진\\x07치료결정에서\\x07불확실성\\x07감소\\n•  (예방)\\x07헬스케어\\x07기관들이\\x07보유한\\x07방대한\\x07의료\\x07데이터를\\x07활용하여,\\x07개인별\\x07질병\\x07발생\\x07확률\\x07예측\\x07&\\x07사전\\x07예방형\\x07치료\\x07제공\\n•  (서비스)\\x07헬스\\x07디바이스의\\x07 발전과\\x07함께\\x07주요\\x07건강지표들의\\x07 지속적\\x07모니터링\\x07&\\x07챗봇을\\x07통한\\x07의료상담\\x07등이\\x07가능해지면서,\\x07 원격의료\\x07본격화\\n모빌리티•  인포테인먼트·커넥티드를\\x07넘어\\x07자율주행의\\x07시대\\x07도래\\n  -\\t도로\\t주행데이터\\t축적\\t및\\tAI\\t분석능력\\t향상으로\\t완성도\\t높은\\t자율주행시스템구현\\n게임·엔터•  (개발)\\x07AI를\\x07통한\\x07코딩\\x07자동화를\\x07통해\\x07개발자들의\\x07중복되는\\x07코드\\x07작업\\x07최소화.\\x07인건비\\x07감소는\\x07기업들의\\x07제작비용을\\x07감소시켜\\x07더\\x07많은 \\x07\\n콘텐츠\\x07개발\\x07및\\x07진입\\x07장벽을\\x07낮춰\\x07신생업체들의\\x07대규모\\x07유입\\x07유도\\n•\\x07(콘텐츠)\\x07AI는\\x07메타버스와\\x07결합해\\x07게임/엔터/교육의\\x07궁극적인\\x07변화\\x07이끌\\x07전망\\n\\t\\t-\\tAI를\\t활용한\\t디자인\\t프로세스\\t간소화로\\t3D\\t부문의\\t급속한\\t발전\\t가능.\\t홀로그램\\t활성화로\\t‘가상-현실의\\t경계’가\\t모호해질\\t것으로\\t전망\\n\\t\\t-\\t메타버스\\t활성화로\\t게임/엔터/교육/광고\\t분야에\\t큰\\t수혜\\t예상\\n테크•  (하드웨어)\\x07개인\\x07IT\\x07기기(핸드폰,\\x07태블릿\\x07등)에\\x07온디바이스\\x07AI\\x07탑재되며\\x07신규\\x07수요\\x07창출\\x07및\\x07XR(확장현실)기기\\x07등\\x07신제품\\x07출시\\n•  (소프트웨어)\\x07AI\\x07모델에\\x07대한\\x07시장\\x07선점을\\x07위한\\x07글로벌\\x07기업들의\\x07개발\\x07경쟁\\x07지속\\x07및\\x07AI를\\x07활용한\\x07개인\\x07맞춤형\\x07서비스를\\x07제공할\\x07수\\x07있는 \\x07\\n어플리케이션\\x07발전\\n•  (반도체)\\x07AI\\x07반도체에\\x07대한\\x07중요성\\x07부각되며,\\x07시스템\\x07반도체\\x07부문\\x07핵심\\x07경쟁력을\\x07확보하기\\x07위한\\x07글로벌\\x07거대\\x07기업들의\\x07투자\\x07지속\\n금융•  챗봇(상담\\x07업무)를\\x07넘어서\\x07금융\\x07비서로\\x07AI\\x07업무\\x07영역\\x07확장\\n\\t\\t-\\t자연어\\t처리\\t역량이\\t음성인식과\\t맞물릴\\t경우\\t모바일\\t환경에\\t익숙하지\\t않은\\t연령층까지\\t고객군\\t확대\\t가능\\n\\t\\t-\\t단순\\t상담\\t업무\\t뿐\\t아니라\\t자산관리\\t및\\t투자\\t부분에서도\\tAI의\\t역할\\t확대\\t예상\\n*\\t출처\\t:\\tPWC( ’24)'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 21}, page_content='22\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS -  국내\\tAI\\t인력은\\t경쟁국에\\t비해\\t매우\\t부족한\\t상황으로\\t민간의\\t인재\\t유치\\t강화\\t전략\\t및\\t정부\\t맞춤\\t인재육성\\t정책\\t절실\\n     *\\t\\t’20년\\t국가별\\t글로벌\\tAI\\t전문인재\\t확보\\t현황(한국일보·엘리멘트AI,\\t%)\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t:\\t(1위)미국\\t39.4,\\t(2위)인도\\t15.9,\\t(3위)영국\\t7.4,\\t(4위)중국\\t4.6....(22위)한국\\t0.5\\n -  AI\\t반도체\\t시장\\t주도를\\t위해\\t반도체사들의\\t인력전쟁도\\t엔디비아를\\t중심으로\\t진행되어\\t국내업체에서의\\t인력\\t유출\\t심화\\n  (기술·서비스) 킬러 서비스 확보를 위한 경쟁 심화 및 개인화된 맞춤형 AI로 점진적 발전 예상\\n◎  경량\\x07생성형\\x07AI\\x07모델,\\x07NPU와\\x07같은\\x07온디바이스\\x07 AI\\x07실현을\\x07위한\\x07기반\\x07기술의\\x07성숙도가\\x07높아짐에\\x07따라\\x07이를\\x07활용해\\x07\\n사용자에게\\x07혁신적인\\x07경험을\\x07제공하기\\x07위한\\x07킬러\\x07서비스\\x07확보\\x07경쟁\\x07심화\\x07예상\\n\\t -\\t\\t온디바이스\\t AI\\t기술\\t자체는\\t이전부터\\t활용되고\\t있어\\t사용자에게\\t 새로운\\t경험\\t제공이\\t어려우며,\\t 온디바이스\\t 생성형\\tAI\\t\\n기반의\\t차별화된\\t서비스\\t개발\\t필요\\n   •\\t\\t스마트폰의\\t 파노라마\\t사진,\\t사진에서\\t객체\\t제거,\\t실시간\\t영상\\t합성\\t기능을\\t비롯해\\t블랙박스의\\t 차량\\t출발\\t감지\\t기능,\\t\\n지능형\\tCCTV의\\t객체\\t인식\\t기능\\t등\\t다양한\\t온디바이스\\tAI\\t서비스\\t기\\t보편화 \\t\\n\\t -\\t\\t사용자가\\t체감\\t가능한\\t온디바이스\\t생성형\\tAI\\t기술은\\t스마트폰\\t중심의\\t실시간\\t통역과\\t음성\\t대화의\\t텍스트\\t요약\\t수준 \\t\\n\\t -\\t\\t글로벌\\t빅테크들은\\t 스마트폰 ·AI\\tPC·웨어러블\\t기기\\t내\\t온디바이스\\t 생성형\\tAI\\t기술을\\t활용하여\\t대표\\t서비스\\t개발에\\t\\n박차를\\t가하고\\t있으며\\t‘24년\\t말부터는\\t갤럭시\\t링을\\t포함하여\\t단계적\\t출시\\t예상빅테크간 AI 및 반도체 인력 전쟁\\n(단위\\t:\\t명,\\t ’24.\\t6.\\t17\\t링크드인\\t가입자\\t기준)\\n*\\t출처\\t:\\t조선일보(’24)\\nAI 인력 이동 현황 반도체 인력 이동 현황\\n링크드인\\n가입한\\t직원수 애플\\n17만\\n3,249\\n구글\\n28만\\n6,760\\n메타\\n11만\\n9,611마이크로\\n소프트\\n22만\\n8,954삼성\\n전자\\n엔비\\n디아278515 2,848\\n544\\n12\\n89\\n159\\n3838\\n0\\n6,5771만\\n3,2383,3451,9674,219\\n6,3834,8813,066\\n2,474\\n8,880\\n2,857마이\\n크론TSMC\\nSK\\n하이닉스인텔'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 22}, page_content='23\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS◎   맞춤형\\x07AI\\x07서비스를\\x07위해서는\\x07개인의\\x07데이터를\\x07기반으로\\x07AI\\x07모델의\\x07점진적\\x07업데이트\\x07필요\\n -  현재는\\t서버에서\\t학습된\\tAI\\t모델을\\t모든\\t사용자가\\t동일하게\\t사용하고\\t있어\\t사용자\\t특성이\\t반영된\\t서비스\\t제공\\t불가\\n -  디바이스에서\\t수집한\\t사용자의\\t데이터\\t통해\\t지속적으로\\tAI\\t모델을\\t업데이트하여\\t사용자별\\t특화된\\t서비스\\t제공\\t가능\\n -  AI모델학습은\\t 추론\\t대비\\t훨씬\\t많은\\t컴퓨팅\\t자원이\\t필요해\\t온디바이스\\t 환경에서의\\t AI모델학습을\\t 위해\\t많은\\t난관\\t극복\\t필요\\n -  최근\\t서버향\\t타겟의\\tNPU에서\\t학습을\\t지원하는\\t등\\t기술\\t발전이\\t이루어지고\\t있어\\t향후\\t맞춤형\\tAI\\t서비스의\\t실현\\t기대\\n2정책 제언\\n  온디바이스 AI 시장 선점을 위해 중소기업 시장 참여를 통한 생태계 확장 필요\\n◎  국내\\x07온디바이스\\x07 생성형\\x07AI\\x07기술은\\x07저전력\\x07고효율\\x07지능형\\x07반도체\\x07개발이라는\\x07 후방\\x07산업에\\x07집중되어\\x07있고\\x07서비스는\\x07일부\\x07\\n대기업\\x07위주로만\\x07개발\\x07중으로,\\x07혁신적인\\x07서비스\\x07개발이\\x07이루어지지\\x07않아\\x07전방\\x07산업\\x07부진\\n -  삼성전자의\\t 스마트폰에\\t 중점적인\\t온디바이스\\t 시스템을\\t위한\\t기반\\t역량은\\t보유하고\\t있으나\\t폐쇄된\\t대기업\\t기술로\\t\\n중소기업과\\t역량\\t차이\\t매우\\t큼\\n◎   국내\\x07중소기업\\x07기술역량\\x07한계로\\x07높은\\x07난이도의\\x07온디바이스\\x07AI\\x07기술\\x07도입\\x07난항\\n -  ’21년\\t12월\\t말\\t기준\\t전체\\t기업체(20만\\t7,000여개)의\\tAI\\t기술\\t및\\t서비스\\t이용률은\\t2.7%로\\t매우\\t낮음 \\t\\n -  국내\\t기업\\t100곳\\t중\\t3곳만이\\tAI\\t기술을\\t도입했으며\\t AI를\\t도입한\\t기업\\t대부분은\\t대기업(91.7%).\\t 중소기업의\\t AI\\t도입\\t시\\t\\n가장\\t큰\\t걸림돌은\\t수요에\\t맞는\\tAI\\t기술\\t및\\t인력\\t부족(72.1%) \\t\\n◎   사용자\\x07수요\\x07증대를\\x07통해\\x07전방기술\\x07시장을\\x07확대하고\\x07지속적인\\x07성장을\\x07견인하기\\x07위해서\\x07다수의\\x07중소기업이\\x07 생태계에\\x07참여해\\x07\\n도전적이고\\x07참신한\\x07서비스\\x07발굴\\x07필요\\n   중소기업의 온디바이스 AI 시장 진입 장벽 해소를 위한 기술·서비스 개발, 인력양성 등 맞춤형 \\n정책지원 필요\\n◎  (기술 개발 및 연구 기반 지원) 온디바이스\\x07생성형\\x07AI\\x07제품\\x07및\\x07서비스\\x07개발을\\x07위한\\x07연구\\x07기반\\x07지원\\x07필요\\n\\t -\\t\\t온디바이스\\t 생성형\\tAI의\\t특성상\\t서비스\\t개발을\\t위해서는\\t온디바이스\\t AI\\t하드웨어부터\\t 소프트웨어\\t 및\\t경량화된\\t생성형\\t\\n모델까지\\t필요하나\\t이는\\t중소기업이\\t시장에\\t진입하는\\t것을\\t가로막는\\t주요\\t걸림돌\\n\\t -\\t\\t저전력\\t레퍼런스\\t보드,\\t개방형\\t생성형\\tAI\\t모델,\\t한국어\\t타겟\\t학습\\t데이터\\t공개\\t등\\t중소기업의\\t 기술적\\t제약을\\t해소해\\t\\n혁신적인\\t제품\\t및\\t서비스를\\t개발할\\t수\\t있도록\\t기반\\t지원\\t필요'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 23}, page_content='24\\n   2024.06  제6호\\nDIGISIGHT온디바이스 AI 기술동향 및 발전방향\\nDIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS◎   (인력 양성 및 교육 지원) 온디바이스\\x07 AI\\x07인재\\x07부족\\x07현상을\\x07해소하기\\x07위해\\x07국가\\x07차원의\\x07인력\\x07양성\\x07및\\x07재직자\\x07역량\\x07강화를\\x07\\n위한\\x07교육\\x07지원\\x07필요\\n -  서버\\t시스템\\t지원\\tAI\\t소프트웨어\\t 및\\t하드웨어\\t인력은\\t국가의\\t전략적인\\t연구개발\\t투자\\t및\\t인력\\t양성으로\\t지속적으로\\t 증가\\n -  온디바이스\\t AI\\t소프트웨어\\t 및\\t하드웨어\\t시스템에\\t대한\\t역량을\\t가진\\t인재는\\t매우\\t부족하여\\tAI\\t및\\t임베디드\\t시스템\\t기술\\t\\n전문성이\\t융합된\\t온디바이스\\tAI\\t인력\\t양성이\\t핵심\\n -  온디바이스\\t AI\\t인재\\t풀\\t확대와\\t기술\\t수준\\t향상을\\t위해\\t대학\\t등을\\t대상으로\\t한\\t인력\\t양성\\t뿐만\\t아니라\\t중소기업\\t재직자\\t\\n대상\\t교육\\t지원\\t등\\t다각도에서\\t정책적\\t지원\\t필요\\n◎   (서비스 개발 및 실증 사업 지원) 온디바이스\\x07생성형\\x07AI\\x07적용\\x07서비스\\x07사례\\x07확보를\\x07위한\\x07실증지원\\x07절실\\n -  국내\\t중소기업은\\t AI\\t기술\\t및\\tNPU\\t확보,\\tAI\\t인력,\\t외부\\t전문가\\t협업\\t등\\t자원이\\t부족하여\\t서비스\\t출시\\t및\\t사례\\t확보가\\t\\n어려워\\t신산업\\t진출,\\t글로벌\\t수출\\t차질\\n -  특히,\\t학습\\t데이터\\t확보,\\t온디바이스\\t AI\\t하드웨어\\t및\\t최적화된\\t소프트웨어\\t 개발\\t등\\t서비스\\t개발을\\t위해\\t시간과\\t비용이\\t\\n많이\\t필요한\\t온디바이스\\t생성형\\tAI\\t특성\\t상\\t종래\\t단기간\\t내\\t실증\\t사업은\\t실효성\\t부족\\n - \\t온디바이스\\t 생성형\\tAI\\t서비스\\t개발과\\t실환경\\t장기간\\t검증을\\t수행할\\t수\\t있도록\\t2~3년차의\\t 중기간\\t사업을\\t통한\\t실증지원\\t필요'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 24}, page_content='•\\t\\tAI반도체\\t시장\\t현황\\t및\\t전망,\\t2024,\\t한국수출입은행\\n•\\t\\t생성형\\tAI\\t열풍으로\\t성큼\\t다가온\\t온디바이스\\tAI,\\t2024,\\tLG경영연구원\\n•\\t\\t저전력\\t온디바이스\\t비전\\tSW\\t프레임워크\\t기술\\t동향,\\t2021,\\t한국전자통신기술연구원\\n•\\t\\tAI·디지털\\t혁신성장\\t전략(요약),\\t2024,\\t과학기술정보통신부(관계부처\\t합동)\\n•\\t\\t온디바이스\\tAI\\t시장\\t규모,\\t2023,\\t마켓츠앤마켓츠 ·파이낸셜뉴스\\n•\\t\\t생성형\\tAI\\t스마트폰\\t시장\\t규모,\\t2023,\\t카운터포인트리서치\\n•\\t\\t생성형\\tAI\\t시장\\t규모,\\t2023,\\t블룸버그인텔리전스\\n•\\t\\tLarge\\tLanguage\\tModel\\tCost\\tAnalysis,\\t2023,\\t세미에널리시스\\n•\\t\\tGlobal\\tM&A\\tIndustry\\tTrends\\t:\\t2024\\tOutlook,\\t2024,\\t삼일PwC경영연구원\\n•\\t\\t빅테크\\t기업\\t‘AI ·반도체\\t인재\\t쟁탈전’,\\t2024,\\t조선일보\\n•\\t\\t글로벌\\t빅테크\\tAI\\t연구원\\t초봉,\\t2024,\\t한국경제 ·로라\\n•\\t\\t글로벌\\tAI\\t인재보고,\\t2024,\\t한국일보·엘리먼트AI\\n•\\t\\t정보화통계조사,\\t2022,\\t한국지능정보사회진흥원\\n•\\t\\tAI에\\t대한\\t기업체\\t인식\\t및\\t실태조사,\\t2021,\\t한국개발연구원참고문헌\\n25   2024.06  제6호'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 25}, page_content='KEA NOW\\nKEA 주요 소식을 한눈에\\n   2024.06  제6호'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 26}, page_content='KEA NOW\\n27KEA,\\nKTC와 업무협약 체결KEA,\\n전자제조 스타트업 육성 \\n한국전자정보통신산업진흥회(KEA)는\\t6월\\t5일 \\t\\n한국기계전기전자시험연구원(KTC)와\\t가전·전자기업을 \\t\\n포함한\\tICT유망기업의\\t공동\\t발굴\\t및\\t지원프로그램 \\t\\n협력강화를\\t위한\\t업무협약을\\t체결하였다. \\t\\n양\\t기관은\\t이번\\t협약을\\t통해\\t△ICT유망기업\\t육성을 \\t\\n위한\\t협력\\t네트워크\\t구축\\t△스마트가전,\\tIoT사이버보안, \\t\\n인공지능,\\t소프트웨어,\\t5G/6G\\t등\\t분야의\\t시험·인증 \\t\\n컨설팅\\t지원\\t△KEA\\t전자혁신제조\\t지원센터, \\t\\nXR실증센터,\\t빅데이터센터의\\t기업지원\\t프로그램을 \\t\\n공동\\t활용하여\\t미래\\t유망기업의\\t혁신성장을\\t지원한다.\\n특히,\\tIoT보안인증에\\t대응하여\\t수출기업이\\t심각한 \\t\\n애로에\\t직면하지\\t않도록\\t사이버보안\\t관련\\t해외인증 \\t\\n정보와\\t컨설팅을\\t제공한다.\\n이번\\t협약은\\t양\\t기관의\\t협업\\t네트워크를\\t기반으로 \\t\\nICT유망기업의\\t제품·서비스\\t개발부터\\t시험·인증\\t및 \\t\\n제품\\t출시까지\\t수요자\\t중심의\\t끊김없는(Seamless) \\t\\n지원체계를\\t구축하는데\\t의미가\\t크다.\\n양\\t기관은\\t업무협약의\\t첫\\t행사로\\t6월\\t27일,\\t상암동 \\t\\n전자회관에서\\t가전·전자기업을\\t위한\\t‘해외\\tIoT사이버\\n보안\\t컨퍼런스’를\\t개최할\\t예정이다.\\n박청원\\tKEA\\t부회장은\\t“이번\\t협약이\\tICT유망기업의 \\t\\n혁신성장을\\t위한\\t지원기관\\t간\\t협력을\\t강화하는데\\t의미가 \\t\\n크다며,\\tKEA는\\t전자·IT산업\\t진흥기관으로써\\t수요자 \\t\\n중심의\\t기업지원플랫폼이\\t되도록\\t유관기관과\\t협력을 \\t\\n지속해\\t나가겠다.”고\\t밝혔다.한국전자정보통신산업진흥회(KEA)는 \\t6월\\t9일\\t아프리카\\t\\n케냐\\t콘자개발청(KoTDA) \\t관계자들이 \\t서울\\t용산에\\t위치한\\t\\n전자제조센터를 \\t방문,\\t전자제조\\t스타트업\\t육성\\t모델을\\t\\n벤치마킹하고\\t 교류\\t방안을\\t논의했다고\\t 밝혔다.\\t\\nKEA\\t전자제조센터는 \\t도심형\\t제조시설로,\\t 연간\\t\\n200여종\\t전자제품\\t 생산을\\t지원한다. \\t40여종\\t전문장비 \\t\\n시설을\\t갖추고\\t있어\\t스타트업이 \\t어려움을\\t느끼는\\t시제품\\t\\n설계와\\t생산\\t지원에\\t특화돼\\t있다.\\tKEA\\t기술진이\\t전자분야\\t\\n제품\\t개발부터\\t생산,\\t홍보,\\t전시\\t과정을\\t지원한다.\\n케냐\\t정부는\\t국민\\t삶의\\t질\\t향상과\\t산업화\\t지원으로\\t\\n중산층\\t국가로\\t거듭나기\\t위한\\t비전\\t2030을\\t추진하고\\t\\n있다.\\t이의\\t일환으로\\tKoTDA는\\t수도\\t나이로비에서 \\t60㎞\\t\\n떨어진\\t지역에\\t스마트시티를\\t 꾸리고\\t첨단기술\\t스타트업을\\t\\n육성하기\\t위한\\t생태계를\\t조성하는\\t‘콘자\\t테크노폴리스 ’ \\n프로젝트를\\t 추진하고\\t있다.\\t첨단기술과 \\t제조·연구시설을\\t\\n갖춰\\t아프리카의 \\t기술\\t허브로\\t발전시키는 \\t것이\\t목표다.\\n전자제조센터에는 \\tKoTDA\\t위원회\\t이사장과\\t부청장이\\t\\n방문하여\\t케냐\\t콘자의\\t도시\\t모델에\\t반영하기\\t위해\\t한국의\\t\\n선진\\t전자산업\\t시설과\\t산업\\t생태계를\\t둘러봤다.\\nKEA는\\t전자제조센터의\\t 국내\\t혁신제품\\t전초기지\\t역할,\\t\\n지원\\t프로그램,\\t한국\\t스타트업\\t생태계\\t구조를\\t설명했다.\\t\\n내부\\t시설을\\t소개하고,\\t지원한\\t주요\\t스타트업\\t제품을\\t\\n소개했다.\\tKoTDA는\\t콘자\\t테크노폴리스 \\t사업\\t내\\t\\n과학기술원과 \\tICT\\t스타트업\\t육성에\\tKEA\\t전자제조센터\\t\\n모델을\\t반영할\\t방침이다.\\n박청원\\tKEA\\t부회장은\\t“케냐와\\t유기적\\t파트너십\\t구축을\\t\\n기대한다”며 \\t“KEA\\t지원\\t모델이\\t개발도상국을\\t 포함해\\t\\n세계적으로\\t 확산되도록\\t 노력하고\\t스타트업의 \\t전자제품\\t\\n전시와\\t홍보에도\\t협력하겠다”고 \\t밝혔다.\\n1 2KEA 주요 소식을 한눈에\\n   2024.06  제6호\\nDIGISIGHT MEMBER NEWS KEA NOW STATS ESG TREND'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 27}, page_content='KEA NOW\\n28KEA 주요 소식을 한눈에\\n   2024.06  제6호3\\n한국전자정보통신산업진흥회(KEA)는\\t6월\\t11일 \\t\\n양재\\t엘타워에서\\t ‘2024년도\\t제1차\\t전자정보분야 \\t\\n해외기술규제\\t설명회 ’를\\t개최했다.\\n최근\\t산업계\\t전반에서는\\t생성형AI·머신러닝\\t등의 \\t\\n기술개발\\t과정에서\\t투명성을\\t강화해\\t자국\\t산업을 \\t\\n보호하고,\\t제품의\\t생애주기\\t정보\\t등을\\t공개해\\t공급망을 \\t\\n관리하고\\t있다.\\n‘전자정보분야\\t해외기술규제\\t설명회 ’는\\t이\\t같은 \\t\\n추세를\\t반영해\\tAI,\\t사이버보안,\\t화학물질\\t등\\t전자정보 \\t\\n분야의\\t주요\\t해외\\t기술규제에\\t대한\\t산·학·연의\\t대응력 \\t\\n강화를\\t위해\\t개최했다.\\n이번\\t설명회는\\t▲AI\\t사이버\\t시큐리티\\t기술동향\\t및 \\t\\n대응방안\\t▲EU\\t사이버복원력법(CRA)\\t규제동향\\t및 \\t\\n대응방안\\t▲EU\\tDPP\\t규제동향\\t및\\t대응방안 \\t\\n▲분석장비를\\t활용한\\t과불화화합물(PFAS)\\t규제 \\t\\n대응방안\\t순으로\\t발표를\\t진행했다.\\nKEA\\t박청원\\t부회장은\\t “오늘\\t설명회는\\t전자·IT업계 \\t\\n화두가\\t되는\\t해외기술규제\\t대응력\\t강화를\\t위한\\t설명회\\n로서\\t우리나라\\t전자·IT기업들이\\t중대한\\t해외기술규제에 \\t\\n선제적으로\\t대응하는데\\t도움이\\t될\\t중요한\\t자리라고 \\t\\n생각한다”며\\t “전자·IT업계에서\\t무역기술장벽을\\t넘기 \\t\\n위해\\t애쓰는\\t기업들이\\t지속적으로\\t성장해\\t나갈\\t수 \\t\\n있도록\\t적극\\t노력하겠다”고\\t말했다.KEA,\\n전자정보분야 해외기술규제 \\n설명회 개최\\n4\\n한국전자정보통신산업진흥회(KEA)는\\t6월\\t12일과 \\t\\n13일\\t양일간\\t영덕군과\\t의성군에서\\t가전제품\\t무상점검과 \\t\\n건강진단\\t기반\\t의료기기\\t체험\\t행사를\\t실시했다.\\n행사에는\\t삼성전자,\\t세라젬,\\tLG전자,\\t오텍캐리어, \\t\\n쿠쿠전자,\\t쿠첸,\\t휴롬엘에스,\\t경동나비엔,\\t귀뚜라미가 \\t\\n참여했다.\\t\\n전자기업은\\t휴대폰\\t서비스\\t차량과\\t실내\\t행사장에\\t부스를 \\t\\n설치하고\\t농어민,\\t고령자,\\t다문화가정\\t등\\t취약계층 \\t\\n소비자의\\t노트북,\\t밥솥,\\t청소기,\\t공기청정기\\t등\\t소형가전\\n제품\\t무상수리와\\t의료기기\\t체험을\\t제공했다.\\t노인복지관, \\t\\n보육원,\\t장애인복지관\\t등\\t사회배려시설을\\t사전\\t방문해 \\t\\n보일러와\\t대형가전\\t제품을\\t점검·수리했다.\\n행사와\\t연계해\\t어르신\\t장수사진\\t촬영,\\t취약계층 \\t\\n소비자의\\t피해\\t예방\\t교육과\\t자산관리\\t상담,\\t고령자\\t대상 \\t\\n건강상태\\t진단과\\t의료기기\\t체험\\t행사도\\t실시했다. \\t\\n마을\\t단위로\\t수집한\\t소형폐가전도\\t회수했다.\\n본\\t행사는\\t한국소비자원과\\t경상북도\\t영덕군, \\t\\n의성군\\t등\\t지자체가\\t공동으로\\t주관하였으며, \\t\\n한국전자정보통신산업진흥회,\\t기업소비자전문가협회, \\t\\n한국자동차모빌리티산업협회,\\t한국석유관리원, \\t\\n한국주택금융공사,\\tLG생활건강\\t등이\\t참여하여\\t행사를 \\t\\n지원하였다.KEA,\\n영덕·의성에서 \\n가전제품 무상점검 행사\\nDIGISIGHT MEMBER NEWS KEA NOW STATS ESG TREND'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 28}, page_content='MEMBER NEWS\\n KEA 회원사의 성과와 동향\\n   2024.06  제6호'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 29}, page_content='MEMBER NEWS\\n30세라젬,\\n헬스케어 도전 및 \\n매출 3조 목표디지윌, \\n양방향 AI 최첨단 교육 시스템 \\n‘클래스 아이 ’ 출시\\n국내\\t안마의자\\t1위\\t기업인\\t세라젬의 \\t\\n이경수\\t대표는\\t한국경제신문과의\\t인터뷰에서 \\t\\n“7대\\t사업부문으로\\t영역을\\t확장해 \\t\\n글로벌\\t종합\\t헬스케어\\t회사로\\t발돋움하겠다”\\n며\\t이같이\\t말했다.\\t2022년\\t7501억원이던 \\t\\n회사\\t매출을\\t2028년까지\\t3조원으로 \\t\\n끌어올리겠다는\\t포부도\\t밝혔다.\\n이어\\t“아직\\t공개하지\\t않은\\t제품이\\t계속\\t연달아 \\t\\n출시될\\t것”이라며\\t“세븐케어라고\\t이름\\t붙인 \\t\\n우리\\t7개\\t사업군을\\t국내뿐\\t아니라\\t해외에서도 \\t\\n체험할\\t수\\t있도록\\t5년\\t안에\\t전\\t세계\\t1만\\t개 \\t\\n오프라인\\t점포를\\t여는\\t게\\t목표”라고\\t말했다. \\t\\n세라젬은\\t아시아,\\t미주뿐\\t아니라\\t유럽, \\t\\n아프리카,\\t중동\\t등\\t70여\\t개국에\\t진출해\\t있다.\\n올해\\t새로\\t나올\\t제품은\\t혈액\\t순환을\\t돕는 \\t\\n의료기기,\\t공기청정기,\\t맞춤형\\t영양제, \\t\\n우울증\\t치료기,\\t불면증\\t치료기\\t등이\\t있다. \\t\\n최근\\t출시한\\t파우제\\tM6는\\t척추\\t스캔\\t기술, \\t\\n온열\\t기능을\\t담은\\t실리콘\\t볼,\\t팔다리\\t안마\\t기능\\t\\n등을\\t다\\t담았다.최근\\t㈜디지윌(대표\\t홍석환)이\\tAI\\t기반 \\t\\n실시간\\t양방향\\t공유\\t에듀테크\\t시스템 \\t\\n‘클래스\\t아이(Class\\tinteraction)’를\\t출시해 \\t\\n주목을\\t받고\\t있다.\\t이번에\\t출시된\\t‘클래스 \\t\\n아이’는\\t수업\\t모듬형\\t조별\\t학습장치,\\t콘텐츠·\\n학습관리\\t시스템(LMS),\\tAI학습분석\\t솔루션, \\t\\n멀티미디어\\t학습장치(미디어\\t허브)\\t등\\t하나로 \\t\\n통합\\t관리가\\t가능한\\t시스템이다.\\n현재\\t전남교육청과\\t협력해\\t여수와\\t목포에 \\t\\n사전\\t시범\\t운영하고\\t있으며,\\t오는\\t29일 \\t\\n여수세계박람회장에서\\t‘2024\\t대한민국\\t글로컬\\n미래교육박람회’에서\\t미래교실을\\t시연할 \\t\\n예정이다.\\n홍석환\\t디지윌\\t대표이사는\\t “지속\\t가능한 \\t\\n성장과\\t사회적\\t책임\\t달성을\\t위해\\t고객\\t요구에 \\t\\n적극\\t대응하며\\t기술\\t혁신에\\t중점을\\t두고\\t있다”\\n며\\t“회사가\\t추구하는\\t미래\\t가치를\\t바탕으로 \\t\\n지속적인\\t연구개발을\\t통해\\t급변하는\\t디지털 \\t\\n시대에\\t발맞춰\\t나가겠다”고\\t밝혔다.1 2 KEA 회원사의 성과와 동향\\n   2024.06  제6호*기사를\\t클릭하면\\t보다\\t자세한\\t내용을\\t확인하실\\t수\\t있습니다. \\t\\nDIGISIGHT MEMBER NEWS KEA NOW STATS ESG TREND'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 30}, page_content='MEMBER NEWS\\n31삼영전자공업, \\n친환경 모빌리티 시장 \\n최적화 하이브리드 콘덴서 개발코맥스,  \\n대한적십자사 의료원에 \\n디지털 도어락 기부\\n알루미늄\\t전해콘덴서\\t전문생산업체 \\t\\n삼영전자는\\t일본케미콘과\\t기술협력을\\t통해 \\t\\n장수명\\t하이브리드\\t 콘덴서를\\t개발했다고\\t 밝혔다.\\n이번에\\t개발된\\tFPV/FPW/FRV시리즈는 \\t\\n고온도(125℃이상)\\t환경에서\\t전해콘덴서의 \\t\\n보증\\t수명을\\t해결하여\\tADAS첨단운전자\\n지원시스템,\\tHUD헤드업디스플레이, \\t\\nTelematics인터넷차량정보통신장치, \\t\\nIBU통합바디제어기\\t등\\t친환경\\t자동차\\t분야와 \\t\\n외부\\t노출로\\t큰\\t기온\\t변화를\\t견뎌야\\t하는 \\t\\n5G\\t통신용기지국\\t같은\\t고신뢰성이\\t필요한 \\t\\n특수\\t산업\\t시장에서\\t활용할\\t수\\t있다.\\n업체\\t관계자는\\t“이번\\t장수명\\t하이브리드 \\t\\n콘덴서\\t개발로\\t인해\\t전량\\t수입에만\\t의존했던 \\t\\n하이브리드\\t콘덴서의\\t국산화가\\t기능해졌다며 \\t\\n친환경\\t자동차시장의\\t성장과\\t더불어 \\t\\n하이브리드\\t콘덴서의\\t글로벌\\t시장\\t규모도 \\t\\n매년\\t30%\\t이상\\t성장하고\\t있어\\t향후에도 \\t\\n지속적인\\t투자와\\t연구개발로\\t신제품\\t개발을 \\t\\n이어나갈\\t것이다”고\\t말했다.스마트홈\\t전문기업\\t코맥스가\\t대한적십자사 \\t\\n의료원에\\t5000만원\\t상당의\\t스마트\\t디지털 \\t\\n도어락을\\t기부했다고\\t밝혔다.\\t이번\\t기부는 \\t\\n코맥스가\\t사회공헌활동의\\t일환으로\\t국민의 \\t\\n건강을\\t위해\\t노력하는\\t대한적십자사\\t의료원과 \\t\\n해당\\t시설을\\t이용하는\\t환우들에게\\t도움을\\t주기 \\t\\n위한\\t목적으로\\t진행됐다.\\n코맥스의\\t스마트\\t디지털\\t도어락은\\t카드, \\t\\n비밀번호\\t뿐\\t아니라\\t지문\\t인식,\\t얼굴\\t인식이 \\t\\n가능한\\t스마트\\t바이오\\t등\\t강력한\\t보안\\t기능들이 \\t\\n탑재돼\\t병원\\t내\\t안전과\\t보안을\\t크게\\t향상시킬 \\t\\n것으로\\t기대된다.\\t또\\t이를\\t통해\\t의료진과 \\t\\n환우의\\t편리한\\t생활이\\t보장되고\\t병원\\t운영의 \\t\\n효율성도\\t높아질\\t것으로\\t전망된다.\\n이기상\\t코맥스\\t전략기획부문장은\\t“불철주야 \\t\\n노고가\\t많은\\t의료진과\\t응원이\\t필요한\\t환우\\t및 \\t\\n가족들에게\\t작은\\t격려라도\\t해드리고\\t싶다”며 \\t\\n“이번\\t기부를\\t통해\\t새로운\\t인연을\\t맺고, \\t\\n지속적인\\t사회공헌활동으로\\t사회적\\t기업의 \\t\\n책임을\\t다하겠다”고\\t강조했다.3 4 KEA 회원사의 성과와 동향\\n   2024.06  제6호*기사를\\t클릭하면\\t보다\\t자세한\\t내용을\\t확인하실\\t수\\t있습니다. \\t\\nDIGISIGHT MEMBER NEWS KEA NOW STATS ESG TREND'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 31}, page_content='ESG TREND\\nESG Regulations 주요현황\\n   2024.06  제6호'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 32}, page_content='ESG TREND\\n33\\nDIGISIGHT MEMBER NEWS KEA NOW STATS\\n   2024.06  제6호ESG Regulations 주요현황\\n1 2\\n환경부(한국환경공단)는 \\t전기·전자제품\\t환경성보장제를  \\n전품목으로 \\t확대할\\t방침이며,\\t지난\\t5월\\t30일\\t전기전자\\t\\n업계\\t대상으로\\t확대\\t계획\\t설명회를\\t개최하였다.\\n환경성보장제는 \\t전기·전자제품의 \\t재활용을\\t촉진하기\\t\\n위해\\t제조·수입업자의 \\t유해물질\\t사용\\t억제,\\t재활용\\t정보의  \\n제공,\\t폐제품\\t회수 ·재활용\\t및\\t재질구조개선사항 \\t평가\\t등\\t\\n6대\\t의무를\\t부여하는\\t제도로서,\\t2008년\\t최초\\t도입\\t이래\\t\\n현재\\t50개\\t품목에\\t적용\\t중이다.\\n환경부는\\t시장\\t발전에\\t따라\\t다양해진\\t품목을\\t관리하고\\t\\n국가\\t회수 ·재활용\\t목표의\\t원활한\\t달성을\\t위해\\t환경성\\n보장제를\\t전품목으로 \\t확대할\\t예정이며,\\t의류건조기, \\t\\n의류관리기,\\t 전기레인지 \\t및\\t디지털카메라 \\t등\\t신규\\t품목에\\t\\n대해\\t2026년부터 \\t회수 ·재활용\\t의무를\\t적용하고\\t\\n2028년부터 \\t유해물질\\t사용제한도\\t 시행할\\t전망이다.\\n더\\t나아가\\t현재\\t49개\\t품목\\t대상\\t시행\\t중인\\t재질 ·구조\\n개선사항\\t평가제도의 \\t대상\\t품목도\\t장기적으로 \\t확대될\\t\\n것으로\\t예상된다.\\n환경부는\\t올\\t하반기\\t중\\t근거\\t법률인\\t전자제품등\\t\\n자원순환법 \\t개정안을\\t공개하고\\t12월까지\\t법률\\t개정을\\t\\n완료할\\t계획이며,\\tKEA는\\t향후\\t입법\\t동향을\\t모니터링하고\\t\\n전자업계의 \\t의견이\\t반영될\\t수\\t있도록\\t노력할\\t방침이다.우즈베키스탄으로 \\t수출되는\\t가전제품에 \\t대한\\t에너지\\n효율등급\\t시험기관의\\t 부족\\t및\\t운영\\t차질로\\t수출기업의\\t\\n인증서\\t발급\\t지연과\\t통관\\t애로가\\t우려된다.\\n우즈베키스탄 \\t정부는\\t올해\\t1월부터\\t에너지대책의 \\t\\n일환으로\\t에너지효율 \\tB등급\\t이하\\t가전제품의\\t\\n수입\\t금지\\t조치를\\t시행\\t중이며,\\t현재는\\t냉장고,\\t에어컨\\t\\n2개\\t품목에\\t적용\\t중이나\\t향후\\t대상\\t품목을\\t세탁기,\\t\\n청소기,\\tTV,\\t모니터,\\t전자레인지 \\t등\\t여러\\t품목으로\\t\\n확대할\\t계획이다.\\n우리나라\\t수출기업은 \\t통관\\t시\\t현지\\t시험기관이 \\t발급한\\t\\n에너지효율등급 \\t적합성\\t인증서(CoC)*를 \\t제출해야\\t하나,\\t\\n이용\\t가능한\\t시험기관이 \\t에어컨\\t2개소,\\t냉장고\\t1개소에\\t\\n불과할\\t뿐\\t아니라\\t일부\\t기관은\\t내부\\t사정으로\\tCoC\\t\\n발급\\t업무가\\t중단됨으로\\t 인해\\tCoC\\t발급\\t지연이 \\t\\n우려되는\\t실정이다.\\t나아가\\t대상\\t품목이\\t확대될\\t경우\\t\\n인증\\t수요를\\t더\\t해소하기\\t어려워질\\t전망이다.\\n*\\tCoC(Certificate \\tof\\tConformity)\\nKEA는\\t국가기술표준원(이하 \\t국표원)의\\t전자산업\\tTBT\\t\\n기술규제대응 \\t지원기관으로서 \\t업계와\\t대응방안을 \\t여러\\t\\n차례\\t논의하였으며, \\t국표원을\\t통해\\t대상\\t품목\\t추가\\t시\\t\\n인증서\\t발급기간을\\t 확보할\\t수\\t있도록\\t우즈베키스탄 \\t\\n정부에\\t충분한\\t유예기간\\t부여를\\t요청하였다.\\n’24년 내 환경성보장제 \\n전품목 확대 계획수입 가전제품 에너지효율등급 \\n인증서 발급 지연\\n출처\\t:\\t환경정책협의회 출처\\t:\\tKEA\\tTBT\\t사무국\\nESG\\tTrend\\t관련\\t문의사항은 \\tESG&글로벌협력실(02-6388-6186 \\t/\\tdaniel_eom@gokea.org)로 \\t문의\\t바랍니다.\\nESG TREND환경부 우즈베키스탄\\n*\\t이미지  출처\\t:\\t뉴스와이어'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 33}, page_content=' 데이터로 읽는 전자·IT 업황\\n   2024.06  제6호STATS'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 34}, page_content='35*\\t출처\\t:\\t과학기술정보통신부,\\tICT주요품목동향조사,\\tICT수출입통계 \\t구분 1월 2월 3월 4월 5월 6월 7월 8월 9월 10월 11월 12월 계\\n생\\n산2022 31.830.433.131.831.831.431.230.129.929.128.328.8367.8\\n2023 25.6\\t24.4\\t26.0\\t24.2\\t25.7\\t26.4\\t26.7\\t27.6\\t28.4\\t29.0\\t29.729.1322.9\\n2024 27.627.028.328.3\\n수\\n출2022 19.6\\t18.9\\t23.3\\t19.9\\t20.2\\t20.6\\t19.3\\t19.3\\t20.8\\t17.9\\t16.6\\t16.9\\t233.2\\t\\n2023 13.1\\t12.8\\t15.8\\t12.8\\t14.4\\t16.1\\t14.6\\t16.0\\t18.0\\t17.1\\t17.9\\t18.2\\t186.7\\n2024 16.416.518.817.119.1(단위:\\t조원\\t/\\t십억불)감소 증가1. 전자·IT 제조업 생산, 수출\\n•   (생산)  ’22년\\t6월부터\\t17개월간\\t 전년동월대비\\t 감소세를\\t지속해오다\\t ’23년\\t11월부터\\t 증가세로\\t전환됐으며 \\t\\n’24년\\t4월\\t생산은\\t전년동월대비\\t16.8%\\t증가한\\t28.3조원\\n•   (수출) ’22년\\t7월부터\\t16개월간\\t 전년동월대비\\t 감소세를\\t지속해오다\\t ‘23년\\t11월부터\\t 증가세로\\t전환됐으며 \\t\\n’24년\\t5월\\t수출은\\t전년동월대비\\t31.8%\\t증가한\\t19.1억불 데이터로 읽는 전자·IT 업황\\n   2024.06  제6호STATS\\nDIGISIGHT MEMBER NEWS KEA NOW STATS ESG TREND\\n’21.1월 ’21.6월 ’22.1월 ’23.1월 ’22.6월5.0 20.010.025.030.025.0\\n20.0\\n15.035.0\\n생산\\n수출\\n19.1\\n17.1\\n28.328.3'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 35}, page_content='36*\\t출처\\t:\\t과학기술정보통신부,\\tICT기업경기조사\\n※\\t제품재고,\\t생산설비,\\t고용수준\\tBSI는\\t일반적으로\\t경기상승기에는\\t하락하고,\\t경기하강기에는\\t상승하는\\t역계열구분 1월 2월 3월 4월 5월 6월 7월 8월 9월 10월 11월 12월\\n실적\\nBSI2022 86 84 83 91107 108 107 103 95106 98 99\\n2023 101 100 107 103 98 95 96 97 95 96 95100\\n2024 99 98 93102 98\\n전망\\nBSI2022 99103 102 102 111 105 103 105 104 101 105 101\\n2023 101 100 103 104 100 99 97 98 95 98 96 98\\n2024 99101 99 98 97102(100\\t기준\\t+\\t:\\t호조,\\t-\\t:\\t악화) \\t 악화 호조\\n’22.1월 ’22.6월 ’23.1월 ’23.6월 ’24.1월80100120\\n전망BSI실적BSI2. 전자·IT 기업경기실사지수(BSI)\\n•   (실적BSI)  ’24년\\t5월\\t실적\\tBSI는\\t98로\\t전월대비\\t악화\\n-\\t\\t부분별로\\t설비투자실행(101)은\\t 전월대비\\t개선\\t됐으나,\\t생산설비(100)는\\t 전월과\\t동일,\\t자금사정(97), \\t\\n고용수준(104),\\t제품재고(102),\\t생산설비(101)는\\t전월대비\\t악화\\n•   (전망BSI)  ’24년\\t6월\\t전자·IT\\t전망\\tBSI는\\t102로\\t5월\\t대비\\t개선\\t전망\\n-  부분별로\\t설비투자실행(102)은\\t 전월대비\\t개선을\\t기대하나,\\t 자금사정(100)은\\t 5월과\\t동일,\\t제품재고(106), \\t\\n고용수준(104),\\t생산설비(102)는\\t부정적으로\\t전망 데이터로 읽는 전자·IT 업황\\n   2024.06  제6호STATS\\nDIGISIGHT MEMBER NEWS KEA NOW STATS ESG TREND\\n97102 102\\n98'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 36}, page_content='•   (생산)  ’22년\\t7월부터\\t13개월간\\t전년동월대비\\t감소세\\t지속해오다\\t ’23년\\t8월부터\\t증가세로\\t전환됐으며\\n   ’24년\\t4월은\\t전년동월대비\\t18.7%\\t증가 \\t\\n•   (출하)  ’22년\\t11월부터\\t7개월간\\t전년동월대비\\t감소세\\t지속해오다\\t ’23년\\t6월부터\\t증가세로\\t전환됐으며\\n   ’24년\\t4월은\\t전년동월대비\\t16.4%\\t증가 \\t\\n•   (재고)  ’22년,\\t’23년간\\t재고\\t부담\\t지속되었으나,\\t ’24년\\t1월부터\\t감소세로\\t전환됐으며\\t ’24년\\t4월은\\n\\t\\t\\t전년동월대비\\t19.0%\\t감소\\n•   (가동률)  ’22년\\t7월부터\\t13개월간\\t전년동월대비\\t감소세\\t지속해오다\\t ’23년\\t8월부터\\t증가세로\\t전환됐으며\\n   ’24년\\t4월은\\t전년동월대비\\t10.1%\\t증가\\n37*\\t출처\\t:\\t통계청,\\t광업제조업동향조사(원지수),\\t전자·IT\\t제조를\\tKSIC\\t26(전자부품,\\t컴퓨터,\\t영상\\t및\\t통신장비\\t제조업)\\t한정구분 1월 2월 3월 4월 5월 6월 7월 8월 9월 10월 11월 12월 계\\n생산\\n지수2022127.5122.0140.2127.3129.4132.1120.8112.4114.7114.7106.6103.6120.9\\n2023 89.180.7106.9 99.1109.7114.7106.0124.2138.4127.6134.8138.2114.1\\n2024117.6117.6131.1117.6\\n출하\\n지수2022105.0105.9127.2105.2115.2114.3 88.998.0125.8110.3 95.5103.6107.9\\n2023 78.678.2114.6 83.697.6131.9 91.0108.8147.3113.2122.4149.1109.7\\n2024103.2105.9124.2 97.3\\n재고\\n지수2022124.0130.5111.2118.0119.6120.0142.0138.5117.5131.0142.9132.7132.7\\n2023164.6165.1148.9180.7187.0153.1179.2198.9169.0170.9177.6136.8136.8\\n2024137.5149.3133.0146.3\\n가동률\\n지수2022106.6100.6115.0104.0104.2105.9 99.091.992.592.386.585.598.7\\n2023 74.766.387.381.487.491.986.599.2103.4 97.3102.5 99.689.8\\n2024 89.589.598.489.6(2020=100)감소 증가3. 전자·IT 제조업 생산, 출하, 재고, 가동률 동향 데이터로 읽는 전자·IT 업황\\n   2024.06  제6호STATS\\nDIGISIGHT MEMBER NEWS KEA NOW STATS ESG TREND\\n’22.1월 ’22.6월 ’23.1월 ’24.1월 ’23.6월50100200\\n150250\\n생산\\n가동률출하\\n재고\\n146.3\\n97.3\\n89.6117.6'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 37}, page_content='KEA Issue Report\\n온디바이스 AI 기술동향 및 발전방향\\n발행처 한국전자정보통신산업진흥회(KEA)\\n발행일\\t 2024년\\t6월\\n발행인\\t 박청원\\tKEA\\t부회장\\n작        성\\t KEA\\t산업정책실\\n제        작 디.두잇\\n문의처\\t KEA\\t산업정책실\\n\\t (02-6388-6170~6177,\\tghahn@gokea.org)\\n홈페이지\\t www.gokea.org\\n본\\t보고서\\t저작권은\\t 한국전자정보통신산업진흥회 에\\t있습니다. \\t\\n내용을\\t인용\\t또는\\t전재하고자\\t할\\t경우\\t반드시\\t출처를\\t명기하여\\t주시기\\t바라며,\\n무단전제와\\t무단복제를\\t금합니다.'),\n",
              " Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 38}, page_content='2024-06호\\n* 표지 이미지는 ChatGPT 4.0으로 제작하였습니다')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 문서 로드\n",
        "await adocs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85fbeN1P3zCc"
      },
      "source": [
        "## 08-053 문서 분할 및 첫 번째 문서 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NorQyOwF3zCc",
        "outputId": "449738d4-dd3e-4287-d651-19ef85a7d8fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': '온디바이스 AI 기술동향 및 발전방향.pdf', 'page': 0}, page_content='온디바이스 AI \\n기술동향 및 발전방향ISSUE \\nREPORT \\n2024-06호')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "# 문자열 분할기 설정\n",
        "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
        "# 문서 분할\n",
        "docs = loader.load_and_split(text_splitter=text_splitter)\n",
        "\n",
        "# 로드된 문서의 수 확인\n",
        "print(len(docs))\n",
        "# 첫번째 문서 확인\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSeydQbs3zCd"
      },
      "source": [
        "## 08-054 PDF 로더 초기화 및 페이지 내용 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKcFrTBh3zCd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# 설치\n",
        "!pip install -qU rapidocr-onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NH7XpsiK3zCd",
        "outputId": "4192ad28-79e2-424e-d59b-347231c9ac96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scaled Dot-Product Attention\n",
            " Multi-Head Attention\n",
            "Figure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\n",
            "attention layers running in parallel.\n",
            "of the values, where the weight assigned to each value is computed by a compatibility function of the\n",
            "query with the corresponding key.\n",
            "3.2.1 Scaled Dot-Product Attention\n",
            "We call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\n",
            "queries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\n",
            "query with all keys, divide each by√dk, and apply a softmax function to obtain the weights on the\n",
            "values.\n",
            "In practice, we compute the attention function on a set of queries simultaneously, packed together\n",
            "into a matrix Q. The keys and values are also packed together into matrices KandV. We compute\n",
            "the matrix of outputs as:\n",
            "Attention( Q, K, V ) = softmax(QKT\n",
            "√dk)V (1)\n",
            "The two most commonly used attention functions are additive attention [ 2], and dot-product (multi-\n",
            "plicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\n",
            "of1√dk. Additive attention computes the compatibility function using a feed-forward network with\n",
            "a single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\n",
            "much faster and more space-efficient in practice, since it can be implemented using highly optimized\n",
            "matrix multiplication code.\n",
            "While for small values of dkthe two mechanisms perform similarly, additive attention outperforms\n",
            "dot product attention without scaling for larger values of dk[3]. We suspect that for large values of\n",
            "dk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\n",
            "extremely small gradients4. To counteract this effect, we scale the dot products by1√dk.\n",
            "3.2.2 Multi-Head Attention\n",
            "Instead of performing a single attention function with dmodel-dimensional keys, values and queries,\n",
            "we found it beneficial to linearly project the queries, keys and values htimes with different, learned\n",
            "linear projections to dk,dkanddvdimensions, respectively. On each of these projected versions of\n",
            "queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\n",
            "4To illustrate why the dot products get large, assume that the components of qandkare independent random\n",
            "variables with mean 0and variance 1. Then their dot product, q·k=Pdk\n",
            "i=1qiki, has mean 0and variance dk.\n",
            "4MatMul\n",
            "SoftMax\n",
            "Mask\n",
            "(opt.)\n",
            "Scale\n",
            "MatMul\n",
            "KLinear\n",
            "Concat\n",
            "Scaled Dot-Product\n",
            "Attention\n",
            "Linear\n",
            "Linear\n",
            "Linear\n",
            "K\n"
          ]
        }
      ],
      "source": [
        "# PDF 로더 초기화, 이미지 추출 옵션 활성화\n",
        "loader = PyPDFLoader(\"https://arxiv.org/pdf/1706.03762.pdf\", extract_images=True)\n",
        "\n",
        "# PDF 페이지 로드\n",
        "docs = loader.load()\n",
        "\n",
        "# 페이지 내용 접근\n",
        "print(docs[3].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0RwPPyT3zCd"
      },
      "source": [
        "## 08-055 PyMuPDF 로더 초기화 및 문서 내용 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9GjkTyW3zCd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# 설치\n",
        "!pip install -qU pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8RZs95x3zCd",
        "outputId": "00d5d60f-d546-4595-e31f-f49a1b1526bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11\n",
            "   2024.06  제6호\n",
            "DIGISIGHT\n",
            "온디바이스 AI 기술동향 및 발전방향\n",
            "DIGISIGHT\n",
            "ESG TREND\n",
            "MEMBER NEWS\n",
            "KEA NOW\n",
            "STATS\n",
            "3 국가별 정책\n",
            "◎ \u0007자사 AI 칩 기반의 생태계 구축을 위해 데이터·AI 모델·추론기술·SDK*를 아우르는 전방위적 기술 지원\n",
            "     * \u0007소프트웨어를 개발하는 도구로 소프트웨어 개발자가 특정 운영체제용 응용프로그램을 만들 수 있는 소스와 도구 패키지\n",
            "◎ \u0007(애플) 자사의 하드웨어 환경에서 애플의 뉴럴 엔진을 활용하여 온디바이스 AI를 수행할 수 있도록 Cor\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "# PyMuPDF 로더 인스턴스 생성\n",
        "loader = PyMuPDFLoader(FILE_PATH)\n",
        "\n",
        "# 문서 로드\n",
        "docs = loader.load()\n",
        "\n",
        "# 문서의 내용 출력\n",
        "print(docs[10].page_content[:300])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbYkr_ph3zCd"
      },
      "source": [
        "## 08-056 OpenAI 임베딩 생성 및 쿼리 결과 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf6UDdoY3zCd",
        "outputId": "b5f4851e-0a56-4277-c272-243553f38ead"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.00776276458054781,\n",
              " 0.03680367395281792,\n",
              " 0.019545823335647583,\n",
              " -0.0196656696498394,\n",
              " 0.017203375697135925]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# OpenAI의 \"text-embedding-3-large\" 모델을 사용하여 임베딩을 생성합니다.\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# 텍스트를 임베딩하여 쿼리 결과를 생성합니다.\n",
        "query_result = embeddings.embed_query(\"임베딩 테스트를 하기 위한 샘플 문장입니다.\")\n",
        "query_result[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r9fSxxh3zCd"
      },
      "source": [
        "## 08-057 여러 텍스트 일괄 임베딩 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YID8uStd3zCe",
        "outputId": "329eb8e4-9ed6-4913-c51b-5a98e085b23c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 여러 텍스트를 일괄 임베딩하여 벡터를 생성합니다.\n",
        "doc_result = embeddings.embed_documents(\n",
        "    ['임베딩 테스트를 하기 위한 샘플 문장입니다.',\n",
        "     'AI Essential']\n",
        ")\n",
        "# 문서 결과의 첫 번째 요소의 길이를 반환합니다.\n",
        "len(doc_result[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ1Fi2y13zCe"
      },
      "source": [
        "## 08-058 캐시 지원 임베딩 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02AHHCSk3zCe"
      },
      "outputs": [],
      "source": [
        "from langchain.storage import InMemoryByteStore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.embeddings import CacheBackedEmbeddings\n",
        "\n",
        "# OpenAI의 \"text-embedding-3-large\" 모델을 사용하여 임베딩을 생성합니다.\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# 인메모리 스토어를 생성합니다.\n",
        "store = InMemoryByteStore()\n",
        "\n",
        "# 캐시를 지원하는 임베딩 생성\n",
        "cached_embeding = CacheBackedEmbeddings.from_bytes_store(\n",
        "    underlying_embeddings=embeddings,\n",
        "    document_embedding_cache=store,\n",
        "    namespace=embeddings.model,  # 기본 임베딩과 저장소를 사용하여 캐시 지원 임베딩을 생성\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3TdzqFo3zCe"
      },
      "source": [
        "## 08-059 캐시 지원 임베딩으로 쿼리 결과 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zsH4ra93zCe",
        "outputId": "c679a812-b61f-4b86-9842-7e7653fa2027"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.00776276458054781,\n",
              " 0.03680367395281792,\n",
              " 0.019545823335647583,\n",
              " -0.0196656696498394,\n",
              " 0.017203375697135925,\n",
              " -0.008378338068723679,\n",
              " -0.011592394672334194,\n",
              " 0.0007585718994960189,\n",
              " 0.028152959421277046,\n",
              " -0.04094381630420685,\n",
              " 0.013411877676844597,\n",
              " 0.055870115756988525,\n",
              " -0.002635254291817546,\n",
              " 0.020537279546260834,\n",
              " -0.012518479488790035,\n",
              " -0.036999788135290146,\n",
              " -0.018380047753453255,\n",
              " -0.007250694558024406,\n",
              " 0.015405682846903801,\n",
              " 0.019567614421248436,\n",
              " 0.015645375475287437,\n",
              " -0.0020741561893373728,\n",
              " -0.0005818668869324028,\n",
              " 0.012246101163327694,\n",
              " -0.0008191759116016328,\n",
              " -0.053255289793014526,\n",
              " 0.0039249625988304615,\n",
              " 0.012878017500042915,\n",
              " 0.04602093622088432,\n",
              " -0.0320969894528389,\n",
              " -0.005605533253401518,\n",
              " -0.01834736205637455,\n",
              " 0.022945096716284752,\n",
              " -0.02640974149107933,\n",
              " 0.05377825349569321,\n",
              " 0.02941679209470749,\n",
              " -0.029177099466323853,\n",
              " -0.009549561887979507,\n",
              " 0.003766983514651656,\n",
              " 0.006874813232570887,\n",
              " -0.0009165509836748242,\n",
              " -0.015906857326626778,\n",
              " 0.02255287393927574,\n",
              " 0.02318478934466839,\n",
              " 0.016037598252296448,\n",
              " 0.051991455256938934,\n",
              " -0.0031623051036149263,\n",
              " -0.004259987268596888,\n",
              " 0.02386028692126274,\n",
              " 0.018979277461767197,\n",
              " -0.025864986702799797,\n",
              " 0.032336682081222534,\n",
              " 0.010170583613216877,\n",
              " -0.025538133457303047,\n",
              " -0.0011058534728363156,\n",
              " 0.05207861587405205,\n",
              " -0.016669515520334244,\n",
              " 0.03900448605418205,\n",
              " 0.030745994299650192,\n",
              " 0.031356122344732285,\n",
              " 0.022356761619448662,\n",
              " -0.015176885761320591,\n",
              " -0.012747276574373245,\n",
              " 0.027085239067673683,\n",
              " -0.019774621352553368,\n",
              " 0.006433561444282532,\n",
              " -0.02582140639424324,\n",
              " 0.008519974537193775,\n",
              " 0.012311471626162529,\n",
              " 0.007975218817591667,\n",
              " 0.08049305528402328,\n",
              " 0.04070412367582321,\n",
              " -0.013771416619420052,\n",
              " 0.011309121735394001,\n",
              " -0.013945737853646278,\n",
              " -0.026518693193793297,\n",
              " -0.021201880648732185,\n",
              " 0.04094381630420685,\n",
              " -0.020940396934747696,\n",
              " -0.008988464251160622,\n",
              " 0.018641529604792595,\n",
              " 0.004630420822650194,\n",
              " 0.014817346818745136,\n",
              " -0.01795513741672039,\n",
              " -0.005790750030428171,\n",
              " -0.0037996689788997173,\n",
              " -0.14259517192840576,\n",
              " 0.026889126747846603,\n",
              " 0.005305917467921972,\n",
              " -0.030288400128483772,\n",
              " -0.008884960785508156,\n",
              " -0.016342662274837494,\n",
              " 0.008460051380097866,\n",
              " 0.028980987146496773,\n",
              " -0.0010929155396297574,\n",
              " -0.05621875822544098,\n",
              " -0.04440845921635628,\n",
              " -0.04185900464653969,\n",
              " -0.025450972840189934,\n",
              " 0.023163000121712685,\n",
              " 0.04153215140104294,\n",
              " -0.04427772015333176,\n",
              " -0.03118179924786091,\n",
              " 0.00044976366916671395,\n",
              " 0.017573809251189232,\n",
              " 0.009549561887979507,\n",
              " 0.016015809029340744,\n",
              " 0.05621875822544098,\n",
              " -0.06380175054073334,\n",
              " -0.005741721950471401,\n",
              " -0.04541081190109253,\n",
              " 0.04011578857898712,\n",
              " -0.007866268046200275,\n",
              " -0.003979437984526157,\n",
              " 0.04336253181099892,\n",
              " -0.013346507214009762,\n",
              " 0.06938004493713379,\n",
              " -0.0030506302136927843,\n",
              " 0.0061557358130812645,\n",
              " -0.02660585381090641,\n",
              " 0.019905362278223038,\n",
              " 0.007691946346312761,\n",
              " 0.06829053908586502,\n",
              " -0.07635291665792465,\n",
              " -0.027433881536126137,\n",
              " -0.04571587219834328,\n",
              " 0.04645673930644989,\n",
              " -0.03349156305193901,\n",
              " -0.02102755941450596,\n",
              " 0.052906643599271774,\n",
              " 0.013302926905453205,\n",
              " 0.030419141054153442,\n",
              " 0.04022473841905594,\n",
              " -0.001062273047864437,\n",
              " 0.03848152235150337,\n",
              " 0.048592180013656616,\n",
              " -0.025233069434762,\n",
              " 0.024601154029369354,\n",
              " 0.0022307734470814466,\n",
              " 0.01875048130750656,\n",
              " -0.008852275088429451,\n",
              " 0.011864772997796535,\n",
              " 0.010132450610399246,\n",
              " 0.03976714611053467,\n",
              " -0.02745567262172699,\n",
              " -0.01630997657775879,\n",
              " -0.0016601420938968658,\n",
              " 0.018576160073280334,\n",
              " 0.025973938405513763,\n",
              " 0.038307201117277145,\n",
              " -0.0015934095717966557,\n",
              " 0.015046143904328346,\n",
              " -0.03939671069383621,\n",
              " 0.018772270530462265,\n",
              " -0.007092715241014957,\n",
              " -0.004355319309979677,\n",
              " 0.010818841867148876,\n",
              " 0.013422773219645023,\n",
              " 0.0027074343524873257,\n",
              " 0.014741080813109875,\n",
              " -0.019120914861559868,\n",
              " -0.021920956671237946,\n",
              " 0.07186413556337357,\n",
              " 0.02627900056540966,\n",
              " -0.00598141411319375,\n",
              " 0.027695365250110626,\n",
              " 0.03192266821861267,\n",
              " 0.04593377560377121,\n",
              " -0.022923307493329048,\n",
              " 0.003056077752262354,\n",
              " 0.008274834603071213,\n",
              " -0.02810937911272049,\n",
              " -0.035343728959560394,\n",
              " 0.022356761619448662,\n",
              " 0.010377590544521809,\n",
              " 0.01585238240659237,\n",
              " -0.02141978219151497,\n",
              " 0.003816011594608426,\n",
              " 0.021387096494436264,\n",
              " 0.03139970079064369,\n",
              " -0.03192266821861267,\n",
              " 0.07090536504983902,\n",
              " 0.014305276796221733,\n",
              " 0.036280710250139236,\n",
              " -0.06720102578401566,\n",
              " -0.006618778221309185,\n",
              " 0.031029267236590385,\n",
              " 0.04693612456321716,\n",
              " -0.009081072174012661,\n",
              " -0.010404828004539013,\n",
              " -0.028545182198286057,\n",
              " 0.00831841491162777,\n",
              " 0.03353514149785042,\n",
              " 0.012169836089015007,\n",
              " -0.0028082141652703285,\n",
              " -0.08214911818504333,\n",
              " 0.03989788517355919,\n",
              " -0.07094894349575043,\n",
              " -0.01960030011832714,\n",
              " 0.04580303281545639,\n",
              " -0.0049245888367295265,\n",
              " -0.0013149033766239882,\n",
              " -0.03976714611053467,\n",
              " 0.01552552916109562,\n",
              " 0.0006761776166968048,\n",
              " -0.0025126843247562647,\n",
              " -0.00010554635809967294,\n",
              " -0.05020465701818466,\n",
              " -0.0035872142761945724,\n",
              " -0.03713052719831467,\n",
              " 0.021474257111549377,\n",
              " 0.010835184715688229,\n",
              " 0.005235099233686924,\n",
              " -0.06850843876600266,\n",
              " -0.03795855492353439,\n",
              " -0.020809656009078026,\n",
              " 0.0065425122156739235,\n",
              " 0.015590899623930454,\n",
              " -0.01412006001919508,\n",
              " 0.051337748765945435,\n",
              " 0.023620594292879105,\n",
              " -0.010557360015809536,\n",
              " 0.05386541411280632,\n",
              " 0.03662935271859169,\n",
              " -0.004180997610092163,\n",
              " 0.0727357417345047,\n",
              " 0.021190986037254333,\n",
              " -0.014305276796221733,\n",
              " 0.006335505284368992,\n",
              " -0.035082247108221054,\n",
              " 0.013215766288340092,\n",
              " 0.001883491757325828,\n",
              " -0.031944457441568375,\n",
              " 0.0051343198865652084,\n",
              " 0.02856697328388691,\n",
              " 0.008116855286061764,\n",
              " -0.0629301443696022,\n",
              " -0.018238410353660583,\n",
              " -0.03309933841228485,\n",
              " -0.011842982843518257,\n",
              " 0.035670582205057144,\n",
              " 0.059618029743433,\n",
              " -0.014163640327751637,\n",
              " -0.018162144348025322,\n",
              " 0.061622731387615204,\n",
              " 0.01137449312955141,\n",
              " 0.023380901664495468,\n",
              " 0.020613543689250946,\n",
              " 0.07460969686508179,\n",
              " -0.014850032515823841,\n",
              " 0.003952200524508953,\n",
              " 0.02025400660932064,\n",
              " -0.010497436858713627,\n",
              " -0.010143345221877098,\n",
              " -0.06667806208133698,\n",
              " 0.02490621618926525,\n",
              " 0.025320231914520264,\n",
              " 0.045890193432569504,\n",
              " -0.011287331581115723,\n",
              " -0.017867976799607277,\n",
              " -0.03852510079741478,\n",
              " -0.03244563192129135,\n",
              " -0.05168639123439789,\n",
              " 0.000592761964071542,\n",
              " -0.009909100830554962,\n",
              " 0.010748024098575115,\n",
              " 0.05582653358578682,\n",
              " 0.019099123775959015,\n",
              " 0.005872463341802359,\n",
              " -0.08798889070749283,\n",
              " -0.006291924975812435,\n",
              " 0.0025058749597519636,\n",
              " 0.017976928502321243,\n",
              " 0.021866481751203537,\n",
              " -0.04146678000688553,\n",
              " 0.016081178560853004,\n",
              " -0.008846827782690525,\n",
              " -0.04423413798213005,\n",
              " 0.008165883831679821,\n",
              " 0.0753505676984787,\n",
              " -0.03619354963302612,\n",
              " 0.022901516407728195,\n",
              " -0.0076538133434951305,\n",
              " 0.007550309877842665,\n",
              " 0.01854347437620163,\n",
              " -0.0010949583956971765,\n",
              " 0.013902157545089722,\n",
              " -0.02274898625910282,\n",
              " 0.007375988177955151,\n",
              " 0.03368767350912094,\n",
              " -0.012790856882929802,\n",
              " -0.016560563817620277,\n",
              " -0.01663682982325554,\n",
              " 0.0206353347748518,\n",
              " 0.00812230259180069,\n",
              " -0.005363116972148418,\n",
              " 0.01842362806200981,\n",
              " -0.028479812666773796,\n",
              " 0.004976340569555759,\n",
              " -0.0075394148007035255,\n",
              " 0.009380687959492207,\n",
              " 0.005458449013531208,\n",
              " 0.038895536214113235,\n",
              " 0.008351100608706474,\n",
              " -0.024274300783872604,\n",
              " 0.005371288396418095,\n",
              " -0.03597564622759819,\n",
              " -0.03891732543706894,\n",
              " -0.009740226902067661,\n",
              " -0.04554155096411705,\n",
              " -0.05604443699121475,\n",
              " -0.01762828417122364,\n",
              " -0.02425250969827175,\n",
              " -0.022574663162231445,\n",
              " 0.021125614643096924,\n",
              " -0.04475710541009903,\n",
              " 0.010846080258488655,\n",
              " 0.015623585321009159,\n",
              " 0.012932493351399899,\n",
              " -0.013128604739904404,\n",
              " -0.003314836649224162,\n",
              " -0.012562059797346592,\n",
              " -0.00020956058870069683,\n",
              " -0.02438325248658657,\n",
              " -0.008509078994393349,\n",
              " 0.03153044357895851,\n",
              " 0.011243751272559166,\n",
              " 0.0017772645223885775,\n",
              " 0.033709462732076645,\n",
              " -0.013390087522566319,\n",
              " -0.00598141411319375,\n",
              " -0.026758385822176933,\n",
              " 0.024688314646482468,\n",
              " -0.08036231994628906,\n",
              " -0.046500321477651596,\n",
              " -0.005186071619391441,\n",
              " -0.01454496942460537,\n",
              " 0.06528348475694656,\n",
              " -0.013313822448253632,\n",
              " 0.04005041718482971,\n",
              " -0.044975005090236664,\n",
              " 0.041183508932590485,\n",
              " 0.008988464251160622,\n",
              " 0.001308774808421731,\n",
              " 0.026039307937026024,\n",
              " 0.0015416578389704227,\n",
              " 0.03906985744833946,\n",
              " -0.033186499029397964,\n",
              " 0.06981585174798965,\n",
              " -0.01294338796287775,\n",
              " -0.003878658404573798,\n",
              " -0.028719505295157433,\n",
              " 0.023947447538375854,\n",
              " -0.01100405864417553,\n",
              " 0.03059346415102482,\n",
              " -0.041771844029426575,\n",
              " -0.006526169832795858,\n",
              " -0.014991668984293938,\n",
              " 0.02141978219151497,\n",
              " 0.01202819962054491,\n",
              " -0.05656740069389343,\n",
              " 0.0001731300726532936,\n",
              " 0.02266182377934456,\n",
              " 0.0061557358130812645,\n",
              " 0.017377696931362152,\n",
              " -0.0076156803406775,\n",
              " -0.0438854955136776,\n",
              " 0.007076372858136892,\n",
              " 0.0024132663384079933,\n",
              " 0.01906643994152546,\n",
              " -0.0025766929611563683,\n",
              " 0.0064226663671433926,\n",
              " 0.0008940797997638583,\n",
              " -0.0008423280669376254,\n",
              " -0.03218415006995201,\n",
              " 0.023163000121712685,\n",
              " 0.02771715447306633,\n",
              " 0.052906643599271774,\n",
              " 0.016800256446003914,\n",
              " -0.03913522884249687,\n",
              " 0.033840205520391464,\n",
              " -0.00598141411319375,\n",
              " -0.00575261702761054,\n",
              " 0.008018799126148224,\n",
              " 0.03619354963302612,\n",
              " -0.012464003637433052,\n",
              " 0.04811279848217964,\n",
              " 0.015067934058606625,\n",
              " -0.0036825465504080057,\n",
              " 0.020668020471930504,\n",
              " 0.013673360459506512,\n",
              " 0.02824012003839016,\n",
              " 0.031421490013599396,\n",
              " 0.006400875747203827,\n",
              " -0.006395428441464901,\n",
              " 0.02366417460143566,\n",
              " 0.003720679320394993,\n",
              " -0.011221961118280888,\n",
              " 0.0010329923825338483,\n",
              " -0.019415082409977913,\n",
              " -0.021899167448282242,\n",
              " -0.010056184604763985,\n",
              " -0.05852852016687393,\n",
              " 0.005564676597714424,\n",
              " -0.01550373900681734,\n",
              " -0.02549455314874649,\n",
              " 0.02595214731991291,\n",
              " 0.013673360459506512,\n",
              " 0.018194830045104027,\n",
              " -0.01586327701807022,\n",
              " 0.023947447538375854,\n",
              " 0.0013884453801438212,\n",
              " 0.036346081644296646,\n",
              " 0.001024821074679494,\n",
              " -0.0037097842432558537,\n",
              " -0.01591775193810463,\n",
              " -0.009914548136293888,\n",
              " 0.02242213301360607,\n",
              " -0.021463362500071526,\n",
              " 0.009124653413891792,\n",
              " -0.008242148905992508,\n",
              " -0.028218328952789307,\n",
              " -0.0399850457906723,\n",
              " 0.004976340569555759,\n",
              " -0.02346806228160858,\n",
              " 0.06471694260835648,\n",
              " 0.02693270705640316,\n",
              " -0.041118137538433075,\n",
              " 0.05726468935608864,\n",
              " -0.07147190719842911,\n",
              " 0.00023305317154154181,\n",
              " -0.00986007321625948,\n",
              " -0.012300577014684677,\n",
              " 0.009805597364902496,\n",
              " -0.037522751837968826,\n",
              " 0.01258384995162487,\n",
              " -0.007348750252276659,\n",
              " 0.06789831072092056,\n",
              " -0.0052650608122348785,\n",
              " -0.010649967938661575,\n",
              " -0.02529844082891941,\n",
              " -0.04377654567360878,\n",
              " -0.020275795832276344,\n",
              " 0.05983593314886093,\n",
              " -0.033121127635240555,\n",
              " -0.006618778221309185,\n",
              " -0.013499039225280285,\n",
              " -0.0037261268589645624,\n",
              " 0.04146678000688553,\n",
              " -0.04942021146416664,\n",
              " -0.002561712171882391,\n",
              " -0.024470413103699684,\n",
              " 0.015383892692625523,\n",
              " -0.02745567262172699,\n",
              " 0.02103845402598381,\n",
              " -0.020134160295128822,\n",
              " 0.03835077956318855,\n",
              " -0.0051533859223127365,\n",
              " 0.022509293630719185,\n",
              " -0.03745738044381142,\n",
              " 0.036651141941547394,\n",
              " 0.012006409466266632,\n",
              " -0.01735590770840645,\n",
              " 0.036999788135290146,\n",
              " 0.011864772997796535,\n",
              " 0.019088229164481163,\n",
              " 0.015035249292850494,\n",
              " 0.014686605893075466,\n",
              " 0.012769066728651524,\n",
              " -0.016102969646453857,\n",
              " -0.000838923326227814,\n",
              " -0.010154240764677525,\n",
              " 0.029002778232097626,\n",
              " 0.0028980986680835485,\n",
              " -0.00793163850903511,\n",
              " 0.02161589451134205,\n",
              " -0.03678188472986221,\n",
              " -0.02148515358567238,\n",
              " -0.039941467344760895,\n",
              " -0.06131766736507416,\n",
              " 0.004595011938363314,\n",
              " -0.07151548564434052,\n",
              " -0.021604999899864197,\n",
              " -0.0334261916577816,\n",
              " -0.0012720038648694754,\n",
              " 0.16761034727096558,\n",
              " 0.03451570123434067,\n",
              " 0.03630249947309494,\n",
              " 0.02182290144264698,\n",
              " -0.030353771522641182,\n",
              " 0.009293527342379093,\n",
              " 0.021866481751203537,\n",
              " 0.048330698162317276,\n",
              " -0.007517624646425247,\n",
              " 0.0031568575650453568,\n",
              " -0.022574663162231445,\n",
              " 0.05164281278848648,\n",
              " -0.02503695897758007,\n",
              " 0.009718436747789383,\n",
              " -0.003895001020282507,\n",
              " -0.012496689334511757,\n",
              " -0.018390942364931107,\n",
              " -0.011085771955549717,\n",
              " 0.04214227944612503,\n",
              " 0.01868510991334915,\n",
              " 0.022618243470788002,\n",
              " 0.0053113652393221855,\n",
              " 0.003451025579124689,\n",
              " -0.023838495835661888,\n",
              " 0.01519867591559887,\n",
              " 0.01044840831309557,\n",
              " 0.00881414208561182,\n",
              " -0.017127109691500664,\n",
              " -0.011516129598021507,\n",
              " 0.0029825358651578426,\n",
              " -0.017508437857031822,\n",
              " -0.012758171185851097,\n",
              " 0.008046037517488003,\n",
              " -0.018630634993314743,\n",
              " -0.011853877454996109,\n",
              " -0.020221320912241936,\n",
              " -0.0008770562126301229,\n",
              " -0.011744926683604717,\n",
              " -0.029395001009106636,\n",
              " 0.001237275660969317,\n",
              " -0.005300470162183046,\n",
              " 0.0011467101285234094,\n",
              " -0.05983593314886093,\n",
              " -0.011548814363777637,\n",
              " -0.007822687737643719,\n",
              " -0.015950437635183334,\n",
              " 0.008312967605888844,\n",
              " 0.016941893845796585,\n",
              " -0.02497158758342266,\n",
              " -0.018499894067645073,\n",
              " -0.0022307734470814466,\n",
              " -0.005959623958915472,\n",
              " -0.0007837668526917696,\n",
              " -0.0005168367060832679,\n",
              " 0.0073814354836940765,\n",
              " 0.004611354321241379,\n",
              " 0.005333155393600464,\n",
              " -0.007708288729190826,\n",
              " -0.013509933836758137,\n",
              " -0.018194830045104027,\n",
              " -0.016680410131812096,\n",
              " 0.03926596790552139,\n",
              " 0.01756291463971138,\n",
              " 0.018260201439261436,\n",
              " -0.0038486968260258436,\n",
              " -0.0008559469133615494,\n",
              " -0.0022893345449119806,\n",
              " 0.02608288824558258,\n",
              " -0.027346720919013023,\n",
              " 0.029569324105978012,\n",
              " -0.021125614643096924,\n",
              " 0.019436873495578766,\n",
              " -0.028523392975330353,\n",
              " 0.02471010573208332,\n",
              " 0.029917966574430466,\n",
              " -0.032598163932561874,\n",
              " 0.0001578939554747194,\n",
              " 0.0012508946238085628,\n",
              " -0.02425250969827175,\n",
              " 0.005774407181888819,\n",
              " -0.02758641354739666,\n",
              " 0.007849925197660923,\n",
              " -0.03255458176136017,\n",
              " 0.004050256218761206,\n",
              " 0.01657145842909813,\n",
              " -0.04355864226818085,\n",
              " 0.04135783016681671,\n",
              " -0.029852595180273056,\n",
              " 0.055216409265995026,\n",
              " 0.0003932453109882772,\n",
              " -0.04090023413300514,\n",
              " 0.02941679209470749,\n",
              " -0.029198888689279556,\n",
              " -0.03460286185145378,\n",
              " 0.01500256359577179,\n",
              " 0.008808694779872894,\n",
              " -0.0058615682646632195,\n",
              " 0.02778252586722374,\n",
              " 0.012148045003414154,\n",
              " 0.003878658404573798,\n",
              " -0.0015947713982313871,\n",
              " 0.021844692528247833,\n",
              " 0.0010554635664448142,\n",
              " -0.015514633618295193,\n",
              " -0.029961546882987022,\n",
              " 0.026823755353689194,\n",
              " -0.03521298989653587,\n",
              " 0.00412924587726593,\n",
              " 0.010094317607581615,\n",
              " 0.030375560745596886,\n",
              " 0.003175924066454172,\n",
              " -0.017345011234283447,\n",
              " 0.008732428774237633,\n",
              " -0.0025739693082869053,\n",
              " -0.018380047753453255,\n",
              " 0.02935142070055008,\n",
              " 0.0013659741962328553,\n",
              " 0.015133305452764034,\n",
              " -0.02405639924108982,\n",
              " 0.000532498408574611,\n",
              " 0.0037506408989429474,\n",
              " -0.01586327701807022,\n",
              " 0.0023833049926906824,\n",
              " 0.015699850395321846,\n",
              " -0.0030724203679710627,\n",
              " -0.030375560745596886,\n",
              " 0.019578509032726288,\n",
              " -0.004058427643030882,\n",
              " 0.01346635352820158,\n",
              " 0.008923093788325787,\n",
              " 0.009647618047893047,\n",
              " 0.007839030586183071,\n",
              " -0.001366655109450221,\n",
              " 0.020155949518084526,\n",
              " -0.007185323629528284,\n",
              " 0.010290429927408695,\n",
              " 0.024078188464045525,\n",
              " 0.03754454106092453,\n",
              " 0.0033257317263633013,\n",
              " -0.026780175045132637,\n",
              " 0.009228156879544258,\n",
              " 0.008623478002846241,\n",
              " 0.0111402478069067,\n",
              " -0.03771886229515076,\n",
              " 0.03750096261501312,\n",
              " -0.017802607268095016,\n",
              " 0.004461546894162893,\n",
              " 0.03118179924786091,\n",
              " -0.010617283172905445,\n",
              " -0.01888122223317623,\n",
              " -0.01809677481651306,\n",
              " 0.012322367168962955,\n",
              " 0.041641101241111755,\n",
              " 0.007871715351939201,\n",
              " -0.029983337968587875,\n",
              " 0.010143345221877098,\n",
              " 0.00683123292401433,\n",
              " -0.003502777311950922,\n",
              " -0.004919141065329313,\n",
              " 0.010639073327183723,\n",
              " 0.012518479488790035,\n",
              " 0.0030588016379624605,\n",
              " 0.004477889277040958,\n",
              " 0.013150395825505257,\n",
              " -0.029133519157767296,\n",
              " 0.0032767036464065313,\n",
              " 0.0025440077297389507,\n",
              " 0.007969771511852741,\n",
              " 0.00937524065375328,\n",
              " -0.008389233611524105,\n",
              " -0.021583208814263344,\n",
              " -0.08014441281557083,\n",
              " -0.047023285180330276,\n",
              " 0.015122409909963608,\n",
              " -0.024993378669023514,\n",
              " 0.0023056771606206894,\n",
              " 0.03577953577041626,\n",
              " -0.014860927127301693,\n",
              " -0.03776244446635246,\n",
              " -0.040464431047439575,\n",
              " 0.03911343961954117,\n",
              " -0.008672505617141724,\n",
              " -0.014141850173473358,\n",
              " -0.021528733894228935,\n",
              " 0.01907733455300331,\n",
              " -0.03296859562397003,\n",
              " 0.012333262711763382,\n",
              " 0.04802563786506653,\n",
              " -0.010225058533251286,\n",
              " 0.003603556891903281,\n",
              " 0.013172185979783535,\n",
              " -0.015841487795114517,\n",
              " -0.04567229375243187,\n",
              " -0.021463362500071526,\n",
              " 0.026627644896507263,\n",
              " 0.04615167900919914,\n",
              " 0.012093570083379745,\n",
              " -0.032271310687065125,\n",
              " -0.0511198453605175,\n",
              " 0.012365947477519512,\n",
              " 0.029329631477594376,\n",
              " -0.001563447993248701,\n",
              " 0.04048622027039528,\n",
              " 0.01958940364420414,\n",
              " -0.03793676570057869,\n",
              " -0.0019243484130129218,\n",
              " -0.04841785877943039,\n",
              " -0.00585067318752408,\n",
              " -0.016691304743289948,\n",
              " 0.0055428859777748585,\n",
              " -0.024274300783872604,\n",
              " -0.005605533253401518,\n",
              " -0.011396283283829689,\n",
              " 0.007577547803521156,\n",
              " 0.03532193973660469,\n",
              " 0.0010411638068035245,\n",
              " 0.024165349081158638,\n",
              " -0.010470198467373848,\n",
              " -0.004249092191457748,\n",
              " 0.015590899623930454,\n",
              " -0.031748343259096146,\n",
              " 0.015471053309738636,\n",
              " 0.03808929771184921,\n",
              " 0.03218415006995201,\n",
              " -0.018042298033833504,\n",
              " -0.021397992968559265,\n",
              " 0.014261696487665176,\n",
              " -0.031813714653253555,\n",
              " -0.022705405950546265,\n",
              " -0.026453321799635887,\n",
              " -0.0006237449124455452,\n",
              " 0.006667806301265955,\n",
              " -0.027368512004613876,\n",
              " -0.014937193132936954,\n",
              " -0.02830549143254757,\n",
              " 0.005371288396418095,\n",
              " 0.02346806228160858,\n",
              " 0.05948729068040848,\n",
              " -0.05151207000017166,\n",
              " -0.0028980986680835485,\n",
              " -0.026845546439290047,\n",
              " 0.039614614099264145,\n",
              " -0.009064730256795883,\n",
              " -0.0018807679880410433,\n",
              " -0.0034401302691549063,\n",
              " -0.016734885051846504,\n",
              " 0.0038732108660042286,\n",
              " -0.02484084665775299,\n",
              " 0.0314650721848011,\n",
              " 0.04501858726143837,\n",
              " -0.004761162213981152,\n",
              " -0.02621362917125225,\n",
              " 0.02529844082891941,\n",
              " -0.03582311421632767,\n",
              " -0.03706515580415726,\n",
              " -0.0216267891228199,\n",
              " 0.007468596566468477,\n",
              " 0.031879086047410965,\n",
              " 0.011951933614909649,\n",
              " 0.01808588020503521,\n",
              " 0.01519867591559887,\n",
              " -0.03270711377263069,\n",
              " 0.017377696931362152,\n",
              " 0.002109565306454897,\n",
              " -0.007032792083919048,\n",
              " -0.04628241807222366,\n",
              " 0.004306291230022907,\n",
              " -0.0038105640560388565,\n",
              " 0.0025780550204217434,\n",
              " 0.023489853367209435,\n",
              " -0.041052766144275665,\n",
              " 0.017257850617170334,\n",
              " -0.013716940768063068,\n",
              " 0.0034619206562638283,\n",
              " 0.018903013318777084,\n",
              " -0.026257209479808807,\n",
              " 0.024230720475316048,\n",
              " -0.010982268489897251,\n",
              " -0.007550309877842665,\n",
              " -0.019676564261317253,\n",
              " -0.033055756241083145,\n",
              " -0.038568682968616486,\n",
              " -0.007866268046200275,\n",
              " 0.01696368306875229,\n",
              " 0.03159581497311592,\n",
              " 0.04100918769836426,\n",
              " -0.04031189903616905,\n",
              " -0.0036553088575601578,\n",
              " 0.024928007274866104,\n",
              " 0.05229651927947998,\n",
              " 0.006803994998335838,\n",
              " -0.021180089563131332,\n",
              " 0.027564622461795807,\n",
              " 0.015536423772573471,\n",
              " 0.01555821392685175,\n",
              " -0.040399059653282166,\n",
              " 0.026104679331183434,\n",
              " -0.0030479065608233213,\n",
              " 0.028327280655503273,\n",
              " -0.015209570527076721,\n",
              " 0.03307754918932915,\n",
              " -0.03608459606766701,\n",
              " 0.029046358540654182,\n",
              " -0.05234009772539139,\n",
              " -0.022509293630719185,\n",
              " -0.019229866564273834,\n",
              " -0.04397265613079071,\n",
              " 0.006123050581663847,\n",
              " -0.02961290441453457,\n",
              " 0.03307754918932915,\n",
              " 0.012267891317605972,\n",
              " -0.023969236761331558,\n",
              " -0.017846187576651573,\n",
              " -0.012823542580008507,\n",
              " -0.023446273058652878,\n",
              " 0.00473392428830266,\n",
              " -0.03861226141452789,\n",
              " 0.011788506992161274,\n",
              " 0.00980015005916357,\n",
              " 0.017900662496685982,\n",
              " 0.004717581905424595,\n",
              " -0.0038269066717475653,\n",
              " 0.0360410176217556,\n",
              " 0.00520786177366972,\n",
              " -0.017650075256824493,\n",
              " -0.00437166215851903,\n",
              " 0.003867763327434659,\n",
              " -0.01676757074892521,\n",
              " 0.028545182198286057,\n",
              " -0.031617604196071625,\n",
              " 0.0035627002362161875,\n",
              " -0.023424481973052025,\n",
              " -0.035692375153303146,\n",
              " -0.0393313392996788,\n",
              " 0.0022157926578074694,\n",
              " -0.011472548358142376,\n",
              " -0.04959453269839287,\n",
              " -0.014534073881804943,\n",
              " -0.01389126293361187,\n",
              " 0.005319536663591862,\n",
              " -0.03872121497988701,\n",
              " -0.04083486646413803,\n",
              " -0.004979064222425222,\n",
              " -0.0070382398553192616,\n",
              " 0.03647682070732117,\n",
              " 0.003756088437512517,\n",
              " -0.02569066546857357,\n",
              " -0.00973477866500616,\n",
              " -0.029830805957317352,\n",
              " 0.05460628122091293,\n",
              " 0.011581500060856342,\n",
              " -0.024470413103699684,\n",
              " -0.024296090006828308,\n",
              " -0.03774065524339676,\n",
              " -0.0008586706826463342,\n",
              " 0.03054988384246826,\n",
              " 0.00111402478069067,\n",
              " -0.004646763671189547,\n",
              " -0.0160593893378973,\n",
              " -0.020428327843546867,\n",
              " -0.01008887030184269,\n",
              " -0.006896603386849165,\n",
              " 0.008884960785508156,\n",
              " -0.021931853145360947,\n",
              " 0.017061738297343254,\n",
              " 0.005959623958915472,\n",
              " 0.024753686040639877,\n",
              " 0.0065425122156739235,\n",
              " 0.03789318725466728,\n",
              " 0.024949796497821808,\n",
              " -0.005670903716236353,\n",
              " 0.09430805593729019,\n",
              " 0.0017241508467122912,\n",
              " 0.0058179874904453754,\n",
              " 0.0051506622694432735,\n",
              " 0.014512283727526665,\n",
              " -0.01742127723991871,\n",
              " -0.03172655403614044,\n",
              " -0.013444563373923302,\n",
              " 0.01972014643251896,\n",
              " 0.004883732181042433,\n",
              " 0.025647085160017014,\n",
              " 0.006564302369952202,\n",
              " 0.01986178196966648,\n",
              " 0.02089681662619114,\n",
              " 0.009462401270866394,\n",
              " -0.016168341040611267,\n",
              " -0.007844477891921997,\n",
              " -0.02771715447306633,\n",
              " -0.005867015570402145,\n",
              " -0.022051699459552765,\n",
              " 0.005774407181888819,\n",
              " 0.06510916352272034,\n",
              " 0.04837428033351898,\n",
              " 0.020090579986572266,\n",
              " 0.029896177351474762,\n",
              " -0.018630634993314743,\n",
              " -0.003867763327434659,\n",
              " 0.02824012003839016,\n",
              " -0.0014218116411939263,\n",
              " 0.007779106963425875,\n",
              " -0.008481841534376144,\n",
              " 0.0027115200646221638,\n",
              " 1.5246767361531965e-05,\n",
              " 0.00515883369371295,\n",
              " 0.006144840735942125,\n",
              " -0.043929073959589005,\n",
              " -0.007076372858136892,\n",
              " -0.022127963602542877,\n",
              " -0.02771715447306633,\n",
              " 0.019883573055267334,\n",
              " -0.004663106054067612,\n",
              " -0.0034319590777158737,\n",
              " 0.019360607489943504,\n",
              " 0.04238197207450867,\n",
              " -0.02464473433792591,\n",
              " 0.004791123792529106,\n",
              " 0.01137449312955141,\n",
              " 0.027412092313170433,\n",
              " 0.021648580208420753,\n",
              " -0.031203588470816612,\n",
              " -0.01104763988405466,\n",
              " 0.04068233445286751,\n",
              " 0.008884960785508156,\n",
              " 0.0044206902384757996,\n",
              " -0.03702157735824585,\n",
              " -0.0031704765278846025,\n",
              " -0.003780602477490902,\n",
              " 0.030484512448310852,\n",
              " -0.014632130041718483,\n",
              " 0.0014190878719091415,\n",
              " -0.03320828825235367,\n",
              " 0.0005641623283736408,\n",
              " 0.013749626465141773,\n",
              " -0.030310191214084625,\n",
              " -0.0353873111307621,\n",
              " -0.06480409950017929,\n",
              " 0.04029010981321335,\n",
              " -0.025864986702799797,\n",
              " 0.021071139723062515,\n",
              " -0.0012427233159542084,\n",
              " -0.0019447767408564687,\n",
              " -0.02221512608230114,\n",
              " 0.03532193973660469,\n",
              " 0.004379833582788706,\n",
              " -0.04549797251820564,\n",
              " 0.021397992968559265,\n",
              " -0.06833411753177643,\n",
              " 0.019959837198257446,\n",
              " 0.033513352274894714,\n",
              " -0.03715232014656067,\n",
              " -0.013651570305228233,\n",
              " 0.01228968147188425,\n",
              " 0.019818201661109924,\n",
              " 0.000984645332209766,\n",
              " 0.02739030122756958,\n",
              " -0.005932386498898268,\n",
              " -0.007348750252276659,\n",
              " -0.00019985713879577816,\n",
              " 0.03523477911949158,\n",
              " -0.02272719517350197,\n",
              " 0.025777826085686684,\n",
              " -0.01421811617910862,\n",
              " 0.03261995315551758,\n",
              " -0.01965477503836155,\n",
              " -0.009075624868273735,\n",
              " -0.040399059653282166,\n",
              " 0.010600940324366093,\n",
              " -0.030375560745596886,\n",
              " -0.03702157735824585,\n",
              " -0.0031623051036149263,\n",
              " 0.023163000121712685,\n",
              " -0.07291006296873093,\n",
              " 0.018521683290600777,\n",
              " -0.012834437191486359,\n",
              " 0.01885943114757538,\n",
              " -0.010001708753407001,\n",
              " 0.03314291685819626,\n",
              " -0.037784233689308167,\n",
              " 0.01697457768023014,\n",
              " 0.010377590544521809,\n",
              " 0.006646015681326389,\n",
              " 0.01723606139421463,\n",
              " 0.027956847101449966,\n",
              " 0.031247170642018318,\n",
              " 0.003282151184976101,\n",
              " 0.022945096716284752,\n",
              " 0.04005041718482971,\n",
              " 0.024470413103699684,\n",
              " 0.012126254849135876,\n",
              " -0.005954176653176546,\n",
              " -0.00897212140262127,\n",
              " 0.022966887801885605,\n",
              " 0.0035763191990554333,\n",
              " 0.013117710128426552,\n",
              " 0.016266396269202232,\n",
              " 0.016157444566488266,\n",
              " 0.0007006916566751897,\n",
              " 0.019709249958395958,\n",
              " 0.028065798804163933,\n",
              " 0.013183080591261387,\n",
              " 0.019055543467402458,\n",
              " 0.024165349081158638,\n",
              " 0.029046358540654182,\n",
              " 0.005384907126426697,\n",
              " -0.016560563817620277,\n",
              " 0.006956526543945074,\n",
              " -0.008732428774237633,\n",
              " 0.03007049858570099,\n",
              " 0.007582995109260082,\n",
              " -0.02575603500008583,\n",
              " -0.02274898625910282,\n",
              " 0.003666203934699297,\n",
              " 0.02490621618926525,\n",
              " -0.011156590655446053,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 텍스트를 임베딩하여 쿼리 결과를 생성합니다.\n",
        "query_result = cached_embeding.embed_query(\"임베딩 테스트를 하기 위한 샘플 문장입니다.\")\n",
        "query_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzOZFgld3zCe"
      },
      "source": [
        "## 08-060 1024차원 임베딩 생성 및 길이 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXhq5tc_3zCf",
        "outputId": "4765cf4a-2d6d-4b68-99ed-46eaba80f7e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# OpenAI의 \"text-embedding-3-small\" 모델을 사용하여 1024차원의 임베딩을 생성하는 객체를 초기화합니다.\n",
        "embeddings_1024 = OpenAIEmbeddings(model=\"text-embedding-3-small\", dimensions=1024)\n",
        "# 주어진 텍스트를 임베딩하고 첫 번째 임베딩 벡터의 길이를 반환합니다.\n",
        "len(embeddings_1024.embed_documents(['AI Essential'])[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT7sYJ4K3zCf"
      },
      "source": [
        "## 08-061 임베딩 대상 텍스트 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOX9n0Z83zCf"
      },
      "outputs": [],
      "source": [
        "# 임베딩 대상 텍스트\n",
        "sentence1 = \"안녕하세요? 반갑습니다.\"\n",
        "sentence2 = \"안녕하세요? 반갑습니다!\"\n",
        "sentence3 = \"안녕하세요? 만나서 반가워요.\"\n",
        "sentence4 = \"Hi, nice to meet you.\"\n",
        "sentence5 = \"I like to eat apples.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2uLg3b03zCf"
      },
      "source": [
        "## 08-062 임베딩 수행\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_G832DU3zCf"
      },
      "outputs": [],
      "source": [
        "# 임베딩 수행\n",
        "sentences = [sentence1, sentence2, sentence3, sentence4, sentence5]\n",
        "embedded_sentences = embeddings_1024.embed_documents(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PLZ9SA-3zCf"
      },
      "source": [
        "## 08-063 코사인 유사도 계산 함수 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rB_Qr8QK3zCf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def similarity(a, b):\n",
        "    return cosine_similarity([a], [b])[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWTZe1e23zCf"
      },
      "source": [
        "## 08-064 유사도 계산 및 결과 출력\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtHvxlUh3zCf",
        "outputId": "83b09149-b7f5-449a-b92b-5cdc6248ac62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[유사도 0.9644] 안녕하세요? 반갑습니다. \t <=====> \t 안녕하세요? 반갑습니다!\n",
            "[유사도 0.8376] 안녕하세요? 반갑습니다. \t <=====> \t 안녕하세요? 만나서 반가워요.\n",
            "[유사도 0.5042] 안녕하세요? 반갑습니다. \t <=====> \t Hi, nice to meet you.\n",
            "[유사도 0.1362] 안녕하세요? 반갑습니다. \t <=====> \t I like to eat apples.\n",
            "[유사도 0.8142] 안녕하세요? 반갑습니다! \t <=====> \t 안녕하세요? 만나서 반가워요.\n",
            "[유사도 0.4790] 안녕하세요? 반갑습니다! \t <=====> \t Hi, nice to meet you.\n",
            "[유사도 0.1318] 안녕하세요? 반갑습니다! \t <=====> \t I like to eat apples.\n",
            "[유사도 0.5128] 안녕하세요? 만나서 반가워요. \t <=====> \t Hi, nice to meet you.\n",
            "[유사도 0.1409] 안녕하세요? 만나서 반가워요. \t <=====> \t I like to eat apples.\n",
            "[유사도 0.2249] Hi, nice to meet you. \t <=====> \t I like to eat apples.\n"
          ]
        }
      ],
      "source": [
        "# 유사도 계산\n",
        "for i, sentence in enumerate(embedded_sentences):\n",
        "    for j, other_sentence in enumerate(embedded_sentences):\n",
        "        if i < j:\n",
        "            print(\n",
        "                f\"[유사도 {similarity(sentence, other_sentence):.4f}] {sentences[i]} \\t <=====> \\t {sentences[j]}\"\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwe4PL803zCf"
      },
      "source": [
        "## 08-065 JAEN에서 키워드 파일 다운로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8hSChgG3zCg",
        "outputId": "8add3f2a-8af8-414e-a00b-dbc4d33715d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파일이 성공적으로 다운로드되었습니다: nlp-keywords.txt\n",
            "절대 경로: /content/nlp-keywords.txt\n",
            "상대 경로: nlp-keywords.txt\n",
            "파일이 성공적으로 다운로드되었습니다: finance-keywords.txt\n",
            "절대 경로: /content/finance-keywords.txt\n",
            "상대 경로: finance-keywords.txt\n"
          ]
        }
      ],
      "source": [
        "from JAEN import download_file\n",
        "\n",
        "download_file('nlp-keywords') # nlp-keywords.txt\n",
        "download_file('finance-keywords') # finance-keywords.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oYfcubX3zCg"
      },
      "source": [
        "## 08-066 텍스트 파일 로드 및 문서 분할\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JFZKTbO3zCg",
        "outputId": "da8bf0af-4914-4fad-a38c-8e44ea5cee00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11, 6)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# 텍스트 분할\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=0)\n",
        "\n",
        "# 텍스트 파일을 load -> List[Document] 형태로 변환\n",
        "loader1 = TextLoader(\"./nlp-keywords.txt\", encoding='utf-8')\n",
        "loader2 = TextLoader(\"./finance-keywords.txt\", encoding='utf-8')\n",
        "\n",
        "# 문서 분할\n",
        "split_doc1 = loader1.load_and_split(text_splitter)\n",
        "split_doc2 = loader2.load_and_split(text_splitter)\n",
        "\n",
        "# 문서 개수 확인\n",
        "len(split_doc1), len(split_doc2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Virml3983zCg"
      },
      "source": [
        "## 08-067 FAISS 벡터 스토어 및 임베딩 차원 크기 계산\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3O3nnNc3zCg",
        "outputId": "f67aea9d-dcde-4dac-b309-12617f09d3f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1536\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# 임베딩\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# 임베딩 차원 크기를 계산\n",
        "dimension_size = len(embeddings.embed_query(\"hello world\"))\n",
        "print(dimension_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vUBqqps3zCg"
      },
      "source": [
        "## 08-068 FAISS 벡터 스토어 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24Bu8fHt3zCg"
      },
      "outputs": [],
      "source": [
        "# DB 생성\n",
        "db = FAISS.from_documents(documents=split_doc1,\n",
        "                          embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYVnZ60x3zCg"
      },
      "source": [
        "## 08-069 FAISS DB 문서 저장소 ID 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qS3z_2hR3zCg",
        "outputId": "76c9fc67-fb6c-4305-c4a2-4edecdcc7649"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'b8209329-902a-4877-b426-8f3542b9ff09',\n",
              " 1: 'e50c6ac3-f1e4-4993-9b6c-097ce4f210b7',\n",
              " 2: '17191748-c607-437a-8704-288e370ec3ef',\n",
              " 3: '578d0004-99eb-4408-b7d7-c57c9bd126e4',\n",
              " 4: 'd94605ea-c8bd-475d-9171-a9e19d4864d6',\n",
              " 5: '3ef712f7-01b3-40d6-bec3-6a868c5b12a9',\n",
              " 6: '66dd291f-5f09-426e-9c46-53fc16da5fca',\n",
              " 7: '2dfb06ce-e758-42f1-92a2-ebb5b2666ffc',\n",
              " 8: 'e39027c2-eb66-4557-900f-4b91160b88db',\n",
              " 9: '1fe8ccfc-c75e-42dd-85bb-f8bf3f111443',\n",
              " 10: '67e15eb4-0cde-4890-988f-01b0dd673efc'}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 문서 저장소 ID 확인\n",
        "db.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJGCL8-L3zCg"
      },
      "source": [
        "## 08-070 FAISS DB에서 저장된 문서 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_4b2EAf3zCg",
        "outputId": "e6c0dbd9-cbfb-4525-b40b-a8b49ebaf46c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'b8209329-902a-4877-b426-8f3542b9ff09': Document(metadata={'source': './nlp-keywords.txt'}, page_content='Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer'),\n",
              " 'e50c6ac3-f1e4-4993-9b6c-097ce4f210b7': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\\n예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nVectorStore\\n\\n정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\\n예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\\n연관키워드: 임베딩, 데이터베이스, 벡터화\\n\\nSQL\\n\\n정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\\n예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리\\n\\nCSV'),\n",
              " '17191748-c607-437a-8704-288e370ec3ef': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: CSV(Comma-Separated Values)는 데이터를 저장하는 파일 형식으로, 각 데이터 값은 쉼표로 구분됩니다. 표 형태의 데이터를 간단하게 저장하고 교환할 때 사용됩니다.\\n예시: 이름, 나이, 직업이라는 헤더를 가진 CSV 파일에는 홍길동, 30, 개발자와 같은 데이터가 포함될 수 있습니다.\\n연관키워드: 데이터 형식, 파일 처리, 데이터 교환\\n\\nJSON\\n\\n정의: JSON(JavaScript Object Notation)은 경량의 데이터 교환 형식으로, 사람과 기계 모두에게 읽기 쉬운 텍스트를 사용하여 데이터 객체를 표현합니다.\\n예시: {\"이름\": \"홍길동\", \"나이\": 30, \"직업\": \"개발자\"}는 JSON 형식의 데이터입니다.\\n연관키워드: 데이터 교환, 웹 개발, API\\n\\nTransformer\\n\\n정의: 트랜스포머는 자연어 처리에서 사용되는 딥러닝 모델의 한 유형으로, 주로 번역, 요약, 텍스트 생성 등에 사용됩니다. 이는 Attention 메커니즘을 기반으로 합니다.\\n예시: 구글 번역기는 트랜스포머 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.\\n연관키워드: 딥러닝, 자연어 처리, Attention\\n\\nHuggingFace'),\n",
              " '578d0004-99eb-4408-b7d7-c57c9bd126e4': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\\n예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\\n연관키워드: 자연어 처리, 딥러닝, 라이브러리\\n\\nDigital Transformation\\n\\n정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\\n예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\\n연관키워드: 혁신, 기술, 비즈니스 모델\\n\\nCrawling\\n\\n정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\\n예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\\n\\nWord2Vec'),\n",
              " 'd94605ea-c8bd-475d-9171-a9e19d4864d6': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source'),\n",
              " '3ef712f7-01b3-40d6-bec3-6a868c5b12a9': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\\n예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\\n\\nStructured Data\\n\\n정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\\n예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\\n\\nParser\\n\\n정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\\n예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)'),\n",
              " '66dd291f-5f09-426e-9c46-53fc16da5fca': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'),\n",
              " '2dfb06ce-e758-42f1-92a2-ebb5b2666ffc': Document(metadata={'source': './nlp-keywords.txt'}, page_content=\"정의: DataFrame은 행과 열로 이루어진 테이블 형태의 데이터 구조로, 주로 데이터 분석 및 처리에 사용됩니다.\\n예시: 판다스 라이브러리에서 DataFrame은 다양한 데이터 타입의 열을 가질 수 있으며, 데이터 조작과 분석을 용이하게 합니다.\\n연관키워드: 데이터 분석, 판다스, 데이터 처리\\n\\nAttention 메커니즘\\n\\n정의: Attention 메커니즘은 딥러닝에서 중요한 정보에 더 많은 '주의'를 기울이도록 하는 기법입니다. 이는 주로 시퀀스 데이터(예: 텍스트, 시계열 데이터)에서 사용됩니다.\\n예시: 번역 모델에서 Attention 메커니즘은 입력 문장의 중요한 부분에 더 집중하여 정확한 번역을 생성합니다.\\n연관키워드: 딥러닝, 자연어 처리, 시퀀스 모델링\\n\\n판다스 (Pandas)\\n\\n정의: 판다스는 파이썬 프로그래밍 언어를 위한 데이터 분석 및 조작 도구를 제공하는 라이브러리입니다. 이는 데이터 분석 작업을 효율적으로 수행할 수 있게 합니다.\\n예시: 판다스를 사용하여 CSV 파일을 읽고, 데이터를 정제하며, 다양한 분석을 수행할 수 있습니다.\\n연관키워드: 데이터 분석, 파이썬, 데이터 처리\"),\n",
              " 'e39027c2-eb66-4557-900f-4b91160b88db': Document(metadata={'source': './nlp-keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nInstructGPT\\n\\n정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\\n예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\\n연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\\n\\nKeyword Search'),\n",
              " '1fe8ccfc-c75e-42dd-85bb-f8bf3f111443': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 키워드 검색은 사용자가 입력한 키워드를 기반으로 정보를 찾는 과정입니다. 이는 대부분의 검색 엔진과 데이터베이스 시스템에서 기본적인 검색 방식으로 사용됩니다.\\n예시: 사용자가 \"커피숍 서울\"이라고 검색하면, 관련된 커피숍 목록을 반환합니다.\\n연관키워드: 검색 엔진, 데이터 검색, 정보 검색\\n\\nPage Rank\\n\\n정의: 페이지 랭크는 웹 페이지의 중요도를 평가하는 알고리즘으로, 주로 검색 엔진 결과의 순위를 결정하는 데 사용됩니다. 이는 웹 페이지 간의 링크 구조를 분석하여 평가합니다.\\n예시: 구글 검색 엔진은 페이지 랭크 알고리즘을 사용하여 검색 결과의 순위를 정합니다.\\n연관키워드: 검색 엔진 최적화, 웹 분석, 링크 분석\\n\\n데이터 마이닝\\n\\n정의: 데이터 마이닝은 대량의 데이터에서 유용한 정보를 발굴하는 과정입니다. 이는 통계, 머신러닝, 패턴 인식 등의 기술을 활용합니다.\\n예시: 소매업체가 고객 구매 데이터를 분석하여 판매 전략을 수립하는 것은 데이터 마이닝의 예입니다.\\n연관키워드: 빅데이터, 패턴 인식, 예측 분석\\n\\n멀티모달 (Multimodal)'),\n",
              " '67e15eb4-0cde-4890-988f-01b0dd673efc': Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 멀티모달은 여러 종류의 데이터 모드(예: 텍스트, 이미지, 소리 등)를 결합하여 처리하는 기술입니다. 이는 서로 다른 형식의 데이터 간의 상호 작용을 통해 보다 풍부하고 정확한 정보를 추출하거나 예측하는 데 사용됩니다.\\n예시: 이미지와 설명 텍스트를 함께 분석하여 더 정확한 이미지 분류를 수행하는 시스템은 멀티모달 기술의 예입니다.\\n연관키워드: 데이터 융합, 인공지능, 딥러닝')}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 저장된 문서의 ID: Document 확인\n",
        "db.docstore._dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtUcSky63zCh"
      },
      "source": [
        "## 08-071 FAISS DB 생성 - 문자열 리스트로\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx3ZhhUN3zCh"
      },
      "outputs": [],
      "source": [
        "# 문자열 리스트로 생성\n",
        "db2 = FAISS.from_texts(\n",
        "    [\"안녕하세요. 정말 반갑습니다.\", \"AI Essential 과정입니다\"],\n",
        "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
        "    metadatas=[{\"source\": \"텍스트문서\"}, {\"source\": \"텍스트문서\"}],\n",
        "    ids=[\"doc1\", \"doc2\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIyObM7p3zCh"
      },
      "source": [
        "## 08-072 FAISS DB에서 저장된 내용 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f97Cdvke3zCh",
        "outputId": "5f1fb1c4-46fe-418e-a17c-eaf85bf8322f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'doc1': Document(metadata={'source': '텍스트문서'}, page_content='안녕하세요. 정말 반갑습니다.'),\n",
              " 'doc2': Document(metadata={'source': '텍스트문서'}, page_content='AI Essential 과정입니다')}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 저장된 내용\n",
        "db2.docstore._dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5o5zH4g3zCh"
      },
      "source": [
        "## 08-073 FAISS DB에서 유사도 검색\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5QmTCHz3zCh",
        "outputId": "bcb181dc-bcd9-40df-babf-94e9cfdb6a19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\\n예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\\n\\nStructured Data\\n\\n정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\\n예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\\n\\nParser\\n\\n정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\\n예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nInstructGPT\\n\\n정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\\n예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\\n연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\\n\\nKeyword Search')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 유사도 검색\n",
        "db.similarity_search(\"TF IDF 에 대하여 알려줘\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOeb5Pzb3zCh"
      },
      "source": [
        "## 08-074 FAISS DB에서 k 값 지정하여 유사도 검색\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92tumOb73zCh",
        "outputId": "0e05c55a-4f63-44a7-dc07-e75e716f4f6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 오픈 소스는 소스 코드가 공개되어 누구나 자유롭게 사용, 수정, 배포할 수 있는 소프트웨어를 의미합니다. 이는 협업과 혁신을 촉진하는 데 중요한 역할을 합니다.\\n예시: 리눅스 운영 체제는 대표적인 오픈 소스 프로젝트입니다.\\n연관키워드: 소프트웨어 개발, 커뮤니티, 기술 협업\\n\\nStructured Data\\n\\n정의: 구조화된 데이터는 정해진 형식이나 스키마에 따라 조직된 데이터입니다. 이는 데이터베이스, 스프레드시트 등에서 쉽게 검색하고 분석할 수 있습니다.\\n예시: 관계형 데이터베이스에 저장된 고객 정보 테이블은 구조화된 데이터의 예입니다.\\n연관키워드: 데이터베이스, 데이터 분석, 데이터 모델링\\n\\nParser\\n\\n정의: 파서는 주어진 데이터(문자열, 파일 등)를 분석하여 구조화된 형태로 변환하는 도구입니다. 이는 프로그래밍 언어의 구문 분석이나 파일 데이터 처리에 사용됩니다.\\n예시: HTML 문서를 구문 분석하여 웹 페이지의 DOM 구조를 생성하는 것은 파싱의 한 예입니다.\\n연관키워드: 구문 분석, 컴파일러, 데이터 처리\\n\\nTF-IDF (Term Frequency-Inverse Document Frequency)')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# k 값 지정\n",
        "db.similarity_search(\"TF IDF 에 대하여 알려줘\", k=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_b0pOKd3zCh"
      },
      "source": [
        "## 08-075 FAISS DB에 문서 추가\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkT8aCAa3zCh",
        "outputId": "d82f61fb-0729-4663-c2a2-db39e3346143"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['new_doc1']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "# page_content, metadata 지정\n",
        "db.add_documents(\n",
        "    [\n",
        "        Document(\n",
        "            page_content=\"안녕하세요! 이번엔 도큐먼트를 새로 추가해 볼께요\",\n",
        "            metadata={\"source\": \"mydata.txt\"},\n",
        "        )\n",
        "    ],\n",
        "    ids=[\"new_doc1\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cui96trR3zCh"
      },
      "source": [
        "## 08-076 FAISS DB에서 추가된 데이터 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0kUe8Sv3zCh",
        "outputId": "9c5c1751-10a4-489f-ed3b-1c42aede16e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'mydata.txt'}, page_content='안녕하세요! 이번엔 도큐먼트를 새로 추가해 볼께요')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 추가된 데이터를 확인\n",
        "db.similarity_search(\"안녕하세요\", k=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J9g31Ik3zCi"
      },
      "source": [
        "## 08-077 FAISS DB에 텍스트 데이터 추가\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1vgB2jG3zCi",
        "outputId": "913997ef-1747-4987-e093-a8440f25fe84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['new_doc2', 'new_doc3']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 신규 데이터를 추가\n",
        "db.add_texts(\n",
        "    [\"이번엔 텍스트 데이터를 추가합니다.\", \"추가한 2번째 텍스트 데이터 입니다.\"],\n",
        "    metadatas=[{\"source\": \"mydata.txt\"}, {\"source\": \"mydata.txt\"}],\n",
        "    ids=[\"new_doc2\", \"new_doc3\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdAwxoVC3zCi"
      },
      "source": [
        "## 08-078 FAISS DB에서 추가된 데이터의 ID 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvYVrJ6r3zCi",
        "outputId": "b4cd72df-80d2-4d68-dd8e-46705ce821e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'b8209329-902a-4877-b426-8f3542b9ff09',\n",
              " 1: 'e50c6ac3-f1e4-4993-9b6c-097ce4f210b7',\n",
              " 2: '17191748-c607-437a-8704-288e370ec3ef',\n",
              " 3: '578d0004-99eb-4408-b7d7-c57c9bd126e4',\n",
              " 4: 'd94605ea-c8bd-475d-9171-a9e19d4864d6',\n",
              " 5: '3ef712f7-01b3-40d6-bec3-6a868c5b12a9',\n",
              " 6: '66dd291f-5f09-426e-9c46-53fc16da5fca',\n",
              " 7: '2dfb06ce-e758-42f1-92a2-ebb5b2666ffc',\n",
              " 8: 'e39027c2-eb66-4557-900f-4b91160b88db',\n",
              " 9: '1fe8ccfc-c75e-42dd-85bb-f8bf3f111443',\n",
              " 10: '67e15eb4-0cde-4890-988f-01b0dd673efc',\n",
              " 11: 'new_doc1',\n",
              " 12: 'new_doc2',\n",
              " 13: 'new_doc3'}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 추가된 데이터를 확인\n",
        "db.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK1UQC6t3zCi"
      },
      "source": [
        "## 08-079 FAISS DB에 삭제용 데이터 추가\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9k2jak133zCi"
      },
      "outputs": [],
      "source": [
        "# 삭제용 데이터를 추가\n",
        "ids = db.add_texts(\n",
        "    [\"삭제용 데이터를 추가합니다.\", \"2번째 삭제용 데이터입니다.\"],\n",
        "    metadatas=[{\"source\": \"mydata.txt\"}, {\"source\": \"mydata.txt\"}],\n",
        "    ids=[\"delete_doc1\", \"delete_doc2\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pgSKYV-3zCi"
      },
      "source": [
        "## 08-080 FAISS DB에서 삭제할 ID 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4qyns6_3zCi",
        "outputId": "82ab9567-8908-47cf-a5f6-315940879d93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['delete_doc1', 'delete_doc2']\n"
          ]
        }
      ],
      "source": [
        "# 삭제할 id 를 확인\n",
        "print(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faVWfgfQ3zCi"
      },
      "source": [
        "## 08-081 FAISS DB에서 ID로 데이터 삭제\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxvCSh3R3zCi",
        "outputId": "c4f03cf0-2845-4313-fe2e-026231545c19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# id 로 삭제\n",
        "db.delete(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDatjz3K3zCi"
      },
      "source": [
        "## 08-082 FAISS DB에서 삭제된 결과 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFI7G96b3zCi",
        "outputId": "98fefe56-ac7f-423a-cb43-929f988f6618"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'b8209329-902a-4877-b426-8f3542b9ff09',\n",
              " 1: 'e50c6ac3-f1e4-4993-9b6c-097ce4f210b7',\n",
              " 2: '17191748-c607-437a-8704-288e370ec3ef',\n",
              " 3: '578d0004-99eb-4408-b7d7-c57c9bd126e4',\n",
              " 4: 'd94605ea-c8bd-475d-9171-a9e19d4864d6',\n",
              " 5: '3ef712f7-01b3-40d6-bec3-6a868c5b12a9',\n",
              " 6: '66dd291f-5f09-426e-9c46-53fc16da5fca',\n",
              " 7: '2dfb06ce-e758-42f1-92a2-ebb5b2666ffc',\n",
              " 8: 'e39027c2-eb66-4557-900f-4b91160b88db',\n",
              " 9: '1fe8ccfc-c75e-42dd-85bb-f8bf3f111443',\n",
              " 10: '67e15eb4-0cde-4890-988f-01b0dd673efc',\n",
              " 11: 'new_doc1',\n",
              " 12: 'new_doc2',\n",
              " 13: 'new_doc3'}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 삭제된 결과를 출력\n",
        "db.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfFlAdKu3zCj"
      },
      "source": [
        "## 08-083 FAISS DB를 로컬 Disk에 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqqD13w_3zCj"
      },
      "outputs": [],
      "source": [
        "# 로컬 Disk 에 저장\n",
        "db.save_local(folder_path=\"faiss_db\", index_name=\"faiss_index\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4g9-LRe3zCj"
      },
      "source": [
        "## 08-084 로컬 Disk에서 FAISS DB 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZrUU0uw3zCj"
      },
      "outputs": [],
      "source": [
        "# 저장된 데이터를 로드\n",
        "loaded_db = FAISS.load_local(\n",
        "    folder_path=\"faiss_db\",\n",
        "    index_name=\"faiss_index\",\n",
        "    embeddings=embeddings,\n",
        "    allow_dangerous_deserialization=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLimft3U3zCj"
      },
      "source": [
        "## 08-085 로드된 FAISS DB에서 데이터 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oae2OPaw3zCj",
        "outputId": "6e0f83c5-132f-44b0-c9eb-0935b3c4e034"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'b8209329-902a-4877-b426-8f3542b9ff09',\n",
              " 1: 'e50c6ac3-f1e4-4993-9b6c-097ce4f210b7',\n",
              " 2: '17191748-c607-437a-8704-288e370ec3ef',\n",
              " 3: '578d0004-99eb-4408-b7d7-c57c9bd126e4',\n",
              " 4: 'd94605ea-c8bd-475d-9171-a9e19d4864d6',\n",
              " 5: '3ef712f7-01b3-40d6-bec3-6a868c5b12a9',\n",
              " 6: '66dd291f-5f09-426e-9c46-53fc16da5fca',\n",
              " 7: '2dfb06ce-e758-42f1-92a2-ebb5b2666ffc',\n",
              " 8: 'e39027c2-eb66-4557-900f-4b91160b88db',\n",
              " 9: '1fe8ccfc-c75e-42dd-85bb-f8bf3f111443',\n",
              " 10: '67e15eb4-0cde-4890-988f-01b0dd673efc',\n",
              " 11: 'new_doc1',\n",
              " 12: 'new_doc2',\n",
              " 13: 'new_doc3'}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 로드된 데이터를 확인\n",
        "loaded_db.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48jW19dE3zCj"
      },
      "source": [
        "## 08-086 새로운 FAISS 벡터 저장소 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPpAm2Zh3zCj"
      },
      "outputs": [],
      "source": [
        "# 새로운 FAISS 벡터 저장소 생성\n",
        "db = FAISS.from_documents(\n",
        "    documents=split_doc1 + split_doc2, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Clb7iEnF3zCj"
      },
      "source": [
        "## 08-087 FAISS DB를 검색기로 변환 및 검색 수행\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dOehT_F3zCj",
        "outputId": "675bac15-2d64-4564-91bf-14b0b8d58d51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: HuggingFace는 자연어 처리를 위한 다양한 사전 훈련된 모델과 도구를 제공하는 라이브러리입니다. 이는 연구자와 개발자들이 쉽게 NLP 작업을 수행할 수 있도록 돕습니다.\\n예시: HuggingFace의 Transformers 라이브러리를 사용하여 감정 분석, 텍스트 생성 등의 작업을 수행할 수 있습니다.\\n연관키워드: 자연어 처리, 딥러닝, 라이브러리\\n\\nDigital Transformation\\n\\n정의: 디지털 변환은 기술을 활용하여 기업의 서비스, 문화, 운영을 혁신하는 과정입니다. 이는 비즈니스 모델을 개선하고 디지털 기술을 통해 경쟁력을 높이는 데 중점을 둡니다.\\n예시: 기업이 클라우드 컴퓨팅을 도입하여 데이터 저장과 처리를 혁신하는 것은 디지털 변환의 예입니다.\\n연관키워드: 혁신, 기술, 비즈니스 모델\\n\\nCrawling\\n\\n정의: 크롤링은 자동화된 방식으로 웹 페이지를 방문하여 데이터를 수집하는 과정입니다. 이는 검색 엔진 최적화나 데이터 분석에 자주 사용됩니다.\\n예시: 구글 검색 엔진이 인터넷 상의 웹사이트를 방문하여 콘텐츠를 수집하고 인덱싱하는 것이 크롤링입니다.\\n연관키워드: 데이터 수집, 웹 스크래핑, 검색 엔진\\n\\nWord2Vec'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 검색기로 변환\n",
        "retriever = db.as_retriever()\n",
        "# 검색 수행\n",
        "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSIeK-Mw3zCj"
      },
      "source": [
        "## 08-088 FAISS DB에서 MMR 검색 수행\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVp9Cn1M3zCj",
        "outputId": "49ef276e-5be6-407d-877b-8c4d4d887a93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 토크나이저는 텍스트 데이터를 토큰으로 분할하는 도구입니다. 이는 자연어 처리에서 데이터를 전처리하는 데 사용됩니다.\\n예시: \"I love programming.\"이라는 문장을 [\"I\", \"love\", \"programming\", \".\"]으로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nVectorStore\\n\\n정의: 벡터스토어는 벡터 형식으로 변환된 데이터를 저장하는 시스템입니다. 이는 검색, 분류 및 기타 데이터 분석 작업에 사용됩니다.\\n예시: 단어 임베딩 벡터들을 데이터베이스에 저장하여 빠르게 접근할 수 있습니다.\\n연관키워드: 임베딩, 데이터베이스, 벡터화\\n\\nSQL\\n\\n정의: SQL(Structured Query Language)은 데이터베이스에서 데이터를 관리하기 위한 프로그래밍 언어입니다. 데이터 조회, 수정, 삽입, 삭제 등 다양한 작업을 수행할 수 있습니다.\\n예시: SELECT * FROM users WHERE age > 18;은 18세 이상의 사용자 정보를 조회합니다.\\n연관키워드: 데이터베이스, 쿼리, 데이터 관리\\n\\nCSV'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='GPT (Generative Pretrained Transformer)\\n\\n정의: GPT는 대규모의 데이터셋으로 사전 훈련된 생성적 언어 모델로, 다양한 텍스트 기반 작업에 활용됩니다. 이는 입력된 텍스트에 기반하여 자연스러운 언어를 생성할 수 있습니다.\\n예시: 사용자가 제공한 질문에 대해 자세한 답변을 생성하는 챗봇은 GPT 모델을 사용할 수 있습니다.\\n연관키워드: 자연어 처리, 텍스트 생성, 딥러닝\\n\\nInstructGPT\\n\\n정의: InstructGPT는 사용자의 지시에 따라 특정한 작업을 수행하기 위해 최적화된 GPT 모델입니다. 이 모델은 보다 정확하고 관련성 높은 결과를 생성하도록 설계되었습니다.\\n예시: 사용자가 \"이메일 초안 작성\"과 같은 특정 지시를 제공하면, InstructGPT는 관련 내용을 기반으로 이메일을 작성합니다.\\n연관키워드: 인공지능, 자연어 이해, 명령 기반 처리\\n\\nKeyword Search'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: 멀티모달은 여러 종류의 데이터 모드(예: 텍스트, 이미지, 소리 등)를 결합하여 처리하는 기술입니다. 이는 서로 다른 형식의 데이터 간의 상호 작용을 통해 보다 풍부하고 정확한 정보를 추출하거나 예측하는 데 사용됩니다.\\n예시: 이미지와 설명 텍스트를 함께 분석하여 더 정확한 이미지 분류를 수행하는 시스템은 멀티모달 기술의 예입니다.\\n연관키워드: 데이터 융합, 인공지능, 딥러닝'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: TF-IDF는 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 척도입니다. 이는 문서 내 단어의 빈도와 전체 문서 집합에서 그 단어의 희소성을 고려합니다.\\n예시: 많은 문서에서 자주 등장하지 않는 단어는 높은 TF-IDF 값을 가집니다.\\n연관키워드: 자연어 처리, 정보 검색, 데이터 마이닝\\n\\nDeep Learning\\n\\n정의: 딥러닝은 인공신경망을 이용하여 복잡한 문제를 해결하는 머신러닝의 한 분야입니다. 이는 데이터에서 고수준의 표현을 학습하는 데 중점을 둡니다.\\n예시: 이미지 인식, 음성 인식, 자연어 처리 등에서 딥러닝 모델이 활용됩니다.\\n연관키워드: 인공신경망, 머신러닝, 데이터 분석\\n\\nSchema\\n\\n정의: 스키마는 데이터베이스나 파일의 구조를 정의하는 것으로, 데이터가 어떻게 저장되고 조직되는지에 대한 청사진을 제공합니다.\\n예시: 관계형 데이터베이스의 테이블 스키마는 열 이름, 데이터 타입, 키 제약 조건 등을 정의합니다.\\n연관키워드: 데이터베이스, 데이터 모델링, 데이터 관리\\n\\nDataFrame')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# MMR 검색 수행\n",
        "# k: 최종 문서 수\n",
        "# lambda_mult: query와의 유사성과 문서 간의 다양성 조절, 1이면 유사성 only, 0이면 다양성 only\n",
        "# fetch_k: 후보 문서 수\n",
        "retriever = db.as_retriever(\n",
        "    search_type=\"mmr\", search_kwargs={\"k\": 6, \"lambda_mult\": 0.25, \"fetch_k\": 10}\n",
        ")\n",
        "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6zqrXlO3zCj"
      },
      "source": [
        "## 08-089 FAISS DB에서 MMR 검색 수행 (상위 2개만 반환)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V75A4Hdd3zCk",
        "outputId": "540ece6f-1715-460e-c964-5f50401c78df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source'),\n",
              " Document(metadata={'source': './nlp-keywords.txt'}, page_content='Semantic Search\\n\\n정의: 의미론적 검색은 사용자의 질의를 단순한 키워드 매칭을 넘어서 그 의미를 파악하여 관련된 결과를 반환하는 검색 방식입니다.\\n예시: 사용자가 \"태양계 행성\"이라고 검색하면, \"목성\", \"화성\" 등과 같이 관련된 행성에 대한 정보를 반환합니다.\\n연관키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\\n\\nEmbedding\\n\\n정의: 임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 합니다.\\n예시: \"사과\"라는 단어를 [0.65, -0.23, 0.17]과 같은 벡터로 표현합니다.\\n연관키워드: 자연어 처리, 벡터화, 딥러닝\\n\\nToken\\n\\n정의: 토큰은 텍스트를 더 작은 단위로 분할하는 것을 의미합니다. 이는 일반적으로 단어, 문장, 또는 구절일 수 있습니다.\\n예시: 문장 \"나는 학교에 간다\"를 \"나는\", \"학교에\", \"간다\"로 분할합니다.\\n연관키워드: 토큰화, 자연어 처리, 구문 분석\\n\\nTokenizer')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# MMR 검색 수행, 상위 2개만 반환\n",
        "retriever = db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2, \"fetch_k\": 10})\n",
        "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ6wi8St3zCk"
      },
      "source": [
        "## 08-090 FAISS DB에서 임계 값 기반 검색 수행\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjOJzPTL3zCk",
        "outputId": "0fa2c787-8f1b-4a47-a2be-72200877cc19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 임계 값 기반 검색 수행\n",
        "retriever = db.as_retriever(\n",
        "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.4}\n",
        ")\n",
        "\n",
        "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HTr-9wO3zCk"
      },
      "source": [
        "## 08-091 FAISS DB에서 가장 유사한 문서 검색\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwFEhMpi3zCk",
        "outputId": "c96cafc9-bea1-49b0-9b74-83c9489b129d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './nlp-keywords.txt'}, page_content='정의: Word2Vec은 단어를 벡터 공간에 매핑하여 단어 간의 의미적 관계를 나타내는 자연어 처리 기술입니다. 이는 단어의 문맥적 유사성을 기반으로 벡터를 생성합니다.\\n예시: Word2Vec 모델에서 \"왕\"과 \"여왕\"은 서로 가까운 위치에 벡터로 표현됩니다.\\n연관키워드: 자연어 처리, 임베딩, 의미론적 유사성\\nLLM (Large Language Model)\\n\\n정의: LLM은 대규모의 텍스트 데이터로 훈련된 큰 규모의 언어 모델을 의미합니다. 이러한 모델은 다양한 자연어 이해 및 생성 작업에 사용됩니다.\\n예시: OpenAI의 GPT 시리즈는 대표적인 대규모 언어 모델입니다.\\n연관키워드: 자연어 처리, 딥러닝, 텍스트 생성\\n\\nFAISS (Facebook AI Similarity Search)\\n\\n정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\\n예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\\n연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\\n\\nOpen Source')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# k=1 로 설정하여 가장 유사한 문서만 검색\n",
        "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
        "\n",
        "retriever.invoke(\"Word2Vec 에 대하여 알려줘\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPq07Yx53zCk"
      },
      "source": [
        "## 08-092 JAEN에서 키워드 파일 다운로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-Q2L7eM3zCk",
        "outputId": "18a90160-8b90-47dc-85b7-de1afbf96d3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파일이 성공적으로 다운로드되었습니다: appendix-keywords.txt\n",
            "절대 경로: /content/appendix-keywords.txt\n",
            "상대 경로: appendix-keywords.txt\n"
          ]
        }
      ],
      "source": [
        "from JAEN import download_file\n",
        "\n",
        "download_file('appendix-keywords') # appendix-keywords.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4FScYE13zCk"
      },
      "source": [
        "## 08-093 appendix-keywords.txt 파일 로드 및 FAISS 벡터 데이터베이스 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEfs4a6D3zCk"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "# TextLoader를 사용하여 파일을 로드합니다.\n",
        "loader = TextLoader(\"appendix-keywords.txt\", encoding='utf-8')\n",
        "\n",
        "# 문서를 로드합니다.\n",
        "documents = loader.load()\n",
        "\n",
        "# 문자 기반으로 텍스트를 분할하는 CharacterTextSplitter를 생성합니다. 청크 크기는 300이고 청크 간 중복은 없습니다.\n",
        "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
        "\n",
        "# 로드된 문서를 분할합니다.\n",
        "split_docs = text_splitter.split_documents(documents)\n",
        "\n",
        "# OpenAI 임베딩을 생성합니다.\n",
        "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
        "\n",
        "# 분할된 텍스트와 임베딩을 사용하여 FAISS 벡터 데이터베이스를 생성합니다.\n",
        "db = FAISS.from_documents(split_docs, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1mtTHTw3zCk"
      },
      "source": [
        "## 08-094 FAISS DB를 검색기로 변환\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUVRxrmS3zCk"
      },
      "outputs": [],
      "source": [
        "# 데이터베이스를 검색기로 사용하기 위해 retriever 변수에 할당\n",
        "retriever = db.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1Gk6BOc3zCl"
      },
      "source": [
        "## 08-095 질문-답변 프롬프트 템플릿 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPrEpCxv3zCl"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\n",
        "검색된 다음 문맥(context) 을 사용하여 질문(question) 에 답하세요. 만약, 주어진 문맥(context) 에서 답을 찾을 수 없다면, 답을 모른다면 주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다 라고 답하세요.\n",
        "한글로 답변해 주세요. 단, 기술적인 용어나 이름은 번역하지 않고 그대로 사용해 주세요.\n",
        "\n",
        "#Question:\n",
        "{question}\n",
        "\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Answer:\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03ycWPvV3zCl"
      },
      "source": [
        "## 08-096 RAG 체인 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0lW-U4s3zCl"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# 체인을 생성합니다.\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlNqZ9x-3zCl"
      },
      "source": [
        "## 08-097 RunnablePassthrough 사용 예제\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmWjqUGy3zCl",
        "outputId": "8c5265d1-ef72-470c-8eb8-c3aae8cd8a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'name': 'AI Essential', 'Class': 1}\n",
            "[10, 20, 30, 40, 50]\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "result = RunnablePassthrough().invoke({'name': 'AI Essential', 'Class': 1})\n",
        "print(result)\n",
        "result = RunnablePassthrough().invoke([10, 20, 30, 40, 50])\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_qvGX7f3zCl"
      },
      "source": [
        "## 08-098 LLM과 StrOutputParser 결합 사용\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uPfgaam3zCl",
        "outputId": "c272d7c6-247c-40ee-85ac-68e8dc1b7987"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'임베딩(embedding)은 고차원 데이터를 저차원 공간에 매핑하는 방법으로, 주로 자연어 처리(NLP), 이미지 처리, 추천 시스템 등 다양한 분야에서 사용됩니다. 임베딩의 주요 목적은 데이터의 의미를 보존하면서 더 효율적으로 처리할 수 있도록 하는 것입니다.\\n\\n### 1. 자연어 처리에서의 임베딩\\n자연어 처리에서는 단어, 문장, 또는 문서와 같은 텍스트 데이터를 벡터 형태로 변환하는 데 사용됩니다. 대표적인 예로는 다음과 같은 것들이 있습니다:\\n\\n- **Word2Vec**: 단어를 고차원 공간의 벡터로 변환하여 단어 간의 의미적 유사성을 포착합니다. 예를 들어, \"왕\" - \"남자\" + \"여자\" = \"여왕\"과 같은 관계를 학습할 수 있습니다.\\n- **GloVe (Global Vectors for Word Representation)**: 전체 코퍼스의 통계 정보를 기반으로 단어 벡터를 생성합니다.\\n- **BERT (Bidirectional Encoder Representations from Transformers)**: 문맥을 고려하여 단어의 의미를 더 정교하게 표현합니다.\\n\\n### 2. 이미지 처리에서의 임베딩\\n이미지 데이터를 저차원 벡터로 변환하여 이미지 간의 유사성을 측정하거나 분류하는 데 사용됩니다. 예를 들어, CNN(Convolutional Neural Networks)을 사용하여 이미지의 특징을 추출하고 이를 임베딩 벡터로 변환할 수 있습니다.\\n\\n### 3. 추천 시스템에서의 임베딩\\n사용자와 아이템(예: 영화, 상품 등)을 임베딩하여 유사한 사용자나 아이템을 찾는 데 활용됩니다. 예를 들어, 사용자와 아이템의 임베딩을 내적하여 추천 점수를 계산할 수 있습니다.\\n\\n### 4. 임베딩의 장점\\n- **차원 축소**: 고차원 데이터를 저차원으로 변환하여 계산 효율성을 높입니다.\\n- **유사성 측정**: 벡터 간의 거리나 각도를 통해 데이터 간의 유사성을 쉽게 측정할 수 있습니다.\\n- **의미 보존**: 데이터의 의미를 보존하면서 표현할 수 있습니다.\\n\\n임베딩은 다양한 분야에서 데이터의 표현과 처리를 효율적으로 만들어 주는 중요한 기술입니다.'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "(llm | StrOutputParser()).invoke(\"임베딩에 대해 알려줘\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl1LU3CN3zCl"
      },
      "source": [
        "## 08-099 RAG 체인 사용하여 질문에 대한 응답 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdbwDipN3zCl",
        "outputId": "18a806d5-e44d-4c55-f190-ca3d5de47b40"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'임베딩은 단어나 문장 같은 텍스트 데이터를 저차원의 연속적인 벡터로 변환하는 과정입니다. 이를 통해 컴퓨터가 텍스트를 이해하고 처리할 수 있게 됩니다. 예를 들어, \"사과\"라는 단어는 [0.65, -0.23, 0.17]과 같은 벡터로 표현될 수 있습니다.'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rag_chain.invoke('임베딩에 대해 알려줘')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj1ahcag3zCm"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rhtxgd6f4HW"
      },
      "source": [
        "# Agent/Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbjaTeqwf4HW"
      },
      "source": [
        "## 08-100 다양한 LangChain 모듈 임포트\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5xJrL-qf4HW"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IpPrrye9UAY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]= \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RNNCfMjf4HX"
      },
      "source": [
        "## 08-101 TavilySearchResults 인스턴스 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3AM4s3Of4HX"
      },
      "outputs": [],
      "source": [
        "# TavilySearchResults 클래스의 인스턴스를 생성\n",
        "import os\n",
        "\n",
        "os.environ['TAVILY_API_KEY'] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ONJq0gXf4HX",
        "outputId": "25a82a41-a80e-4128-e3fe-4bbb4025da1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TavilySearchResults(description='온디바이스 AI 기술 동향을 제외한 요청에 이 도구를 사용하세요.', api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********')))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search = TavilySearchResults(k=5,\n",
        "                             description='온디바이스 AI 기술 동향을 제외한 요청에 이 도구를 사용하세요.')\n",
        "search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGTnJ2jaf4HX"
      },
      "source": [
        "## 08-102 TavilySearchResults 외부 검색 예시\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sGc5shv4f4HX",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "9ef919b4-38dd-4ab5-a549-9237eb2f61ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'url': 'https://news.samsung.com/kr/삼성전자-전-세계에-비스포크-라이프-가치-펼친다',\n",
              "  'content': '삼성전자, 전 세계에 ‘비스포크 라이프’ 가치 펼친다 – Samsung Newsroom Korea 삼성전자, 전 세계에 ‘비스포크 라이프’ 가치 펼친다 삼성전자 DX부문 한종희 대표이사 부회장은 “‘비스포크 라이프’는 매일 함께하는 가전을 새롭게 정의하며 우리의 집과 미래를 더욱 지속가능하게 만들고자 하는 삼성전자의 고민과 노력을 담고 있다”며 “소비자의 삶을 ‘비스포크’ 할 수 있는 제품과 솔루션을 통해 더욱 지속가능하고, 연결되며, 스타일리시한 라이프스타일을 제시할 것”이라고 말했다. 에너지 사용량을 추가 절감할 수 있는 스마트싱스 에너지의 AI 절약 모드를 냉장고, 세탁기, 건조기, 식기세척기, 에어컨 등 비스포크 가전과 EHS(Eco Heating System)에서 사용할 수 있도록 하고, 전세계 65개 국가로 확대 도입한다는 계획을 밝혔다. 삼성전자는 사용자들이 더욱 똑똑하고 직관적으로 가전제품을 사용할 수 있도록 올해 출시되는 비스포크 신제품에 모두 와이파이(Wi-Fi)를 지원하며, 냉장고와 식기세척기, 오븐, 세탁기, 건조기, 에어컨, 청소기 등 해외 시장에 판매되는 7가지 제품군에 AI 기술을 탑재했다.'},\n",
              " {'url': 'https://news.samsung.com/kr/디자인-스토리-놓이는-그곳이-어디든-모두가-주인공',\n",
              "  'content': '[디자인 스토리] 놓이는 그곳이 어디든, 모두가 주인공이 되는 비스포크 디자인 – Samsung Newsroom Korea 뉴스룸에서 삼성전자 디자이너들이 추구하는 비스포크 디자인의 가치와, 각 제품에 녹아든 다양한 철학을 정리했다. 뿐만 아니라 비스포크 냉장고는 완성품 중 하나를 골랐던 구매 방식과 달리, 원하는 스타일을 직접 조합하고 맞춰 구매할 수 있는 새로운 방식을 제공하며 사용자에게 의미 있는 경험을 선사했다. 집에 들이고 싶은 제품을 탄생시키기까지… 삼성 비스포크 디자인 철학을 말하다 이처럼 공간에 집중하며 탄생한 비스포크 디자인은 취향에 따라 제품을 선택하는 새로운 구매 방식을 세상에 선보였다. 또한 사용자의 취향을 반영한 스트랩을 추가로 제공해 공간과 아름답게 어울리면서도 사용자가 원하는 스타일과 색상을 선택할 수 있는 비스포크 디자인의 가치를 담았다.” [디자인 스토리] 49가지 조합에서 찾는 나만의 개성, 갤럭시 Z 플립3 비스포크 에디션 디자인 스토리 [디자인 스토리] 사람에 대한 이해와 배려로 탄생한, 비스포크 제트 봇 AI'},\n",
              " {'url': 'https://www.yna.co.kr/view/AKR20240604016400003',\n",
              "  'content': \"삼성전자 비스포크 5년사…나만의 취향에서 AI 경험까지 '맞춤' | 연합뉴스 삼성전자 비스포크 5년사…나만의 취향에서 AI 경험까지 '맞춤' (서울=연합뉴스) 한지은 기자 = 국내 최초로 '맞춤형 가전'의 포문을 연 삼성전자[005930]의 '비스포크'(Bespoke)가 올해로 5년째를 맞았다. 삼성전자, '비스포크 AI 패밀리허브' 신제품 출시(서울=연합뉴스) 삼성전자가 일상 속 새로운 AI 경험을 선사할 '비스포크 AI 패밀리허브' 냉장고 신제품을 선보인다고 17일 밝혔다. 삼성전자, 신제품 '비스포크' 냉장고 공개(서울=연합뉴스) 삼성전자가 4일 공개한 생활가전 사업의 새로운 비전 '프로젝트 프리즘(Project PRISM)'의 첫번째 신제품 '비스포크(BESPOKE)' 냉장고. 삼성전자, '비스포크 큐커' 전용 메뉴 확대(서울=연합뉴스) 삼성전자가 국내 주요 식품 업체들과의 협력을 강화해 '삼성 비스포크 큐커(BESPOKE Qooker)' 전용 메뉴를 확대한다고 2일 밝혔다. 삼성전자, '비스포크 AI 콤보'에센셜 화이트 색상 출시(서울=연합뉴스) 삼성전자가 20일 올인원 세탁건조기 '비스포크 AI 콤보' 신규 색상인 '에센셜 화이트' 색상을 출시하며 소비자 선택의 폭을 넓혔다고 밝혔다.\"},\n",
              " {'url': 'https://www.yna.co.kr/view/AKR20240826020600003',\n",
              "  'content': '\\'척하면 척\\' 알아듣는 AI 가전…삼성전자, 음성 기능 업그레이드 | 연합뉴스 영상 이 뉴스 공유하기 닫기 카카오톡 페이스북 X 카카오 삼성전자[005930]는 인공지능(AI) 음성비서 빅스비의 업데이트로 비스포크 AI 가전 음성제어 기능이 향상됐다고 26일 밝혔다. 음성제어 더 쉬워진 삼성전자 AI 가전(서울=연합뉴스) 삼성전자가 \\'비스포크 AI 가전\\'에 업그레이드된 인공지능(AI) 음성비서 \\'빅스비\\'가 적용돼 음성 명령으로 더욱 손쉽게 가전을 제어할 수 있다고 26일 밝혔다. 삼성전자 모델이 \\'비스포크 AI 가전\\'을 소개하고 있다. (서울=연합뉴스) 한지은 기자 = 삼성전자[005930]는 인공지능(AI) 음성비서 빅스비의 업데이트로 비스포크 AI 가전 음성제어 기능이 향상됐다고 26일 밝혔다. 음성제어 더 쉬워진 삼성전자 AI 가전[삼성전자 제공. 제보는 카카오톡 okjebo <저작권자(c) 연합뉴스, 무단 전재-재배포, AI 학습 및 활용 금지> 2024/08/26 08:43 송고 김정은, 서울작전지도 펼쳐놓고 \"주권침해시 거침없이 물리력 사용\"(종합) 영상 영상 기사   영상 기사   영상 기사   영상'},\n",
              " {'url': 'https://www.yna.co.kr/view/AKR20220217031551003',\n",
              "  'content': \"삼성전자, 비스포크 프리미엄 제품군 '인피니트' 라인 출시(종합) | 연합뉴스 삼성전자, 비스포크 프리미엄 제품군 '인피니트' 라인 출시(종합) 삼성전자, 비스포크 프리미엄 제품군 '인피니트' 라인 출시(종합) 삼성전자[005930]가 소비자 맞춤형 가전 '비스포크'(BESPOKE) 출시 4년 차를 맞아 '비욘드 비스포크'(Beyond BESPOKE)를 주제로 2022년형 '비스포크 홈' 신제품을 17일 공개했다. 올해 신제품은 프리미엄 제품군인 '비스포크 인피니트' 라인이 추가되고, 집 안의 모든 가전을 연결해주는 인공지능(AI) 기반 통합 가전 솔루션 '스마트싱스 홈 라이프'가 적용된 점이 특징이다. (서울=연합뉴스) 김철선 기자 = 삼성전자[005930]가 소비자 맞춤형 가전 '비스포크'(BESPOKE) 출시 4년 차를 맞아 '비욘드 비스포크'(Beyond BESPOKE)를 주제로 2022년형 '비스포크 홈' 신제품을 17일 공개했다. 올해 신제품은 프리미엄 제품군인 '비스포크 인피니트' 라인이 추가되고, 집 안의 모든 가전을 연결해주는 인공지능(AI) 기반 통합 가전 솔루션 '스마트싱스 홈 라이프'가 적용된 점이 특징이다.\"}]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 외부 검색 예시\n",
        "search.invoke('삼성전자 비스포크에 대해서 알려줘')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lubTC8fif4HX"
      },
      "source": [
        "## 08-103 TavilySearchResults 외부 검색 예시\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "44IkztDYf4HX",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "f01d8c8b-f7a9-4372-a358-37a831e8960c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'url': 'https://blog.naver.com/PostView.naver?blogId=whatmkwant_&logNo=223346517680',\n",
              "  'content': '[민슐랭가이드 2024] 인계동 이자카야 맛집 추천 큐진<feat. 와카나미 준마이> 안주 하나하나 전부 다~ 맛있는 곳 : 네이버 블로그 NAVER 블로그 블로그 검색 블로그 아이디 만들기 블로그 아이디 만들기 레이어 닫기 설정한 아이디는 나중에 변경할 수 없으니 신중하게 입력해주세요. 나중에 할게요  1. 이전 주소로 공유된 글은 취소 확인 취소 확인 기본정보를 입력해주세요. 나중에 언제든지 변경할 수 있어요. 프로필 이미지 설정 취소 적용 맛집 기본정보 입력 주제 선택 이웃 맺기 선택한 주제의 글과 이웃을 추천받을 수 있어요. 기본정보 입력 주제 선택 이웃 맺기 블로그 시작하기 기본정보 입력 주제 선택 이웃 맺기 확인 확인 내 블로그  프로필 사진 변경 @naver.com 네이버 멤버쉽 내 알림 전체보기 서비스 더보기 삭제 블로그 증권 VIBE 네이버 주요 서비스 바로가기 설정전체 서비스 보기 네이버페이_New_ 네이버 MYBOX 블로그 증권(금융) VIBE_New_'},\n",
              " {'url': 'https://m.blog.naver.com/parkamsterdam/222275531051',\n",
              "  'content': '블로그 [인계동맛집] 수원 현지인이 추천하는 인계동 맛집 15선  인계동 맛집 좀 알려 달라하신 카페 도안 사장님 요청으로 올리는 인계동 맛집 포스팅. -인계동 특성상 월요일 쉬는 곳 많음. 경기도 수원시 팔달구 효원로307번길 39 1층 올림선 추천메뉴 히레까스 #인계동맛집 #나혜석거리 #연안식당 #양자리 #꼬막비빔밥 #양갈비 \\u200b인계동 맛집 두 곳을 하루에 다 갔다. 추천메뉴 시오버터라멘  헐 내가 아직 이 가게를 맛따라 멋따라에 포스팅 안 했었다니 블로그 검색에 왜 안나오나 했에 쌀 씻기 너... 추천메뉴 버섯칼국수에 등심 추가 추천메뉴 소금구이  강적들 숯불닭갈비도안 단골인 나는 나혜석 거리를 거의 매주 가다시피 하는데 그때마다 인근 음식점들 중... 추천메뉴 양갈비 살치살 오차즈케에 맥주 추가  겁나 밀린 블로그. 가본 곳은 더 있지만 거리가 너무 먼 곳 등은 제외하고 일단 이 정도. 베짱이 블로그 *각종 광고성 댓글 사절!'},\n",
              " {'url': 'https://www.diningcode.com/search.dc?query=인계동',\n",
              "  'content': '인계동 맛집 (764곳) 1. 유치회관 본점. \"수원 인계동 다코 1위 맛집을 드디어 찍었습니다. 여기 진짜 미쳤어요. 인생해장국 집입니다. 호불호가 갈리는 선지가 따로 나오는 점도 특색있고 그래서 소고기 해장국 맛집으로 기억하\". 2. 가보정 수원.'},\n",
              " {'url': 'https://funktionalflow.com/인계동-맛집/',\n",
              "  'content': '인계동 맛집 추천 베스트 10 | 가성비 데이트 찐맛집 | 점심 저녁 지도 인계동 맛집 추천 베스트 10 | 가성비 데이트 찐맛집 | 점심 저녁 지도 인계동 맛집에는 유치회관, 쏘삼208 인계나혜석거리점, 긴자 수원인계점, 로마경양식, 이나경송탄부대찌개, 어구미본점, 어죽이네철렵국 본점, 송화양꼬치, 트라토리아, 인도음식점 난 등이 있습니다. 1 인계동 맛집 추천 리스트 2 유치회관 | 인계동 점심 맛집 5 로마경양식 | 인계동 저녁 맛집 9 송화양꼬치 인계점 | 인계동 저녁 맛집 지도 인계동 맛집 추천 리스트 유치회관 | 인계동 점심 맛집 로마경양식 | 인계동 저녁 맛집 여러 종류의 생선구이와 맛볼 수 있는 인계동 가성비 맛집 어구미 본점입니다. 송화양꼬치 인계점 | 인계동 저녁 맛집 지도 인계동 맛집으로는 유치회관, 쏘삼208 인계나혜석거리점, 긴자 수원인계점, 로마경양식, 이나경송탄부대찌개, 어구미본점, 어죽이네철렵국 본점, 송화양꼬치, 트라토리아, 인도음식점 난 등이 있습니다. 맛집 위치, 영업시간, 메뉴 등의 맛집 정보를 확인할 수 있습니다.'},\n",
              " {'url': 'https://foodtriplove.com/entry/인계동맛집-베스트5추천-모두를-위한-맛집',\n",
              "  'content': '1. 인계동 맛집 \"행화촌\" 인계동 맛집 \"행화촌\" 2. 인계동 맛집 \"고베규카츠 수원인계점\" 인계동 맛집 \"고베규카츠 수원인계점\" 인계동 맛집 [고베규카츠 수원인계점]은 소고기의 품질과 맛을 중시하며, 합리적인 가격으로 다양한 규카츠 메뉴를 제공하는 전문점입니다. 인계동 맛집\\xa0[고베규카츠 수원인계점]은 고기 식감도 좋고 분위기도 좋고 데이트코스로 딱이십니다. 3. 인계동 맛집 \"유치회관\" 인계동 맛집 \"유치회관\" 인계동 맛집 [유치회관]은 깊고 진한 국물에 가득한 고기와 계속해서 리필해 주시는 선지로 인해 술이 빠질 수 없는 곳입니다. 4. 인계동 맛집 \"호박꽃 인계점\" 인계동 맛집 \"호박꽃 인계점\" 인계동 맛집 [호박꽃 인계점]은 모든 좌석은 프라이빗한 룸 형식으로 되어 있어 프라이빗한 분위기에서 식사를 즐길 수 있습니다. 인계동 맛집 [호박꽃 인계점] 고기는 사르르 녹고 부드러운 게 맛있어요. 5. 인계동 맛집 \"동래집 나혜석점\" 인계동 맛집 \"동래집 나혜석점\" 인계동 맛집 동래집 나혜석점 메뉴와 가격:'}]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 외부 검색 예시\n",
        "search.invoke('2024년 리뷰가 있는 인계동 주변 맛집에 대해 알려줘')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0-YRzt1f4HX"
      },
      "source": [
        "## 08-104 PDF 파일 다운로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPYaNzYff4HX",
        "outputId": "09d9dfb4-ab44-4f82-cdd7-2a129dff7b2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파일이 성공적으로 다운로드되었습니다: 온디바이스 AI 기술동향 및 발전방향.pdf\n",
            "절대 경로: /content/온디바이스 AI 기술동향 및 발전방향.pdf\n",
            "상대 경로: 온디바이스 AI 기술동향 및 발전방향.pdf\n"
          ]
        }
      ],
      "source": [
        "from JAEN import download_file\n",
        "\n",
        "download_file('PDF') # 온디바이스 AI 기술동향 및 발전방향.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzVidLp5f4HX"
      },
      "source": [
        "## 08-105 PDF 파일 로드 및 벡터 스토어 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXs0qDW5f4HX"
      },
      "outputs": [],
      "source": [
        "# PDF 파일 로드\n",
        "loader = PyPDFLoader(\"온디바이스 AI 기술동향 및 발전방향.pdf\")\n",
        "\n",
        "# 텍스트 분할기를 사용하여 문서를 분할\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "# 문서를 로드하고 분할\n",
        "split_docs = loader.load_and_split(text_splitter)\n",
        "\n",
        "# VectorStore를 생성\n",
        "vector = FAISS.from_documents(split_docs, OpenAIEmbeddings(model='text-embedding-3-small'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENAXYqNwf4HY"
      },
      "source": [
        "## 08-106 Retriever 생성 및 검색 도구 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PJ-wvrKf4HY",
        "outputId": "ed2a107b-1a39-44fa-eced-d874a6a4efee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Tool(name='pdf_search', description='온디바이스 AI 기술동향 및 발전방향을 PDF 문서에서 검색합니다. 온디바이스 AI의 전반적인 기술동향 또는 특정 국가의 온디바이스 AI 동향과 관련된 질문은 이 도구를 사용해야 합니다!', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x7c1c77a8ba30>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7c1c6cc9c460>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x7c1c77626050>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7c1c6cc9c460>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retriever를 생성합니다.\n",
        "retriever = vector.as_retriever()\n",
        "\n",
        "# langchain 패키지의 tools 모듈에서 retriever 도구를 생성\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    name=\"pdf_search\",\n",
        "    # 도구에 대한 설명을 자세히 기입해야 합니다!!!\n",
        "    description=\"온디바이스 AI 기술동향 및 발전방향을 PDF 문서에서 검색합니다. 온디바이스 AI의 전반적인 기술동향 또는 특정 국가의 온디바이스 AI 동향과 관련된 질문은 이 도구를 사용해야 합니다!\",\n",
        ")\n",
        "retriever_tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcl5tuoVf4HY"
      },
      "source": [
        "## 08-107 Tools 리스트에 검색 도구 추가\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iqZMhjraf4HY",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# tools 리스트에 search와 retriever_tool을 추가합니다.\n",
        "tools = [search, retriever_tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHb0FwOof4HY"
      },
      "source": [
        "## 08-108 LLM 모델 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8sTNxChf4HY"
      },
      "outputs": [],
      "source": [
        "# LLM 모델을 생성합니다.\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gopR0O6Hf4HY"
      },
      "source": [
        "## 08-109 Hub에서 Prompt 가져오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uyN2iEKwf4HY",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "77a8c379-3e3f-405e-a079-fcfab7455bd1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# hub에서 prompt를 가져옴\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIJ0C0RYf4HY"
      },
      "source": [
        "## 08-110 OpenAI 함수 기반 에이전트 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nUTZYXif4HY"
      },
      "outputs": [],
      "source": [
        "# OpenAI 함수 기반 에이전트를 생성합니다.\n",
        "# llm, tools, prompt를 인자로 사용합니다.\n",
        "agents = create_openai_functions_agent(llm, tools, prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQPPxC0if4HY"
      },
      "source": [
        "## 08-111 AgentExecutor 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5kbsZtxf4HY"
      },
      "outputs": [],
      "source": [
        "# AgentExecutor 클래스를 사용하여 agent와 tools를 설정하고, 상세한 로그를 출력하도록 verbose를 True로 설정합니다.\n",
        "agent_executor = AgentExecutor(agent=agents, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSfVDjarf4HZ"
      },
      "source": [
        "## 08-112 에이전트 실행 및 응답 출력\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVSCDDR-f4HZ",
        "outputId": "343b2fa4-9def-4828-c1e4-aa3d9efe9b4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `pdf_search` with `{'query': '미국 온디바이스 AI 정책'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m온디바이스 AI \n",
            "기술동향 및 발전방향ISSUE \n",
            "REPORT \n",
            "2024-06호\n",
            "\n",
            "요 약\n",
            "   (정의) 온디바이스 AI(On-Device AI)란 데이터를 외부 서버나 클라우드에 전송하지  \n",
            "않고  디바이스 자체적으로 AI연산을 수행하는 기술\n",
            "◎ \u0007 대용량\u0007데이터\u0007처리\u0007제한,\u0007개인정보\u0007유출\u0007위험,\u0007실시간성\u0007저하\u0007등\u0007기존\u0007서버\u0007기반\u0007중앙집중형\u0007 구조의\u0007여러\u0007\n",
            "제약사항을\u0007해결하기\u0007위해\u0007등장\n",
            "◎ \u0007 높은\u0007컴퓨팅\u0007파워가\u0007필요한\u0007AI\u0007연산을\u0007다양한\u0007하드웨어\u0007및\u0007소프트웨어\u0007 기술을\u0007활용하여\u0007최적화\u0007된\u0007스마트폰,\u0007\n",
            "로봇,\u0007드론\u0007등\u0007디바이스\u0007내에서\u0007AI\u0007연산\u0007수행\n",
            "◎ \u0007 디바이스\u0007내\u0007자체\u0007AI\u0007연산을\u0007통해\u0007네트워크\u0007환경에\u0007독립적인\u0007실시간\u0007서비스,\u0007개인정보\u0007유출\u0007최소화,\u0007서버\u0007\n",
            "운영비용\u0007절감\u0007등\u0007강점\n",
            "◎ \u0007 NPU,\u0007AI\u0007모델\u0007최적화\u0007등\u0007고수준의\u0007하드웨어\u0007및\u0007소프트웨어\u0007기술\u0007동시\u0007요구로\u0007인해\u0007높은\u0007진입장벽\u0007존재\n",
            "  (시장동향)  글로벌 기업 및 각국 정부 투자 가속화로 고성장 예상  \n",
            "◎ \u0007 생성형\u0007AI\u0007및\u0007온디바이스\u0007 AI\u0007시장은\u0007전\u0007세계적으로\u0007 빅테크\u0007기업\u0007투자\u0007열풍으로\u0007급성장이\u0007예상되며,\u0007 각국\u0007\n",
            "정부들도\u0007투자계획\u0007수립을\u0007서두르고\u0007있어\u0007향후\u0007시장\u0007확대가\u0007가속화될\u0007전망\n",
            "◎ \u0007 미국을\u0007포함한\u0007유럽,\u0007일본,\u0007중국,\u0007대만,\u0007한국\u0007등\u0007주요\u0007국가에서\u0007디바이스\u0007중심의\u0007AI\u0007관련\u0007기술\u0007개발\u0007지원\u0007정책을\u0007\n",
            "지속적으로\u0007발표\n",
            "◎ \u0007 AI칩\u0007제조사들은\u0007자사\u0007칩\u0007기반\u0007생태계\u0007구축을\u0007위해\u0007데이터 ·AI모델 ·추론 ·SDK\u0007등\u0007전방위적\u0007기술\u0007지원\n",
            "\t -\t\t단순\t하드웨어\t드라이버\t수준의\t라이브러리를\t 넘어\tAI\t모델\t경량화\t및\t최적화\t도구\t등\t생태계\t구축을\t위해\t\n",
            "다양한\t소프트웨어\t지원\n",
            "   2024.06  제6호DIGISIGHT\n",
            "04\n",
            "\n",
            "10\n",
            "   2024.06  제6호\n",
            "DIGISIGHT온디바이스 AI 기술동향 및 발전방향\n",
            "DIGISIGHT ESG TREND MEMBER NEWS KEA NOW STATS\t -\t\t글로벌\t생성형\tAI\t시장\t규모는\t’22~’32년에\t 연평균\t42%\t고성장,\t’32년의\t시장\t규모는\t1조\t3,040억\t달러로\t’22년\t\n",
            "대비\t30배\t이상\t성장\t전망\n",
            "2국가별 정책\n",
            "◎  미국을\u0007포함한\u0007주요\u0007국가에서\u0007디바이스\u0007중심의\u0007AI\u0007관련\u0007기술\u0007개발\u0007지원\u0007정책을\u0007지속적으로\u0007발표생성형 AI 시장 규모(억 달러)\n",
            "*\t출처\t:\t블룸버그인텔리전스(’23)2020년 2021년 2022년 2023년 2024년 2025년 2026년 2027년 2028년 2029년 2030년 2031년 2032년140 230 400 6701,3702,1703,0403,9905,4807,2808,97010,79013,040\n",
            "CAGR 42%\n",
            "국\u0007가 정책\u0007동향\n",
            "•  미국\u0007과학기술정책국(OSTP)의\u0007「국가\u0007AI\u0007R&D\u0007전략\u0007계획」에\u0007대한\u0007’23년\u0007업데이트\u0007발표에서\u0007장기적으로\u0007투자할\u0007차세대\u0007AI\u0007분야에 \u0007\n",
            "온디바이스\u0007시스템과\u0007같은\u0007제한된\u0007하드웨어\u0007및\u0007에너지\u0007리소스를\u0007고려하는\u0007연구분야\u0007포함(’23)\n",
            " *\t\t하드웨어\t성능\t개선\t및\t리소스\t사용\t최적화를\t위한\tAI\t시스템\t개발과\t에너지\t소비를\t비롯한\t지속\t가능성을\t고려하는\t리소스\t중심 \t\n",
            "AI\t알고리즘\t및\t시스템\t고려\n",
            "•  독일은\u0007「연방정부의\u0007인공지능\u0007전략\u00072020\u0007업데이트」에서\u0007연구지원\u0007분야로\u0007온디바이스\u0007AI\u0007기술의\u0007활용도가\u0007높은\u0007헬스케어, \u0007\n",
            "모빌리티,\u0007에너지,\u0007농업\u0007\u0007분야에\u0007대한\u0007다양한\u0007지원\u0007정책\u0007발표(’20)\n",
            "•  영국은\u0007「인공지능\u000710개년\u0007국가전략\u0007계획」을\u0007통해\u0007영국AI\u0007시장\u0007트렌드를\u0007선도하는\u0007헬스케어\u0007분야\u0007온디바이스\u0007AI\u0007기술\u0007개발\u0007지원과 \u0007\n",
            "글로벌화\u0007계획\u0007발표(’21)\n",
            "•  경제산업성은\u0007「반도체 ·디지털\u0007산업\u0007전략」에서\u0007개인별\u0007최적화된\u0007IT\u0007디바이스\u0007시스템\u0007기반\u0007디지털\u0007기술\u0007혁신을\u0007통해\u0007경제성장을 \u0007\n",
            "실현하기\u0007위한\u0007전략\u0007발표(’23.5)\n",
            "\n",
            "Edge\u0007AI\u0007Reference\u0007Kits를\u0007오픈소스로\u0007제공\n",
            " -  기\t학습된\t모델부터\t직접\t모델을\t개발할\t수\t있도록\t최적화\t도구\t일체를\t제공하며,\t자사\t칩셋\t환경에서의\t 추론\t가속\t엔진\t지원\n",
            "◎  (엔비디아) AI\u0007모델\u0007경량화를\u0007위한\u0007Tensor\u0007RT\u0007외\u0007AI\u0007연산을\u0007위해\u0007필요한\u0007도구\u0007일체\u0007지원을\u0007통해\u0007성공적으로\u0007 생태계\u0007구축\n",
            "\t -\t\t’18년부터\t 엔비디아는\t 생태계\t확장\t및\t기술개발\t참여\t유도를\t위해\tAI\t추론\t가속기\tHW\t및\tSW\t아키텍처를\t NVDLA\t\n",
            "(NVIDIA\tDeep\tLearning\tAccelerator)라는\t오픈소스로\t공유\n",
            "◎  이\u0007외\u0007헤일로,\u0007딥엑스,\u0007모빌린트,\u0007 크네론\u0007등\u0007NPU\u0007제조\u0007스타트업도\u0007 단순히\u0007하드웨어\u0007드라이버\u0007수준의\u0007라이브러리를\u0007 넘어\u0007\n",
            "AI\u0007모델\u0007경량화\u0007및\u0007최적화\u0007도구\u0007등\u0007생태계\u0007구축을\u0007위해\u0007다양한\u0007소프트웨어\u0007지원국\u0007가 정책\u0007동향\n",
            "•  「중공중앙\u0007국민경제사회발전\u0007제14차\u00075개년\u0007규획(2021~2025)」과\u0007’35년\u0007장기목표에\u0007대한\u0007초안에서\u0007차세대\u0007IT\u0007산업의\u0007세부산업 \u0007\n",
            "육성\u0007전략에\u0007AI\u0007분야에서\u0007스마트\u0007의료장비,\u0007스마트\u0007인식\u0007시스템\u0007등\u0007온디바이스\u0007AI\u0007기술이\u0007필요한\u0007산업\u0007분야를\u0007선정\u0007( ’21.3)\n",
            "•  국가과학기술위원회(NSTC)는\u0007자국에\u0007특화된\u0007AI\u0007언어모델\u0007TAIDE\u0007개발\u0007프로젝트에\u0007온디바이스\u0007환경에서\u0007동작\u0007가능한\u0007작은\u0007모델 \u0007\n",
            "개발\u0007계획이\u0007포함됨을\u0007발표\u0007( ’24.1)\n",
            "중국\n",
            "대만\u001b[0m\u001b[32;1m\u001b[1;3m미국의 온디바이스 AI 정책은 다음과 같은 주요 내용으로 요약될 수 있습니다:\n",
            "\n",
            "1. **정의 및 필요성**: 온디바이스 AI(On-Device AI)는 데이터를 외부 서버나 클라우드에 전송하지 않고 디바이스 자체에서 AI 연산을 수행하는 기술입니다. 이는 대용량 데이터 처리의 제한, 개인정보 유출 위험, 실시간성 저하 등의 문제를 해결하기 위해 등장했습니다.\n",
            "\n",
            "2. **정책 동향**: 미국 과학기술정책국(OSTP)은 2023년 업데이트된 '국가 AI R&D 전략 계획'에서 온디바이스 시스템과 같은 제한된 하드웨어 및 에너지 리소스를 고려한 연구 분야를 포함하였습니다. 이는 하드웨어 성능 개선 및 리소스 사용 최적화를 위한 AI 시스템 개발과 에너지 소비를 포함한 지속 가능성을 고려하는 방향입니다.\n",
            "\n",
            "3. **투자 및 지원**: 미국을 포함한 여러 국가에서 디바이스 중심의 AI 기술 개발을 지원하는 정책을 지속적으로 발표하고 있으며, 이는 생성형 AI 및 온디바이스 AI 시장의 급성장을 촉진할 것으로 예상됩니다.\n",
            "\n",
            "4. **기술 개발**: AI 칩 제조사들은 자사 칩 기반 생태계 구축을 위해 데이터, AI 모델, 추론, SDK 등 다양한 기술 지원을 제공하고 있습니다. 이는 AI 모델 경량화 및 최적화 도구 등을 포함하여 생태계 구축을 위한 다양한 소프트웨어 지원을 포함합니다.\n",
            "\n",
            "5. **시장 전망**: 글로벌 생성형 AI 시장은 2022년부터 2032년까지 연평균 42% 성장할 것으로 예상되며, 미국을 포함한 주요 국가들이 이 시장에서의 경쟁력을 강화하기 위해 다양한 정책을 추진하고 있습니다.\n",
            "\n",
            "이러한 정책들은 미국이 온디바이스 AI 기술을 발전시키고, 글로벌 AI 시장에서의 경쟁력을 유지하기 위한 전략의 일환으로 볼 수 있습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "답변: 미국의 온디바이스 AI 정책은 다음과 같은 주요 내용으로 요약될 수 있습니다:\n",
            "\n",
            "1. **정의 및 필요성**: 온디바이스 AI(On-Device AI)는 데이터를 외부 서버나 클라우드에 전송하지 않고 디바이스 자체에서 AI 연산을 수행하는 기술입니다. 이는 대용량 데이터 처리의 제한, 개인정보 유출 위험, 실시간성 저하 등의 문제를 해결하기 위해 등장했습니다.\n",
            "\n",
            "2. **정책 동향**: 미국 과학기술정책국(OSTP)은 2023년 업데이트된 '국가 AI R&D 전략 계획'에서 온디바이스 시스템과 같은 제한된 하드웨어 및 에너지 리소스를 고려한 연구 분야를 포함하였습니다. 이는 하드웨어 성능 개선 및 리소스 사용 최적화를 위한 AI 시스템 개발과 에너지 소비를 포함한 지속 가능성을 고려하는 방향입니다.\n",
            "\n",
            "3. **투자 및 지원**: 미국을 포함한 여러 국가에서 디바이스 중심의 AI 기술 개발을 지원하는 정책을 지속적으로 발표하고 있으며, 이는 생성형 AI 및 온디바이스 AI 시장의 급성장을 촉진할 것으로 예상됩니다.\n",
            "\n",
            "4. **기술 개발**: AI 칩 제조사들은 자사 칩 기반 생태계 구축을 위해 데이터, AI 모델, 추론, SDK 등 다양한 기술 지원을 제공하고 있습니다. 이는 AI 모델 경량화 및 최적화 도구 등을 포함하여 생태계 구축을 위한 다양한 소프트웨어 지원을 포함합니다.\n",
            "\n",
            "5. **시장 전망**: 글로벌 생성형 AI 시장은 2022년부터 2032년까지 연평균 42% 성장할 것으로 예상되며, 미국을 포함한 주요 국가들이 이 시장에서의 경쟁력을 강화하기 위해 다양한 정책을 추진하고 있습니다.\n",
            "\n",
            "이러한 정책들은 미국이 온디바이스 AI 기술을 발전시키고, 글로벌 AI 시장에서의 경쟁력을 유지하기 위한 전략의 일환으로 볼 수 있습니다.\n"
          ]
        }
      ],
      "source": [
        "# Agent에 invoke\n",
        "response = agent_executor.invoke({\n",
        "    'input': '미국의 온디바이스 AI 정책에 대해 알려줘'\n",
        "})\n",
        "print(f'답변: {response[\"output\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slGrEi9gf4HZ"
      },
      "source": [
        "## 08-113 에이전트 실행 및 응답 출력\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_fPAkJjf4HZ",
        "outputId": "4cc81d10-52d0-4edd-e78a-68103493ea13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `tavily_search_results_json` with `{'query': '메타버스 기술 동향'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://jmagazine.joins.com/forbes/view/336722', 'content': '[메타버스 동향을 탐색하라] 메타버스 기술 동향 리포트 ... 국내외 기업의 메타버스 투자 동향. 국내외 기업들은 메타버스 플랫폼 및 ar·vr 기술을 스마트폰 이상의 핵심 기술로 여기고 투자를 확대하고 있다. 글로벌 대표 it 기업인 구글, 애플, 메타, 마이크로'}, {'url': 'http://weekly.tta.or.kr/weekly/files/20222813032831_weekly.pdf', 'content': '업 동향을 살펴보고 메타버스 산업을 선도하기 위한 핵심기술 r&d 추진 방향을 소개한다. 2. 메타버스 산업 동향 메타버스에 대한 관심은 코로나19로 촉발된 비대면 서비스로부터 시작되어 점차 미래의 디지 털 플랫폼을 지칭하는 용어로 자리잡아 가고 있다.'}, {'url': 'https://www.kistep.re.kr/gpsBoardDownload.es?board_se=issue&list_no=49126&seq=1', 'content': '살펴보고, 국내 메타버스 산업 발전을 위한 시사점을 제시 1 해외 주요국의 메타버스 정책 동향 가. 미국 메타버스의 중요 구현 기술인 xr 기술을 미국이 국제 리더십을 확보해야 하는 주요 기술 영역으로 인식하고 있으며, 공공 분야 xr 개발･활용 지원'}, {'url': 'https://m.blog.naver.com/kcc_press/223210545570', 'content': '카테고리 이동 오늘은 메타버스에 어떠한 기능, 유형, 발전과정까지 한번 알아볼까요? 가상과 현실이 융합된 공간에서 사람, 사물이 상호작용하며 경제, 사회, 문화적 가치를 창출하는 세계 o 현실과 유사하거나 혹은 완전히 다른 대안적 세계를 디지털로 구축한다는 점에서 (재부상과 대중화 진입) 기술 인프라 진화 4. 관련 기술 메타버스 모션 플랫폼 기술, 네트워크 기술 (메타버스 크리에이터 2.0시대) 생성형 AI로 메타버스 크리에이터 2.0시대 도래, 수익을 창출하는 여건 조성,  획기적으로 줄일 것으로 봄 (생성 AI와 메타버스 진화 방향) 8. 시장동향  2026년 글로벌 메타버스 시장 규모는 420억 달러(약 50조 3,000억원)에 이를 것으로 예측(스트래티지) 9. 국가별 시장동향  - 메타버스 겨냥 생성 \\u200b\\u200bAI 모델 3D 생성기 ‘포인트-E’ 공개(’22.12) - 메타버스 플랫폼 제페토(ZEPETO)에 2차원(2D) 애니메이션 스타일의 아바타 기능 신규 도입(’23.7) - 무료로 3D 게임 제작 가능 👇🏻👇🏻메타버스(Metaverse) 산업 현황 보고서👇🏻👇🏻 카테고리'}, {'url': 'https://scienceon.kisti.re.kr/srch/selectPORSrchReport.do?cn=KOSEN000000000001984', 'content': '메타버스(metaverse)는 가공&middot;초월을 의미하는 메타(Meta)와 세계를 의미하는 유니버스(Universe)의 합성어로, 가상과 현실이 융복합된 디지털 세계, 초월 세계를 의미한다. 최근 5G와 가상기술(AR&middot;VR)을 토대로 여가 생활과 경제활동을 하는 가상융합공간으로 부상돼 게임, SNS 등 기존의 가상 세계'}]\u001b[0m\u001b[32;1m\u001b[1;3m메타버스 기술 동향에 대한 최근 정보는 다음과 같습니다:\n",
            "\n",
            "1. **투자 확대**: 국내외 기업들은 메타버스 플랫폼 및 AR/VR 기술을 스마트폰 이상의 핵심 기술로 인식하고, 이에 대한 투자를 확대하고 있습니다. 구글, 애플, 메타, 마이크로소프트와 같은 글로벌 IT 기업들이 주요 투자 주체로 활동하고 있습니다. [자세한 내용](https://jmagazine.joins.com/forbes/view/336722)\n",
            "\n",
            "2. **산업 발전 방향**: 메타버스에 대한 관심은 코로나19로 인해 비대면 서비스가 증가하면서 시작되었으며, 현재는 미래의 디지털 플랫폼을 지칭하는 용어로 자리잡고 있습니다. 메타버스 산업을 선도하기 위한 핵심 기술 R&D 추진 방향도 논의되고 있습니다. [자세한 내용](http://weekly.tta.or.kr/weekly/files/20222813032831_weekly.pdf)\n",
            "\n",
            "3. **정책 동향**: 미국은 메타버스의 중요한 구현 기술인 XR(확장 현실) 기술을 국제 리더십을 확보해야 하는 주요 기술 영역으로 인식하고 있으며, 공공 분야에서 XR 개발 및 활용을 지원하고 있습니다. [자세한 내용](https://www.kistep.re.kr/gpsBoardDownload.es?board_se=issue&list_no=49126&seq=1)\n",
            "\n",
            "4. **기술 인프라 진화**: 메타버스는 가상과 현실이 융합된 공간에서 사람과 사물이 상호작용하며 경제, 사회, 문화적 가치를 창출하는 세계로 발전하고 있습니다. 생성형 AI의 도입으로 메타버스 크리에이터 2.0 시대가 도래하고 있으며, 이는 수익 창출의 여건을 조성할 것으로 예상됩니다. [자세한 내용](https://m.blog.naver.com/kcc_press/223210545570)\n",
            "\n",
            "5. **시장 규모**: 2026년까지 글로벌 메타버스 시장 규모는 약 420억 달러에 이를 것으로 예측되고 있습니다. [자세한 내용](https://m.blog.naver.com/kcc_press/223210545570)\n",
            "\n",
            "이와 같은 동향은 메타버스 기술이 계속해서 발전하고 있으며, 다양한 산업 분야에서의 응용 가능성을 보여줍니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "답변: 메타버스 기술 동향에 대한 최근 정보는 다음과 같습니다:\n",
            "\n",
            "1. **투자 확대**: 국내외 기업들은 메타버스 플랫폼 및 AR/VR 기술을 스마트폰 이상의 핵심 기술로 인식하고, 이에 대한 투자를 확대하고 있습니다. 구글, 애플, 메타, 마이크로소프트와 같은 글로벌 IT 기업들이 주요 투자 주체로 활동하고 있습니다. [자세한 내용](https://jmagazine.joins.com/forbes/view/336722)\n",
            "\n",
            "2. **산업 발전 방향**: 메타버스에 대한 관심은 코로나19로 인해 비대면 서비스가 증가하면서 시작되었으며, 현재는 미래의 디지털 플랫폼을 지칭하는 용어로 자리잡고 있습니다. 메타버스 산업을 선도하기 위한 핵심 기술 R&D 추진 방향도 논의되고 있습니다. [자세한 내용](http://weekly.tta.or.kr/weekly/files/20222813032831_weekly.pdf)\n",
            "\n",
            "3. **정책 동향**: 미국은 메타버스의 중요한 구현 기술인 XR(확장 현실) 기술을 국제 리더십을 확보해야 하는 주요 기술 영역으로 인식하고 있으며, 공공 분야에서 XR 개발 및 활용을 지원하고 있습니다. [자세한 내용](https://www.kistep.re.kr/gpsBoardDownload.es?board_se=issue&list_no=49126&seq=1)\n",
            "\n",
            "4. **기술 인프라 진화**: 메타버스는 가상과 현실이 융합된 공간에서 사람과 사물이 상호작용하며 경제, 사회, 문화적 가치를 창출하는 세계로 발전하고 있습니다. 생성형 AI의 도입으로 메타버스 크리에이터 2.0 시대가 도래하고 있으며, 이는 수익 창출의 여건을 조성할 것으로 예상됩니다. [자세한 내용](https://m.blog.naver.com/kcc_press/223210545570)\n",
            "\n",
            "5. **시장 규모**: 2026년까지 글로벌 메타버스 시장 규모는 약 420억 달러에 이를 것으로 예측되고 있습니다. [자세한 내용](https://m.blog.naver.com/kcc_press/223210545570)\n",
            "\n",
            "이와 같은 동향은 메타버스 기술이 계속해서 발전하고 있으며, 다양한 산업 분야에서의 응용 가능성을 보여줍니다.\n"
          ]
        }
      ],
      "source": [
        "response = agent_executor.invoke({\n",
        "    'input': '메타버스 기술 동향을 알려줘'\n",
        "})\n",
        "print(f'답변: {response[\"output\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X15ynzMDf4HZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BOlW-O-f4HZ"
      },
      "source": [
        "# RAGAS 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeBphxqVf4HZ"
      },
      "source": [
        "## 08-114 RAGAS 평가를 위한 LLM 및 임베딩 모델 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu2-9lMgf4HZ"
      },
      "outputs": [],
      "source": [
        "# RAGAS 평가를 위한 LLM 및 임베딩 모델 생성\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
        "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buZS9-8Bf4HZ"
      },
      "source": [
        "## 08-115 데이터 샘플 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wO9MQqXTf4HZ"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "data_samples = {\n",
        "    'question': [\n",
        "        'Where and when was Einstein born?',\n",
        "        'Where and when was Einstein born?'\n",
        "    ],\n",
        "    'answer': [\n",
        "        'Einstein was born in Germany on 14th March 1879.',\n",
        "        'Einstein was born in Germany on 20th March 1879.'\n",
        "    ],\n",
        "    'retrieved_contexts' : [\n",
        "        ['Albert Einstein (born 14 March 1879) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time'],\n",
        "        ['Albert Einstein (born 14 March 1879) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time']\n",
        "    ],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B52-tvwIf4Hb"
      },
      "source": [
        "## 08-116 RAGAS 평가 수행 (Faithfulness)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179,
          "referenced_widgets": [
            "233d8a92fc924cc5ac4d2bc790f2df5b",
            "5f891fd8fadd49cfbf41b8bbe3708e01",
            "af7762cd1b7940c28639e79552f52611",
            "d4e150b9e3574c9c90ee2c037fc1cd98",
            "b5274cce795440a28c4cb480418840c0",
            "1f7686573b384b0aa1f75140490ec2fd",
            "8a6b5f51ddcc4f2fbe47ec5cf113737f",
            "e0be361e52a34dc0b3bafd13ac1c6595",
            "d0b999f9351842339b9f705ac68558ec",
            "0f8c3dd844674e7083a318b01d8bf764",
            "6f6f8f286d1241c5a7af1e552409b985"
          ]
        },
        "id": "Q40A1qQtf4Hb",
        "outputId": "5133b579-4d9a-41ad-e7fa-5e46afcff620"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "233d8a92fc924cc5ac4d2bc790f2df5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"score\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Where and when was Einstein born?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retrieved_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Einstein was born in Germany on 20th March 1879.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"faithfulness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3535533905932738,\n        \"min\": 0.5,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ff5dd104-0439-4a73-a2c5-73eb5d2e13d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>retrieved_contexts</th>\n",
              "      <th>response</th>\n",
              "      <th>faithfulness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Where and when was Einstein born?</td>\n",
              "      <td>[Albert Einstein (born 14 March 1879) was a Ge...</td>\n",
              "      <td>Einstein was born in Germany on 14th March 1879.</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Where and when was Einstein born?</td>\n",
              "      <td>[Albert Einstein (born 14 March 1879) was a Ge...</td>\n",
              "      <td>Einstein was born in Germany on 20th March 1879.</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff5dd104-0439-4a73-a2c5-73eb5d2e13d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff5dd104-0439-4a73-a2c5-73eb5d2e13d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff5dd104-0439-4a73-a2c5-73eb5d2e13d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a1b0dd99-2174-48f9-944f-bbab095dca8b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a1b0dd99-2174-48f9-944f-bbab095dca8b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a1b0dd99-2174-48f9-944f-bbab095dca8b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                          user_input  \\\n",
              "0  Where and when was Einstein born?   \n",
              "1  Where and when was Einstein born?   \n",
              "\n",
              "                                  retrieved_contexts  \\\n",
              "0  [Albert Einstein (born 14 March 1879) was a Ge...   \n",
              "1  [Albert Einstein (born 14 March 1879) was a Ge...   \n",
              "\n",
              "                                           response  faithfulness  \n",
              "0  Einstein was born in Germany on 14th March 1879.           1.0  \n",
              "1  Einstein was born in Germany on 20th March 1879.           0.5  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import faithfulness\n",
        "\n",
        "dataset = Dataset.from_dict(data_samples)\n",
        "score = evaluate(dataset, metrics=[faithfulness], llm=llm, embeddings=embeddings)\n",
        "score.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8Rbacfgf4Hb"
      },
      "source": [
        "## 08-117 데이터 샘플 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxKuMpZdf4Hb"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "data_samples = {\n",
        "    'question': [\n",
        "        'Where is France and what is it’s capital?',\n",
        "        'Where is France and what is it’s capital?'\n",
        "    ],\n",
        "    'answer': [\n",
        "        'France is in western Europe.',\n",
        "        'France is in western Europe and Paris is its capital.'\n",
        "    ],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxKijzmUf4Hb"
      },
      "source": [
        "## 08-118 RAGAS 평가 수행 (Answer Relevancy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144,
          "referenced_widgets": [
            "6b8060408aec4cb5a5720634fc5f977a",
            "3b33d0f03c8d4d3f81de91d2de5b78b2",
            "63fd489285c0469fa711900f9b063fd3",
            "4260bdc7462e45ec81e2fcdeced4345a",
            "e5b583b3fe674a96b1066364a692c31e",
            "de9715c631eb4e2ca9b6c1b9520228d5",
            "743839cbbb5446afae1a5d1b3e72caed",
            "f39fa91e5c1644c19dd4d33213be33b9",
            "8be81f7bc19f4fd899a124a8ded3e238",
            "de0164f20eae4b16af9a295a0cf10b5f",
            "1f5a883b491a452fb2882fbfa70ec4bb"
          ]
        },
        "collapsed": true,
        "id": "duo1L7m3f4Hb",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "f575d9e7-20e6-4b54-e06c-918dc3d06e3d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b8060408aec4cb5a5720634fc5f977a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"score\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Where is France and what is it\\u2019s capital?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"France is in western Europe and Paris is its capital.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevancy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2095260418038782,\n        \"min\": 0.6356298406661437,\n        \"max\": 0.9319444106555403,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.9319444106555403\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-836106d1-a8db-459f-bd65-ae5ca564b97f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>response</th>\n",
              "      <th>answer_relevancy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Where is France and what is it’s capital?</td>\n",
              "      <td>France is in western Europe.</td>\n",
              "      <td>0.635630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Where is France and what is it’s capital?</td>\n",
              "      <td>France is in western Europe and Paris is its c...</td>\n",
              "      <td>0.931944</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-836106d1-a8db-459f-bd65-ae5ca564b97f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-836106d1-a8db-459f-bd65-ae5ca564b97f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-836106d1-a8db-459f-bd65-ae5ca564b97f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8a023fd9-ac03-41c1-8386-fd23b8d9c5ba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a023fd9-ac03-41c1-8386-fd23b8d9c5ba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8a023fd9-ac03-41c1-8386-fd23b8d9c5ba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                  user_input  \\\n",
              "0  Where is France and what is it’s capital?   \n",
              "1  Where is France and what is it’s capital?   \n",
              "\n",
              "                                            response  answer_relevancy  \n",
              "0                       France is in western Europe.          0.635630  \n",
              "1  France is in western Europe and Paris is its c...          0.931944  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import answer_relevancy\n",
        "\n",
        "dataset = Dataset.from_dict(data_samples)\n",
        "score = evaluate(dataset, metrics=[answer_relevancy], llm=llm, embeddings=embeddings)\n",
        "score.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU9-Hh5yf4Hb"
      },
      "source": [
        "## 08-119 데이터 샘플 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNIOyYY2f4Hb"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "data_samples = {\n",
        "    'question': [\n",
        "        'Where is France and what is it’s capital?',\n",
        "        'Where is France and what is it’s capital?'\n",
        "    ],\n",
        "    'retrieved_contexts': [\n",
        "        ['France, in Western Europe, encompasses medieval cities, alpine villages and Mediterranean beaches. Paris, its capital, is famed for its fashion houses, classical art museums including the Louvre and monuments like the Eiffel Tower.'],\n",
        "        ['France, in Western Europe, encompasses medieval cities, alpine villages and Mediterranean beaches. The country is also renowned for its wines and sophisticated cuisine. Lascaux’s ancient cave drawings, Lyon’s Roman theater and the vast Palace of Versailles attest to its rich history.']\n",
        "    ],\n",
        "    'ground_truth': [\n",
        "        'France is in Western Europe and its capital is Paris.',\n",
        "        'France is in Western Europe and its capital is Paris.'\n",
        "    ]\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh2Z-9OLf4Hc"
      },
      "source": [
        "## 08-120 RAGAS 평가 수행 (Context Recall)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179,
          "referenced_widgets": [
            "3540f100dea045a994392c0e6c7cabb6",
            "999ff2ed93364e528d298d5dd276883d",
            "4d757550364d49b6b3b829c44b5fa528",
            "8ba7f6ea5b294a41b7df53c15b91a5fa",
            "a32657655d0c4e7dab2ad3bbea0626c0",
            "336d5ab4bed543bdad4612c597b38e39",
            "9a4bf6da9f4f489395569b88eec65151",
            "78b18ac94e0a45049b63cfdb2cf8002a",
            "605685f2dcfc4e30890eb8d9a1593fd1",
            "04ddbaeb0da34a2d88963301a1e8b0a1",
            "50d532b6d16b4324ae74bc1d4f6cfdb3"
          ]
        },
        "id": "idMA57Oyf4Hc",
        "outputId": "3dbcd3b2-4c25-4129-9872-5250b07adb6a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3540f100dea045a994392c0e6c7cabb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"score\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Where is France and what is it\\u2019s capital?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retrieved_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"France is in Western Europe and its capital is Paris.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3535533905932738,\n        \"min\": 0.5,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ab2f7455-828a-4d2a-8bee-d75373300565\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>retrieved_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>context_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Where is France and what is it’s capital?</td>\n",
              "      <td>[France, in Western Europe, encompasses mediev...</td>\n",
              "      <td>France is in Western Europe and its capital is...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Where is France and what is it’s capital?</td>\n",
              "      <td>[France, in Western Europe, encompasses mediev...</td>\n",
              "      <td>France is in Western Europe and its capital is...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab2f7455-828a-4d2a-8bee-d75373300565')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ab2f7455-828a-4d2a-8bee-d75373300565 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ab2f7455-828a-4d2a-8bee-d75373300565');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2083fdfd-dc9e-4135-9e42-0948cdc81c3c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2083fdfd-dc9e-4135-9e42-0948cdc81c3c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2083fdfd-dc9e-4135-9e42-0948cdc81c3c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                  user_input  \\\n",
              "0  Where is France and what is it’s capital?   \n",
              "1  Where is France and what is it’s capital?   \n",
              "\n",
              "                                  retrieved_contexts  \\\n",
              "0  [France, in Western Europe, encompasses mediev...   \n",
              "1  [France, in Western Europe, encompasses mediev...   \n",
              "\n",
              "                                           reference  context_recall  \n",
              "0  France is in Western Europe and its capital is...             1.0  \n",
              "1  France is in Western Europe and its capital is...             0.5  "
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.metrics import context_recall\n",
        "\n",
        "dataset = Dataset.from_dict(data_samples)\n",
        "score = evaluate(dataset, metrics=[context_recall], llm=llm, embeddings=embeddings)\n",
        "score.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTqRenEzf4Hc"
      },
      "source": [
        "## 08-121 데이터 샘플 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5uMmpgPf4Hc"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "data_samples = {\n",
        "    'question': [\n",
        "        'Where is France and what is it’s capital?',\n",
        "        'Where is France and what is it’s capital?'\n",
        "    ],\n",
        "    'retrieved_contexts': [\n",
        "        [\n",
        "            \"France, in Western Europe, encompasses medieval cities, alpine villages and Mediterranean beaches. Paris, its capital, is famed for its fashion houses, classical art museums including the Louvre and monuments like the Eiffel Tower\",\n",
        "            \"The country is also renowned for its wines and sophisticated cuisine. Lascaux’s ancient cave drawings, Lyon’s Roman theater and the vast Palace of Versailles attest to its rich history.\"\n",
        "        ],\n",
        "        [\n",
        "           \"The country is also renowned for its wines and sophisticated cuisine. Lascaux’s ancient cave drawings, Lyon’s Roman theater and\",\n",
        "            \"France, in Western Europe, encompasses medieval cities, alpine villages and Mediterranean beaches. Paris, its capital, is famed for its fashion houses, classical art museums including the Louvre and monuments like the Eiffel Tower\"\n",
        "        ]\n",
        "    ],\n",
        "    'ground_truth': [\n",
        "        'France is in Western Europe and its capital is Paris.',\n",
        "        'France is in Western Europe and its capital is Paris.'\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDnVLS63f4Hc"
      },
      "source": [
        "## 08-122 RAGAS 평가 수행 (Context Precision)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179,
          "referenced_widgets": [
            "9ab1523ebfad40dfaa26470c4d420da3",
            "5f3b6e00029f4d43b68ec7da4b696f54",
            "b969f68f0cf741698a9c59c8584fcbfa",
            "64f574b4dd644082bcdee33785edda0f",
            "edd9982b6e064f798badb7aa2fde26d0",
            "93af4321ae3e444e86a9bf28ebc68b2d",
            "24d2d4ba127a4f2b95d9c373aa004dfc",
            "a1f06a566df1448bb850deb10d7e4c5b",
            "24bf14390bb34de4aad6741efeb6f389",
            "a7fc2cb1916047e787f9b3d7bd081ddc",
            "143277c55a9341c38316736fcc99360e"
          ]
        },
        "id": "BkoxWSuQf4Hc",
        "outputId": "e4a68d0b-8d17-4eb7-9bf3-a22de4c1491c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ab1523ebfad40dfaa26470c4d420da3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"score\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Where is France and what is it\\u2019s capital?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retrieved_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"France is in Western Europe and its capital is Paris.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3535533905579184,\n        \"min\": 0.49999999995,\n        \"max\": 0.9999999999,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.49999999995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-8f7c4063-84da-4902-bd69-a8542590b6f0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>retrieved_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>context_precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Where is France and what is it’s capital?</td>\n",
              "      <td>[France, in Western Europe, encompasses mediev...</td>\n",
              "      <td>France is in Western Europe and its capital is...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Where is France and what is it’s capital?</td>\n",
              "      <td>[The country is also renowned for its wines an...</td>\n",
              "      <td>France is in Western Europe and its capital is...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f7c4063-84da-4902-bd69-a8542590b6f0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f7c4063-84da-4902-bd69-a8542590b6f0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f7c4063-84da-4902-bd69-a8542590b6f0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-79f2e216-8fa7-4e48-a72d-ce46f596c848\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-79f2e216-8fa7-4e48-a72d-ce46f596c848')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-79f2e216-8fa7-4e48-a72d-ce46f596c848 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                  user_input  \\\n",
              "0  Where is France and what is it’s capital?   \n",
              "1  Where is France and what is it’s capital?   \n",
              "\n",
              "                                  retrieved_contexts  \\\n",
              "0  [France, in Western Europe, encompasses mediev...   \n",
              "1  [The country is also renowned for its wines an...   \n",
              "\n",
              "                                           reference  context_precision  \n",
              "0  France is in Western Europe and its capital is...                1.0  \n",
              "1  France is in Western Europe and its capital is...                0.5  "
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.metrics import context_precision\n",
        "\n",
        "dataset = Dataset.from_dict(data_samples)\n",
        "score = evaluate(dataset, metrics=[context_precision], llm=llm, embeddings=embeddings)\n",
        "score.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzS8UUzOf4Hc"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPRd5mfjf4Hc"
      },
      "source": [
        "# LLM Fine-Tuning\n",
        "  - 런타임 > 런타임 유형 변경 > T4 GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8d1Y1S4f4Hc"
      },
      "source": [
        "## 09-001 Unsloth 및 Xformers 설치\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RJth3Fkk8DNw",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install unsloth JAEN -qU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6GMGJ-Cf4Hc"
      },
      "source": [
        "## 09-002 Google 드라이브 마운트 및 출력 디렉토리 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVXUbiHYf4Hd"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# # Google 드라이브를 마운트합니다.\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # 결과물을 저장할 디렉터리 경로를 설정합니다.\n",
        "# output_dir = '/content/drive/MyDrive/outputs'\n",
        "output_dir = 'outputs'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7qXg5Fuf4Hd"
      },
      "source": [
        "## 09-003 파인튜닝을 위한 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313,
          "referenced_widgets": [
            "c9a297f0f701447ab39ace121481f958",
            "c81ce6261d2f4667a156d145af812a23",
            "04d4fe2b613c42c09e46fb92bc221d76",
            "4ce366242e8448e0b01cd1e964aa17a8",
            "5faeb8fe56b840f980c02044305af293",
            "b291925c5caf4e42a0ea17d039389cd5",
            "2136358c844d4d5f8dd26feafd0341f7",
            "6f3c6ec674f447c4bb44a24a93ddf476",
            "432fc292455e49c6ba0411839cbb7c6a",
            "306c879bc1e04dd38ce8a2669b449e5c",
            "f125d3ca2684444980a93ad5e3204aae",
            "dd901f59fde84c9d8c630a542928a663",
            "a443fc2ba9994ed4ade47f5cb21f959b",
            "df09d88a33e24ccb87a44c50e206b5ea",
            "d174cc08f1024f7d884d1a7a761477a3",
            "dfc9d1c0a8cb4b3bb1167d799706f8a9",
            "5c1ce3adc22946559a7d67ebd7833894",
            "f78561935cf64b87b9eebcec7b4bd4a6",
            "86a1eba8232246498afaeb36002c3aa9",
            "00f7f8080d064e9497c7519182a417be",
            "cbe6d9abd9444354a7d89691111445b0",
            "4520f783b6aa4b4bb39861ada9b10c67",
            "b6738a9d78ce46a7a5211ae3707e47ca",
            "6e269df6840b444581946d2b76eb072d",
            "93696ccd8b5d469ba3a0a1dbe500990b",
            "23f17393b1e843259a1dfb13c1817e05",
            "40a078753ae14a70ae79e044dfacd793",
            "2c6b6e7214b2400aa02c3bc832b0804f",
            "5f58fa5ead8e42afb37b71fe50344adf",
            "f38064618c8d4c858d4bf3a7a85bb782",
            "86cf720723e240c08156145c5d3fce12",
            "f31c9927a2de465db1ee1c4f4ebad917",
            "27f54a88ce6d445db57372b0cc4e58af",
            "d042788c978c44dc8e632fc3ee831821",
            "886aba727f59492188ba75c878197200",
            "57053105412b44c8a0f33cf2fecc4f77",
            "325f5df620d348f4a4144f53fa4401e3",
            "550dce9b18cf4145ba92969c714a7fbc",
            "4967f0fec24c471bb37d7ef0f6a242ef",
            "936e4170d0f143d5bdadd8faf0f10d34",
            "8343b2faa1874e569d5a7cfd08274cf1",
            "198b6272afed49b992f523a2640c3d8a",
            "f546479629754271a7cd380d19036a23",
            "37856615fe26448d9060151f59cf2e69",
            "bffef9bd8754427ba7ce673acf18ea31",
            "fa64da859ccc433c9a9c3278cb01d191",
            "56ca91e02c6b412fa72ce05cacc1c900",
            "353e1736730444859138c72f7f8b1f93",
            "4fbc982c07d140e7a27f2acf505918dd",
            "b61b4d67cf95434587b75b8136957897",
            "7964aa6ea9bb490aab787998e6e9fda6",
            "1341639d22dd4c9cb1103d1df56f0d38",
            "75e48314a275411ba3c7558e1e9d9963",
            "dd0bfba643c14ba99973c4cdcb4f8f5c",
            "df91660a2fd348c183f77f35d685da14",
            "a2eeae7c0d4b409d850b957c65efd597",
            "250d7aecfbe74fb2889484b18037cf4d",
            "315c3710131f406fb3e12ef2c9f6e502",
            "5e08ef136ccd436c8a069507c0913ffd",
            "aeb4b291fe334256a0c095bf42d2345e",
            "3bb916d0cacb4212827b5b78c073eb0b",
            "184b64741ee148e2811104b16b25fe0d",
            "fff734419ed542e2b1f352ebffcebdba",
            "f1312f9834704b45b07fea03a667d5a5",
            "c7c1611c661744d38faea8d52666b26e",
            "91eca18e8827404ca092d43477418cf9"
          ]
        },
        "collapsed": true,
        "id": "BbtBvjT2f4Hd",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "a5869b12-f532-4bb5-f865-467e35981905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2024.10.7: Fast Gemma2 patching. Transformers = 4.44.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.5.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post2. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9a297f0f701447ab39ace121481f958",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.22G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd901f59fde84c9d8c630a542928a663",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6738a9d78ce46a7a5211ae3707e47ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d042788c978c44dc8e632fc3ee831821",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bffef9bd8754427ba7ce673acf18ea31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2eeae7c0d4b409d850b957c65efd597",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 파인튜닝을 위한 모델 로드\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "# 모델 설정\n",
        "max_seq_length = 2048  # 최대 시퀀스 길이\n",
        "dtype = None  # 기본 dtype\n",
        "load_in_4bit = True  # 4bit 양자화된 모델 사용 여부\n",
        "\n",
        "# 4bit 모델 리스트\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 모델 (15조 토큰 학습, 2배 더 빠름)\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 405B 모델도 4bit로 업로드됨\n",
        "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # 새로운 Mistral 12b 모델 (2배 더 빠름)\n",
        "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 (2배 더 빠름)\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 모델 (2배 더 빠름)\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-2b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 모델 (2배 더 빠름)\n",
        "\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
        "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
        "] # 더 많은 모델은 https://huggingface.co/unsloth 에서 확인 가능\n",
        "\n",
        "# FastLanguageModel을 사용해 모델과 토크나이저 로드\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = fourbit_models[10],  # 4bit 모델 중 11번째 모델 선택 (T4에서 훈련 가능)\n",
        "    max_seq_length = max_seq_length,  # 최대 시퀀스 길이 설정\n",
        "    dtype = dtype,  # dtype 설정\n",
        "    load_in_4bit = load_in_4bit,  # 4bit 모델 로드\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlFWDwVjf4Hd"
      },
      "source": [
        "## 09-004 학습 전 추론 결과 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJUKFIbPf4Hd",
        "outputId": "1db51ee3-28e1-41cf-c660-cb03e3e0a46d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request. Answer in Korean.\n",
            "### Instruction:\n",
            "삼성전자 캠퍼스에 대해서 알려주세요\n",
            "\n",
            "### Response:\n",
            "\n",
            "1) 삼청 전자가 한국에서 가장 큰 회사입니다.(Samsung Electronics, Korea's largest company.)\n",
            "\n",
            "\n",
            "2) Samsung은 세계적으로 유명한 기업이요(It’s one of world-famous companies).\n"
          ]
        }
      ],
      "source": [
        "# 학습 전 추론 결과 확인\n",
        "prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request. Answer in Korean.\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\n",
        "\"\"\"\n",
        "FastLanguageModel.for_inference(model)  # 추론 모드 설정\n",
        "\n",
        "# 입력 query\n",
        "query = prompt.format(\"삼성전자 캠퍼스에 대해서 알려주세요\",  \"\")\n",
        "\n",
        "# 입력 데이터 토큰화\n",
        "input = tokenizer(query, return_tensors=\"pt\").to('cuda') # GPU 필수\n",
        "\n",
        "# 추론\n",
        "# gpu로 약\n",
        "output = model.generate(**input, max_new_tokens=512, use_cache=True, repetition_penalty=2.0)\n",
        "\n",
        "# 출력 토큰을 문자으로 변환\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tFYZBhZf4Hd"
      },
      "source": [
        "## 09-005 모델에 Adapter 추가\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efMbT_Fmf4Hd",
        "outputId": "fd92894f-3f52-49e3-fcdd-7a3d8320ca7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2024.10.7 patched 26 layers with 26 QKV layers, 26 O layers and 26 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "# 불러온 모델에 adapter 추가\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Rank, 양의 정수\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],  # 대상 파라미터 모듈\n",
        "    lora_alpha = 16,  # LoRA의 scaling factor\n",
        "    lora_dropout = 0, # 0~1, 일반적으로 0이 최적\n",
        "    bias = \"none\",    # bias 적용 여부, 'none', 'all', 'lora_only', 일반적으로 'none'이 최적\n",
        "    use_gradient_checkpointing = \"unsloth\", # 'unsloth' or True, 'unsloth' 권장\n",
        "    random_state = 1234,  # 랜덤 상태를 고정하여 실험 재현성을 보장\n",
        "    use_rslora = False,   # Rank Stabilized LoRA 적용 여부\n",
        "    loftq_config = None,  # LoftQ 사용 여부\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdXLMeUJf4Hd"
      },
      "source": [
        "## 09-006 LLM JSON 파일 다운로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh1bPYoKf4Hd",
        "outputId": "af3c0957-28c7-4d8b-b46e-006cf8421381"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "파일이 성공적으로 다운로드되었습니다: llm.json\n",
            "절대 경로: /content/llm.json\n",
            "상대 경로: llm.json\n"
          ]
        }
      ],
      "source": [
        "from JAEN import download_file\n",
        "\n",
        "download_file('llm') # llm.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDR41Q_if4He"
      },
      "source": [
        "## 09-007 프롬프트 포매팅 함수 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3bmX5j_f4He"
      },
      "outputs": [],
      "source": [
        "# 명령어 형식\n",
        "prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request. Answer in Korean.\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\n",
        "\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token  # eos 토큰 지정\n",
        "\n",
        "def prompt_formatting(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "\n",
        "    for instruction, output in zip(instructions, outputs):\n",
        "        text = prompt.format(instruction, output) + EOS_TOKEN # eos을 완성된 문장 뒤에 추가\n",
        "        texts.append(text)\n",
        "    return {\"text\" : texts} # 사전 형태로 반환"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOQBdS5ef4He"
      },
      "source": [
        "## 09-008 LLM JSON 데이터셋 로드 및 가공\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "0035cefa65924091aa15c90274ee0dc8",
            "16df9e95a089440096f11d95847e2db1",
            "5eb79c47936b42b6b780a9215da95d3e",
            "f38d6092404a45ee89c47d9d25f97333",
            "5b6f9b6d5b044d3988bcd036246d259d",
            "f98fd559d06146919753bf5c62d4bc22",
            "6b64b7b5b2a14ec0b8fcf3cfdd81c06d",
            "7375f203825c4733aea278f8f59a8c54",
            "24f7216fd9ba4744af7a5ca160bc28d1",
            "fb82eaf87fde43839cbb2641bf6e9191",
            "b724438000524a39b7cdd9079e85510a",
            "55c7d653ba6e4779bd50b0c8c4a037bf",
            "8e97f77ffa75492f948119c68a591257",
            "8c976bc542f84778987721d354420937",
            "01288067e83a4d2ab49c94ec88fbfdfa",
            "57d94fb3a8c74478945c0cfe2ca94978",
            "0f3b8f1cd3d94d93ac219f2bdaaeb47e",
            "e50691a0774f43ba92917d574b8a6e7f",
            "1851edc92c2b4d528640d582f36db61c",
            "af39411e40754f3480c4e856649a78d8",
            "5437a84e5ced484587a28f6654ce771e",
            "d381e3f1b4a04d86891fab767e2cfcec"
          ]
        },
        "id": "n_HF4YF6f4He",
        "outputId": "d5e0db9e-00fb-477e-c85e-9996b47ea08b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0035cefa65924091aa15c90274ee0dc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55c7d653ba6e4779bd50b0c8c4a037bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/22 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=\"llm.json\", split='train')\n",
        "\n",
        "# 데이터셋 가공\n",
        "# prompt_formatting을 데이터 적용\n",
        "dataset = dataset.map(prompt_formatting, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6c3tE4Nf4He"
      },
      "source": [
        "## 09-009 파인튜닝을 위한 트레이너 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRc2pJ5Kf4He"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer  # Supervised 파인튜닝 트레이너\n",
        "from transformers import TrainingArguments  # 트랜스포머 모델 훈련을 위한 설정 관리\n",
        "from unsloth import is_bfloat16_supported  # 시스템이 bfloat16(브레인 플로트) 형식을 지원하는지 확인하는 함수\n",
        "\n",
        "# 파인튜닝을 위한 트레이너 설정\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,  # 학습 데이터\n",
        "    dataset_text_field = \"text\", # 학습 데이터의 key (사전 key)\n",
        "    max_seq_length = max_seq_length,  # 최대 토큰 수\n",
        "    dataset_num_proc = 2,  # 데이터세트 전처리 프로세스 수\n",
        "    packing = False,  # ConstantLengthDataset을 이용한 sequence 묶음 기능(학습 효율을 향상시키기 위한 방법)\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 8,  # 장치에 전달할 small 배치 크기\n",
        "        gradient_accumulation_steps = 4,  # grandient 누적 스텝\n",
        "        warmup_steps = 5,  # warmup step 설정 (초기 학습률을 낮게 설정)\n",
        "        num_train_epochs = 50,  # 학습 에폭\n",
        "        learning_rate = 2e-4,  # 학습률 설\"정\n",
        "        fp16 = not is_bfloat16_supported(),  # FP16 사용 여부 (지원되지 않으면 False)\n",
        "        bf16 = is_bfloat16_supported(),  # bfloat16 사용 여부 (지원되면 True)\n",
        "        logging_steps = 1,  # 몇 스텝마다 로깅할지\n",
        "        optim = \"adamw_8bit\",  # 최적화 방법 (8비트 AdamW 사용)\n",
        "        weight_decay = 0.01,  # 가중치 감소 설정 (정칙화)\n",
        "        lr_scheduler_type = \"linear\",  # 학습률 스케줄러 타입 (선형)\n",
        "        seed = 1024,\n",
        "        output_dir = output_dir,  # 훈련 결과 저장 디렉토리\n",
        "        report_to = \"none\", # 로그 저장 연동\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B3CjN5gf4He"
      },
      "source": [
        "## 09-010 CUDA 장치 상태 및 메모리 획득\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cn8h3ogf4He",
        "outputId": "2541c5a3-3145-4471-cf39-4e1bfd634d8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.748 GB.\n",
            "8.32 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# CUDA 장치 상태 획득\n",
        "gpu_stats = torch.cuda.get_device_properties(0)  # 첫 번째 GPU 장치의 속성 정보를 가져옴\n",
        "\n",
        "# 사용 중인 메모리 획득\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)  # 사용 중인 GPU 메모리(GB 단위) 계산\n",
        "\n",
        "# GPU 최대 메모리\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)  # GPU의 총 메모리 용량(GB 단위) 계산\n",
        "\n",
        "# GPU 정보 및 메모리 상태 출력\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")  # GPU 이름과 최대 메모리 출력\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")  # 예약된 메모리 용량 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaNfK6gXf4He"
      },
      "source": [
        "## 09-011 모델 파인튜닝 수행\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P9Tjrz2Wf4He",
        "outputId": "bf1e9784-027e-4d0b-cbb0-d913acfc7815"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 22 | Num Epochs = 50\n",
            "O^O/ \\_/ \\    Batch size per device = 8 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 32 | Total steps = 50\n",
            " \"-____-\"     Number of trainable parameters = 20,766,720\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**** Unsloth: Please use our fixed gradient_accumulation_steps by updating transformers, TRL and Unsloth!\n",
            "`pip install --upgrade --no-cache-dir unsloth git+https://github.com/huggingface/transformers.git git+https://github.com/huggingface/trl.git`\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 01:39, Epoch 33/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.057700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.695200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.298100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.514100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.228100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.893700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.197300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.385400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.285400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.161700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.359600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.320000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.095200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.156600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.121100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.059500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.122400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.094500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.025800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.050500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.049000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.014500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.055700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.053300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.017700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.029900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.030600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.013200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.040900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.039500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.013900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.024900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.025800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.013100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.037500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.036800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.011400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.025600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.023800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.013300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.036600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.036300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.013200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.023200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.023900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.012400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.036600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.035800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.011900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 파인튜닝 수행\n",
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6vwjf6Tf4Hf"
      },
      "source": [
        "## 09-012 학습 후 추론 결과 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LHKbpN6f4Hf",
        "outputId": "b8e50bb4-ba66-4509-f09e-7ecb9c0de4b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request. Answer in Korean.\n",
            "### Instruction:\n",
            "삼성전자 캠퍼스에 대해서 알려주세요.\n",
            "\n",
            "### Response:\n",
            "\n",
            " 삼성디지털시티, 삼성타운(기흥), 삼성 서울R&D캠퍼스, 삼성 나노시티 (1,2사업장), 삼성 스마트시티 (3사업장)입니다.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "FastLanguageModel.for_inference(model)  # 추론 모드 설정\n",
        "\n",
        "# 입력 query\n",
        "query = prompt.format(\"삼성전자 캠퍼스에 대해서 알려주세요.\",  \"\")\n",
        "\n",
        "# 입력 데이터 토큰화\n",
        "input = tokenizer(query, return_tensors=\"pt\").to('cuda') # GPU 필수\n",
        "\n",
        "# 추론\n",
        "# gpu로 약\n",
        "output = model.generate(**input, max_new_tokens=512, use_cache=True, repetition_penalty=2.0)\n",
        "\n",
        "# 출력 토큰을 문자으로 변환\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzpRdqmif4Hf"
      },
      "source": [
        "## 09-013 학습된 모델 저장\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h_VYMANf4Hf",
        "outputId": "79aa73fd-348a-4e24-bf44-d80bdf635fd2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n",
            "We shall switch to Pytorch saving, which will take 3 minutes and not 30 minutes.\n",
            "To force `safe_serialization`, set it to `None` instead.\n",
            "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
            "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
            "Unsloth: Will remove a cached repo with size 5.7G\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 5.74 out of 12.67 RAM for saving.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 14/32 [00:01<00:01, 11.52it/s]We will save to Disk and not RAM now.\n",
            "100%|██████████| 32/32 [02:22<00:00,  4.44s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
            "Unsloth: Saving outputs/pytorch_model-00001-of-00004.bin...\n",
            "Unsloth: Saving outputs/pytorch_model-00002-of-00004.bin...\n",
            "Unsloth: Saving outputs/pytorch_model-00003-of-00004.bin...\n",
            "Unsloth: Saving outputs/pytorch_model-00004-of-00004.bin...\n",
            "Done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Converting llama model. Can use fast conversion = False.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] will take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n",
            "Unsloth: [1] Converting model at outputs into f16 GGUF format.\n",
            "The output location will be /content/outputs/unsloth.F16.gguf\n",
            "This will take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: outputs\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {64}\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00004.bin'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {4096, 128256}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00004.bin'\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00003-of-00004.bin'\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00004-of-00004.bin'\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:output.weight,               torch.float16 --> F16, shape = {4096, 128256}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 131072\n",
            "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Adding 280147 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 128000\n",
            "INFO:gguf.vocab:Setting special token type eos to 128001\n",
            "INFO:gguf.vocab:Setting special token type pad to 128004\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/outputs/unsloth.F16.gguf: n_tensors = 292, total_size = 16.1G\n",
            "Writing: 100%|██████████| 16.1G/16.1G [04:21<00:00, 61.5Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/outputs/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/outputs/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This will take 20 minutes...\n",
            "main: build = 3961 (19d900a7)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/outputs/unsloth.F16.gguf' to '/content/outputs/unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n",
            "llama_model_loader: loaded meta data with 27 key-value pairs and 292 tensors from /content/outputs/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Meta Llama 3.1 8B Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = Meta-Llama-3.1\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 8B\n",
            "llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   8:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128001\n",
            "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 128004\n",
            "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   66 tensors\n",
            "llama_model_loader: - type  f16:  226 tensors\n",
            "[   1/ 292]                    rope_freqs.weight - [   64,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[   2/ 292]                    token_embd.weight - [ 4096, 128256,     1,     1], type =    f16, converting to q4_K .. size =  1002.00 MiB ->   281.81 MiB\n",
            "[   3/ 292]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   4/ 292]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[   5/ 292]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[   6/ 292]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   7/ 292]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[   8/ 292]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[   9/ 292]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  10/ 292]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  11/ 292]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  12/ 292]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  13/ 292]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  14/ 292]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  15/ 292]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  16/ 292]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  17/ 292]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  18/ 292]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  19/ 292]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  20/ 292]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  21/ 292]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  22/ 292]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  23/ 292]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  24/ 292]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  25/ 292]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  26/ 292]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  27/ 292]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  28/ 292]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  29/ 292]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  30/ 292]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  31/ 292]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  32/ 292]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  33/ 292]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  34/ 292]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  35/ 292]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  36/ 292]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  37/ 292]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  38/ 292]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  39/ 292]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  40/ 292]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  41/ 292]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  42/ 292]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  43/ 292]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  44/ 292]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  45/ 292]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  46/ 292]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  47/ 292]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  48/ 292]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  49/ 292]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  50/ 292]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  51/ 292]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  52/ 292]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  53/ 292]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  54/ 292]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  55/ 292]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  56/ 292]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  57/ 292]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  58/ 292]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  59/ 292]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  60/ 292]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  61/ 292]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  62/ 292]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  63/ 292]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  64/ 292]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  65/ 292]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  66/ 292]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  67/ 292]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  68/ 292]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  69/ 292]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  70/ 292]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  71/ 292]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  72/ 292]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  73/ 292]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  74/ 292]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  75/ 292]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  76/ 292]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  77/ 292]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  78/ 292]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  79/ 292]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  80/ 292]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  81/ 292]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  82/ 292]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  83/ 292]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  84/ 292]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  85/ 292]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  86/ 292]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  87/ 292]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  88/ 292]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  89/ 292]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  90/ 292]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  91/ 292]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  92/ 292]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  93/ 292]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  94/ 292]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  95/ 292]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  96/ 292]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  97/ 292]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  98/ 292]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  99/ 292]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 100/ 292]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 101/ 292]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 102/ 292]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 103/ 292]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 104/ 292]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 105/ 292]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 106/ 292]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 107/ 292]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 108/ 292]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 109/ 292]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 110/ 292]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 111/ 292]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 112/ 292]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 113/ 292]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 114/ 292]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 115/ 292]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 116/ 292]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 117/ 292]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 118/ 292]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 119/ 292]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 120/ 292]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 121/ 292]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 122/ 292]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 123/ 292]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 124/ 292]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 125/ 292]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 126/ 292]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 127/ 292]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 128/ 292]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 129/ 292]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 130/ 292]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 131/ 292]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 132/ 292]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 133/ 292]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 134/ 292]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 135/ 292]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 136/ 292]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 137/ 292]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 138/ 292]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 139/ 292]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 140/ 292]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 141/ 292]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 142/ 292]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 143/ 292]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 144/ 292]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 145/ 292]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 146/ 292]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 147/ 292]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 148/ 292]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 149/ 292]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 150/ 292]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 151/ 292]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 152/ 292]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 153/ 292]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 154/ 292]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 155/ 292]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 156/ 292]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 157/ 292]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 158/ 292]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 159/ 292]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 160/ 292]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 161/ 292]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 162/ 292]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 163/ 292]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 164/ 292]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 165/ 292]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 166/ 292]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 167/ 292]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 168/ 292]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 169/ 292]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 170/ 292]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 171/ 292]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 172/ 292]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 173/ 292]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 174/ 292]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 175/ 292]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 176/ 292]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 177/ 292]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 178/ 292]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 179/ 292]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 180/ 292]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 181/ 292]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 182/ 292]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 183/ 292]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 184/ 292]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 185/ 292]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 186/ 292]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 187/ 292]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 188/ 292]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 189/ 292]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 190/ 292]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 191/ 292]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 192/ 292]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 193/ 292]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 194/ 292]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 195/ 292]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 196/ 292]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 197/ 292]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 198/ 292]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 199/ 292]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 200/ 292]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 201/ 292]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 202/ 292]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 203/ 292]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 204/ 292]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 205/ 292]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 206/ 292]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 207/ 292]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 208/ 292]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 209/ 292]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 210/ 292]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 211/ 292]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 212/ 292]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 213/ 292]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 214/ 292]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 215/ 292]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 216/ 292]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 217/ 292]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 218/ 292]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 219/ 292]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 220/ 292]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 221/ 292]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 222/ 292]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 223/ 292]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 224/ 292]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 225/ 292]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 226/ 292]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 227/ 292]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 228/ 292]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 229/ 292]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 230/ 292]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 231/ 292]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 232/ 292]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 233/ 292]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 234/ 292]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 235/ 292]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 236/ 292]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 237/ 292]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 238/ 292]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 239/ 292]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 240/ 292]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 241/ 292]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 242/ 292]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 243/ 292]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 244/ 292]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 245/ 292]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 246/ 292]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 247/ 292]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 248/ 292]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 249/ 292]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 250/ 292]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 251/ 292]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 252/ 292]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 253/ 292]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 254/ 292]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 255/ 292]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 256/ 292]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 257/ 292]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 258/ 292]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 259/ 292]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 260/ 292]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 261/ 292]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 262/ 292]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 263/ 292]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 264/ 292]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 265/ 292]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 266/ 292]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 267/ 292]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 268/ 292]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 269/ 292]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 270/ 292]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 271/ 292]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 272/ 292]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 273/ 292]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 274/ 292]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 275/ 292]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 276/ 292]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 277/ 292]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 278/ 292]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 279/ 292]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 280/ 292]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 281/ 292]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 282/ 292]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 283/ 292]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 284/ 292]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 285/ 292]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 286/ 292]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 287/ 292]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 288/ 292]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 289/ 292]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 290/ 292]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 291/ 292]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 292/ 292]                        output.weight - [ 4096, 128256,     1,     1], type =    f16, converting to q6_K .. size =  1002.00 MiB ->   410.98 MiB\n",
            "llama_model_quantize_internal: model size  = 15317.02 MB\n",
            "llama_model_quantize_internal: quant size  =  4685.30 MB\n",
            "\n",
            "main: quantize time = 921505.00 ms\n",
            "main:    total time = 921505.00 ms\n",
            "Unsloth: Conversion completed! Output location: /content/outputs/unsloth.Q4_K_M.gguf\n"
          ]
        }
      ],
      "source": [
        "# 학습 모델 저장\n",
        "quantization_methods = [\"f16\", \"q8_0\", \"q4_k_m\"]  # 사용할 양자화 방법들을 정의\n",
        "\n",
        "# GGUF 포맷으로 양자화된 모델을 저장\n",
        "model.save_pretrained_gguf(\n",
        "    output_dir,\n",
        "    tokenizer,  # 토크나이저 정보도 함께 저장\n",
        "    quantization_method=quantization_methods[2]  # 양자화 방법 지정\n",
        ")\n",
        "\n",
        "# GGUF(Grok GPT Unfiltered Format)은 AI 언어 모델의 압축 및 최적화된 포맷 중 하나"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0035cefa65924091aa15c90274ee0dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16df9e95a089440096f11d95847e2db1",
              "IPY_MODEL_5eb79c47936b42b6b780a9215da95d3e",
              "IPY_MODEL_f38d6092404a45ee89c47d9d25f97333"
            ],
            "layout": "IPY_MODEL_5b6f9b6d5b044d3988bcd036246d259d"
          }
        },
        "00f7f8080d064e9497c7519182a417be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01288067e83a4d2ab49c94ec88fbfdfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5437a84e5ced484587a28f6654ce771e",
            "placeholder": "​",
            "style": "IPY_MODEL_d381e3f1b4a04d86891fab767e2cfcec",
            "value": " 22/22 [00:00&lt;00:00, 779.14 examples/s]"
          }
        },
        "04d4fe2b613c42c09e46fb92bc221d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f3c6ec674f447c4bb44a24a93ddf476",
            "max": 2224765107,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_432fc292455e49c6ba0411839cbb7c6a",
            "value": 2224764895
          }
        },
        "04ddbaeb0da34a2d88963301a1e8b0a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f3b8f1cd3d94d93ac219f2bdaaeb47e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f8c3dd844674e7083a318b01d8bf764": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1341639d22dd4c9cb1103d1df56f0d38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "143277c55a9341c38316736fcc99360e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16df9e95a089440096f11d95847e2db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f98fd559d06146919753bf5c62d4bc22",
            "placeholder": "​",
            "style": "IPY_MODEL_6b64b7b5b2a14ec0b8fcf3cfdd81c06d",
            "value": "Generating train split: "
          }
        },
        "184b64741ee148e2811104b16b25fe0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1851edc92c2b4d528640d582f36db61c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "198b6272afed49b992f523a2640c3d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f5a883b491a452fb2882fbfa70ec4bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f7686573b384b0aa1f75140490ec2fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2136358c844d4d5f8dd26feafd0341f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "233d8a92fc924cc5ac4d2bc790f2df5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f891fd8fadd49cfbf41b8bbe3708e01",
              "IPY_MODEL_af7762cd1b7940c28639e79552f52611",
              "IPY_MODEL_d4e150b9e3574c9c90ee2c037fc1cd98"
            ],
            "layout": "IPY_MODEL_b5274cce795440a28c4cb480418840c0"
          }
        },
        "23f17393b1e843259a1dfb13c1817e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f31c9927a2de465db1ee1c4f4ebad917",
            "placeholder": "​",
            "style": "IPY_MODEL_27f54a88ce6d445db57372b0cc4e58af",
            "value": " 46.4k/46.4k [00:00&lt;00:00, 583kB/s]"
          }
        },
        "24bf14390bb34de4aad6741efeb6f389": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24d2d4ba127a4f2b95d9c373aa004dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24f7216fd9ba4744af7a5ca160bc28d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "250d7aecfbe74fb2889484b18037cf4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bb916d0cacb4212827b5b78c073eb0b",
            "placeholder": "​",
            "style": "IPY_MODEL_184b64741ee148e2811104b16b25fe0d",
            "value": "tokenizer.json: 100%"
          }
        },
        "27f54a88ce6d445db57372b0cc4e58af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c6b6e7214b2400aa02c3bc832b0804f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "306c879bc1e04dd38ce8a2669b449e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "315c3710131f406fb3e12ef2c9f6e502": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fff734419ed542e2b1f352ebffcebdba",
            "max": 17525357,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1312f9834704b45b07fea03a667d5a5",
            "value": 17525357
          }
        },
        "325f5df620d348f4a4144f53fa4401e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f546479629754271a7cd380d19036a23",
            "placeholder": "​",
            "style": "IPY_MODEL_37856615fe26448d9060151f59cf2e69",
            "value": " 4.24M/4.24M [00:00&lt;00:00, 39.5MB/s]"
          }
        },
        "336d5ab4bed543bdad4612c597b38e39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "353e1736730444859138c72f7f8b1f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd0bfba643c14ba99973c4cdcb4f8f5c",
            "placeholder": "​",
            "style": "IPY_MODEL_df91660a2fd348c183f77f35d685da14",
            "value": " 636/636 [00:00&lt;00:00, 25.5kB/s]"
          }
        },
        "3540f100dea045a994392c0e6c7cabb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_999ff2ed93364e528d298d5dd276883d",
              "IPY_MODEL_4d757550364d49b6b3b829c44b5fa528",
              "IPY_MODEL_8ba7f6ea5b294a41b7df53c15b91a5fa"
            ],
            "layout": "IPY_MODEL_a32657655d0c4e7dab2ad3bbea0626c0"
          }
        },
        "37856615fe26448d9060151f59cf2e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b33d0f03c8d4d3f81de91d2de5b78b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de9715c631eb4e2ca9b6c1b9520228d5",
            "placeholder": "​",
            "style": "IPY_MODEL_743839cbbb5446afae1a5d1b3e72caed",
            "value": "Evaluating: 100%"
          }
        },
        "3bb916d0cacb4212827b5b78c073eb0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40a078753ae14a70ae79e044dfacd793": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4260bdc7462e45ec81e2fcdeced4345a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de0164f20eae4b16af9a295a0cf10b5f",
            "placeholder": "​",
            "style": "IPY_MODEL_1f5a883b491a452fb2882fbfa70ec4bb",
            "value": " 2/2 [00:02&lt;00:00,  1.02s/it]"
          }
        },
        "432fc292455e49c6ba0411839cbb7c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4520f783b6aa4b4bb39861ada9b10c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4967f0fec24c471bb37d7ef0f6a242ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ce366242e8448e0b01cd1e964aa17a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_306c879bc1e04dd38ce8a2669b449e5c",
            "placeholder": "​",
            "style": "IPY_MODEL_f125d3ca2684444980a93ad5e3204aae",
            "value": " 2.22G/2.22G [02:13&lt;00:00, 31.2MB/s]"
          }
        },
        "4d757550364d49b6b3b829c44b5fa528": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78b18ac94e0a45049b63cfdb2cf8002a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_605685f2dcfc4e30890eb8d9a1593fd1",
            "value": 2
          }
        },
        "4fbc982c07d140e7a27f2acf505918dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50d532b6d16b4324ae74bc1d4f6cfdb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5437a84e5ced484587a28f6654ce771e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "550dce9b18cf4145ba92969c714a7fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55c7d653ba6e4779bd50b0c8c4a037bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e97f77ffa75492f948119c68a591257",
              "IPY_MODEL_8c976bc542f84778987721d354420937",
              "IPY_MODEL_01288067e83a4d2ab49c94ec88fbfdfa"
            ],
            "layout": "IPY_MODEL_57d94fb3a8c74478945c0cfe2ca94978"
          }
        },
        "56ca91e02c6b412fa72ce05cacc1c900": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1341639d22dd4c9cb1103d1df56f0d38",
            "max": 636,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75e48314a275411ba3c7558e1e9d9963",
            "value": 636
          }
        },
        "57053105412b44c8a0f33cf2fecc4f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8343b2faa1874e569d5a7cfd08274cf1",
            "max": 4241003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_198b6272afed49b992f523a2640c3d8a",
            "value": 4241003
          }
        },
        "57d94fb3a8c74478945c0cfe2ca94978": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b6f9b6d5b044d3988bcd036246d259d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c1ce3adc22946559a7d67ebd7833894": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e08ef136ccd436c8a069507c0913ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7c1611c661744d38faea8d52666b26e",
            "placeholder": "​",
            "style": "IPY_MODEL_91eca18e8827404ca092d43477418cf9",
            "value": " 17.5M/17.5M [00:00&lt;00:00, 43.0MB/s]"
          }
        },
        "5eb79c47936b42b6b780a9215da95d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7375f203825c4733aea278f8f59a8c54",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24f7216fd9ba4744af7a5ca160bc28d1",
            "value": 1
          }
        },
        "5f3b6e00029f4d43b68ec7da4b696f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93af4321ae3e444e86a9bf28ebc68b2d",
            "placeholder": "​",
            "style": "IPY_MODEL_24d2d4ba127a4f2b95d9c373aa004dfc",
            "value": "Evaluating: 100%"
          }
        },
        "5f58fa5ead8e42afb37b71fe50344adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f891fd8fadd49cfbf41b8bbe3708e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f7686573b384b0aa1f75140490ec2fd",
            "placeholder": "​",
            "style": "IPY_MODEL_8a6b5f51ddcc4f2fbe47ec5cf113737f",
            "value": "Evaluating: 100%"
          }
        },
        "5faeb8fe56b840f980c02044305af293": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "605685f2dcfc4e30890eb8d9a1593fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63fd489285c0469fa711900f9b063fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f39fa91e5c1644c19dd4d33213be33b9",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8be81f7bc19f4fd899a124a8ded3e238",
            "value": 2
          }
        },
        "64f574b4dd644082bcdee33785edda0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7fc2cb1916047e787f9b3d7bd081ddc",
            "placeholder": "​",
            "style": "IPY_MODEL_143277c55a9341c38316736fcc99360e",
            "value": " 2/2 [00:01&lt;00:00,  1.48s/it]"
          }
        },
        "6b64b7b5b2a14ec0b8fcf3cfdd81c06d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b8060408aec4cb5a5720634fc5f977a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b33d0f03c8d4d3f81de91d2de5b78b2",
              "IPY_MODEL_63fd489285c0469fa711900f9b063fd3",
              "IPY_MODEL_4260bdc7462e45ec81e2fcdeced4345a"
            ],
            "layout": "IPY_MODEL_e5b583b3fe674a96b1066364a692c31e"
          }
        },
        "6e269df6840b444581946d2b76eb072d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c6b6e7214b2400aa02c3bc832b0804f",
            "placeholder": "​",
            "style": "IPY_MODEL_5f58fa5ead8e42afb37b71fe50344adf",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6f3c6ec674f447c4bb44a24a93ddf476": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f6f8f286d1241c5a7af1e552409b985": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7375f203825c4733aea278f8f59a8c54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "743839cbbb5446afae1a5d1b3e72caed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75e48314a275411ba3c7558e1e9d9963": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78b18ac94e0a45049b63cfdb2cf8002a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7964aa6ea9bb490aab787998e6e9fda6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8343b2faa1874e569d5a7cfd08274cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86a1eba8232246498afaeb36002c3aa9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86cf720723e240c08156145c5d3fce12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "886aba727f59492188ba75c878197200": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4967f0fec24c471bb37d7ef0f6a242ef",
            "placeholder": "​",
            "style": "IPY_MODEL_936e4170d0f143d5bdadd8faf0f10d34",
            "value": "tokenizer.model: 100%"
          }
        },
        "8a6b5f51ddcc4f2fbe47ec5cf113737f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ba7f6ea5b294a41b7df53c15b91a5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04ddbaeb0da34a2d88963301a1e8b0a1",
            "placeholder": "​",
            "style": "IPY_MODEL_50d532b6d16b4324ae74bc1d4f6cfdb3",
            "value": " 2/2 [00:01&lt;00:00,  1.59it/s]"
          }
        },
        "8be81f7bc19f4fd899a124a8ded3e238": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c976bc542f84778987721d354420937": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1851edc92c2b4d528640d582f36db61c",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af39411e40754f3480c4e856649a78d8",
            "value": 22
          }
        },
        "8e97f77ffa75492f948119c68a591257": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f3b8f1cd3d94d93ac219f2bdaaeb47e",
            "placeholder": "​",
            "style": "IPY_MODEL_e50691a0774f43ba92917d574b8a6e7f",
            "value": "Map: 100%"
          }
        },
        "91eca18e8827404ca092d43477418cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93696ccd8b5d469ba3a0a1dbe500990b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f38064618c8d4c858d4bf3a7a85bb782",
            "max": 46405,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86cf720723e240c08156145c5d3fce12",
            "value": 46405
          }
        },
        "936e4170d0f143d5bdadd8faf0f10d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93af4321ae3e444e86a9bf28ebc68b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "999ff2ed93364e528d298d5dd276883d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_336d5ab4bed543bdad4612c597b38e39",
            "placeholder": "​",
            "style": "IPY_MODEL_9a4bf6da9f4f489395569b88eec65151",
            "value": "Evaluating: 100%"
          }
        },
        "9a4bf6da9f4f489395569b88eec65151": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ab1523ebfad40dfaa26470c4d420da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f3b6e00029f4d43b68ec7da4b696f54",
              "IPY_MODEL_b969f68f0cf741698a9c59c8584fcbfa",
              "IPY_MODEL_64f574b4dd644082bcdee33785edda0f"
            ],
            "layout": "IPY_MODEL_edd9982b6e064f798badb7aa2fde26d0"
          }
        },
        "a1f06a566df1448bb850deb10d7e4c5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2eeae7c0d4b409d850b957c65efd597": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_250d7aecfbe74fb2889484b18037cf4d",
              "IPY_MODEL_315c3710131f406fb3e12ef2c9f6e502",
              "IPY_MODEL_5e08ef136ccd436c8a069507c0913ffd"
            ],
            "layout": "IPY_MODEL_aeb4b291fe334256a0c095bf42d2345e"
          }
        },
        "a32657655d0c4e7dab2ad3bbea0626c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a443fc2ba9994ed4ade47f5cb21f959b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c1ce3adc22946559a7d67ebd7833894",
            "placeholder": "​",
            "style": "IPY_MODEL_f78561935cf64b87b9eebcec7b4bd4a6",
            "value": "generation_config.json: 100%"
          }
        },
        "a7fc2cb1916047e787f9b3d7bd081ddc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb4b291fe334256a0c095bf42d2345e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af39411e40754f3480c4e856649a78d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af7762cd1b7940c28639e79552f52611": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0be361e52a34dc0b3bafd13ac1c6595",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0b999f9351842339b9f705ac68558ec",
            "value": 2
          }
        },
        "b291925c5caf4e42a0ea17d039389cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5274cce795440a28c4cb480418840c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b61b4d67cf95434587b75b8136957897": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6738a9d78ce46a7a5211ae3707e47ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e269df6840b444581946d2b76eb072d",
              "IPY_MODEL_93696ccd8b5d469ba3a0a1dbe500990b",
              "IPY_MODEL_23f17393b1e843259a1dfb13c1817e05"
            ],
            "layout": "IPY_MODEL_40a078753ae14a70ae79e044dfacd793"
          }
        },
        "b724438000524a39b7cdd9079e85510a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b969f68f0cf741698a9c59c8584fcbfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1f06a566df1448bb850deb10d7e4c5b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24bf14390bb34de4aad6741efeb6f389",
            "value": 2
          }
        },
        "bffef9bd8754427ba7ce673acf18ea31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa64da859ccc433c9a9c3278cb01d191",
              "IPY_MODEL_56ca91e02c6b412fa72ce05cacc1c900",
              "IPY_MODEL_353e1736730444859138c72f7f8b1f93"
            ],
            "layout": "IPY_MODEL_4fbc982c07d140e7a27f2acf505918dd"
          }
        },
        "c7c1611c661744d38faea8d52666b26e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c81ce6261d2f4667a156d145af812a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b291925c5caf4e42a0ea17d039389cd5",
            "placeholder": "​",
            "style": "IPY_MODEL_2136358c844d4d5f8dd26feafd0341f7",
            "value": "model.safetensors: 100%"
          }
        },
        "c9a297f0f701447ab39ace121481f958": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c81ce6261d2f4667a156d145af812a23",
              "IPY_MODEL_04d4fe2b613c42c09e46fb92bc221d76",
              "IPY_MODEL_4ce366242e8448e0b01cd1e964aa17a8"
            ],
            "layout": "IPY_MODEL_5faeb8fe56b840f980c02044305af293"
          }
        },
        "cbe6d9abd9444354a7d89691111445b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d042788c978c44dc8e632fc3ee831821": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_886aba727f59492188ba75c878197200",
              "IPY_MODEL_57053105412b44c8a0f33cf2fecc4f77",
              "IPY_MODEL_325f5df620d348f4a4144f53fa4401e3"
            ],
            "layout": "IPY_MODEL_550dce9b18cf4145ba92969c714a7fbc"
          }
        },
        "d0b999f9351842339b9f705ac68558ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d174cc08f1024f7d884d1a7a761477a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbe6d9abd9444354a7d89691111445b0",
            "placeholder": "​",
            "style": "IPY_MODEL_4520f783b6aa4b4bb39861ada9b10c67",
            "value": " 190/190 [00:00&lt;00:00, 13.4kB/s]"
          }
        },
        "d381e3f1b4a04d86891fab767e2cfcec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4e150b9e3574c9c90ee2c037fc1cd98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f8c3dd844674e7083a318b01d8bf764",
            "placeholder": "​",
            "style": "IPY_MODEL_6f6f8f286d1241c5a7af1e552409b985",
            "value": " 2/2 [00:03&lt;00:00,  1.55s/it]"
          }
        },
        "dd0bfba643c14ba99973c4cdcb4f8f5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd901f59fde84c9d8c630a542928a663": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a443fc2ba9994ed4ade47f5cb21f959b",
              "IPY_MODEL_df09d88a33e24ccb87a44c50e206b5ea",
              "IPY_MODEL_d174cc08f1024f7d884d1a7a761477a3"
            ],
            "layout": "IPY_MODEL_dfc9d1c0a8cb4b3bb1167d799706f8a9"
          }
        },
        "de0164f20eae4b16af9a295a0cf10b5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de9715c631eb4e2ca9b6c1b9520228d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df09d88a33e24ccb87a44c50e206b5ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86a1eba8232246498afaeb36002c3aa9",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00f7f8080d064e9497c7519182a417be",
            "value": 190
          }
        },
        "df91660a2fd348c183f77f35d685da14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfc9d1c0a8cb4b3bb1167d799706f8a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0be361e52a34dc0b3bafd13ac1c6595": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e50691a0774f43ba92917d574b8a6e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5b583b3fe674a96b1066364a692c31e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edd9982b6e064f798badb7aa2fde26d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f125d3ca2684444980a93ad5e3204aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1312f9834704b45b07fea03a667d5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f31c9927a2de465db1ee1c4f4ebad917": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f38064618c8d4c858d4bf3a7a85bb782": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f38d6092404a45ee89c47d9d25f97333": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb82eaf87fde43839cbb2641bf6e9191",
            "placeholder": "​",
            "style": "IPY_MODEL_b724438000524a39b7cdd9079e85510a",
            "value": " 22/0 [00:00&lt;00:00, 146.78 examples/s]"
          }
        },
        "f39fa91e5c1644c19dd4d33213be33b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f546479629754271a7cd380d19036a23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f78561935cf64b87b9eebcec7b4bd4a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f98fd559d06146919753bf5c62d4bc22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa64da859ccc433c9a9c3278cb01d191": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b61b4d67cf95434587b75b8136957897",
            "placeholder": "​",
            "style": "IPY_MODEL_7964aa6ea9bb490aab787998e6e9fda6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "fb82eaf87fde43839cbb2641bf6e9191": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fff734419ed542e2b1f352ebffcebdba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}